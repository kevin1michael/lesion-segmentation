{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import glob\n",
    "plt.rcParams['image.cmap'] = 'gist_earth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tf_unet import image_gen\n",
    "from tf_unet import unet\n",
    "from tf_unet import util\n",
    "from tf_unet import image_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx = 256\n",
    "ny = 256\n",
    "\n",
    "\n",
    "class ImageCustomProvider(image_util.ImageDataProvider):\n",
    "    def _find_data_files(self, search_path):\n",
    "        if isinstance(search_path, list):\n",
    "            all_files = []\n",
    "            for path in search_path:\n",
    "                all_files.extend(glob.glob(path))\n",
    "        else:\n",
    "            all_files = glob.glob(search_path)\n",
    "            \n",
    "        return [name for name in all_files if not self.mask_suffix in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files used: 1800\n",
      "../../train_test_data/train0/ISIC_0013129_histeq.tif\n"
     ]
    }
   ],
   "source": [
    "train_dir = '../../train_test_data/train0/*'\n",
    "\n",
    "generator = ImageCustomProvider([train_dir + '_histeq.tif', train_dir + '_segmentation.tif' ], data_suffix=u'_histeq.tif', mask_suffix=u'_segmentation.tif')\n",
    "train_data, labels = generator._next_data()\n",
    "print(generator.data_files[generator.file_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test, y_test = generator(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0157ee5050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAFkCAYAAABmVVBPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGzefZmZmZpaNm08zMzMzy+b/StlVlaVDShEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f015cd82a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, sharey=True, figsize=(8,4))\n",
    "ax[0].imshow(x_test[0,...,:], aspect=\"auto\")\n",
    "ax[1].imshow(y_test[0,...,1], aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 00:22:09,467 Layers 4, features 20, filter size 3x3, pool size: 2x2\n"
     ]
    }
   ],
   "source": [
    "net = unet.Unet(channels=generator.channels, n_class=generator.n_class, layers=4, features_root=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = unet.Trainer(net, optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 00:22:11,424 Removing '/home/bill/Desktop/course/syde522/proj/lesion-segmentation/unets/prediction'\n",
      "2017-03-30 00:22:11,425 Removing '/home/bill/Desktop/course/syde522/proj/lesion-segmentation/unets/unet_trained'\n",
      "2017-03-30 00:22:11,426 Allocating '/home/bill/Desktop/course/syde522/proj/lesion-segmentation/unets/prediction'\n",
      "2017-03-30 00:22:11,427 Allocating '/home/bill/Desktop/course/syde522/proj/lesion-segmentation/unets/unet_trained'\n",
      "2017-03-30 00:22:16,888 Verification error= 92.6%, loss= 0.7134\n",
      "2017-03-30 00:22:17,298 Start optimization\n",
      "2017-03-30 00:22:20,634 Iter 0, Minibatch Loss= 0.6483, Training Accuracy= 0.9802, Minibatch error= 2.0%\n",
      "2017-03-30 00:22:33,442 Iter 5, Minibatch Loss= 0.5266, Training Accuracy= 0.9921, Minibatch error= 0.8%\n",
      "2017-03-30 00:22:46,062 Iter 10, Minibatch Loss= 0.7536, Training Accuracy= 0.5366, Minibatch error= 46.3%\n",
      "2017-03-30 00:22:58,668 Iter 15, Minibatch Loss= 0.5323, Training Accuracy= 0.8063, Minibatch error= 19.4%\n",
      "2017-03-30 00:23:09,629 Iter 20, Minibatch Loss= 0.4673, Training Accuracy= 0.8374, Minibatch error= 16.3%\n",
      "2017-03-30 00:23:20,789 Iter 25, Minibatch Loss= 0.4664, Training Accuracy= 0.7926, Minibatch error= 20.7%\n",
      "2017-03-30 00:23:32,910 Iter 30, Minibatch Loss= 0.6457, Training Accuracy= 0.6592, Minibatch error= 34.1%\n",
      "2017-03-30 00:23:45,629 Iter 35, Minibatch Loss= 0.3337, Training Accuracy= 0.9921, Minibatch error= 0.8%\n",
      "2017-03-30 00:23:58,044 Iter 40, Minibatch Loss= 0.3901, Training Accuracy= 0.9015, Minibatch error= 9.8%\n",
      "2017-03-30 00:24:10,081 Iter 45, Minibatch Loss= 0.2680, Training Accuracy= 0.9636, Minibatch error= 3.6%\n",
      "2017-03-30 00:24:22,256 Iter 50, Minibatch Loss= 0.2567, Training Accuracy= 0.9929, Minibatch error= 0.7%\n",
      "2017-03-30 00:24:34,347 Iter 55, Minibatch Loss= 0.2021, Training Accuracy= 0.9779, Minibatch error= 2.2%\n",
      "2017-03-30 00:24:46,925 Iter 60, Minibatch Loss= 0.8411, Training Accuracy= 0.4650, Minibatch error= 53.5%\n",
      "2017-03-30 00:24:59,137 Iter 65, Minibatch Loss= 0.4414, Training Accuracy= 0.8614, Minibatch error= 13.9%\n",
      "2017-03-30 00:25:11,286 Iter 70, Minibatch Loss= 0.3404, Training Accuracy= 0.9926, Minibatch error= 0.7%\n",
      "2017-03-30 00:25:23,955 Iter 75, Minibatch Loss= 0.2749, Training Accuracy= 0.9921, Minibatch error= 0.8%\n",
      "2017-03-30 00:25:36,810 Iter 80, Minibatch Loss= 0.3456, Training Accuracy= 0.8822, Minibatch error= 11.8%\n",
      "2017-03-30 00:25:49,708 Iter 85, Minibatch Loss= 0.1438, Training Accuracy= 0.9618, Minibatch error= 3.8%\n",
      "2017-03-30 00:26:02,235 Iter 90, Minibatch Loss= 0.3555, Training Accuracy= 0.8926, Minibatch error= 10.7%\n",
      "2017-03-30 00:26:14,768 Iter 95, Minibatch Loss= 0.3993, Training Accuracy= 0.8334, Minibatch error= 16.7%\n",
      "2017-03-30 00:26:24,471 Epoch 0, Average loss: 0.4412, learning rate: 0.0010\n",
      "2017-03-30 00:26:29,037 Verification error= 7.2%, loss= 0.2948\n",
      "2017-03-30 00:26:32,880 Iter 100, Minibatch Loss= 0.2204, Training Accuracy= 0.9930, Minibatch error= 0.7%\n",
      "2017-03-30 00:26:45,897 Iter 105, Minibatch Loss= 0.2282, Training Accuracy= 0.9562, Minibatch error= 4.4%\n",
      "2017-03-30 00:26:58,917 Iter 110, Minibatch Loss= 0.1843, Training Accuracy= 0.9557, Minibatch error= 4.4%\n",
      "2017-03-30 00:27:12,382 Iter 115, Minibatch Loss= 0.5365, Training Accuracy= 0.7585, Minibatch error= 24.1%\n",
      "2017-03-30 00:27:25,413 Iter 120, Minibatch Loss= 0.4464, Training Accuracy= 0.7409, Minibatch error= 25.9%\n",
      "2017-03-30 00:27:37,031 Iter 125, Minibatch Loss= 0.2469, Training Accuracy= 0.9538, Minibatch error= 4.6%\n",
      "2017-03-30 00:27:48,898 Iter 130, Minibatch Loss= 0.2429, Training Accuracy= 0.9286, Minibatch error= 7.1%\n",
      "2017-03-30 00:28:00,407 Iter 135, Minibatch Loss= 0.2175, Training Accuracy= 0.9288, Minibatch error= 7.1%\n",
      "2017-03-30 00:28:11,950 Iter 140, Minibatch Loss= 0.1514, Training Accuracy= 0.9808, Minibatch error= 1.9%\n",
      "2017-03-30 00:28:23,477 Iter 145, Minibatch Loss= 0.1441, Training Accuracy= 0.9758, Minibatch error= 2.4%\n",
      "2017-03-30 00:28:35,339 Iter 150, Minibatch Loss= 0.6026, Training Accuracy= 0.5965, Minibatch error= 40.4%\n",
      "2017-03-30 00:28:47,202 Iter 155, Minibatch Loss= 0.4094, Training Accuracy= 0.7770, Minibatch error= 22.3%\n",
      "2017-03-30 00:28:58,911 Iter 160, Minibatch Loss= 0.2287, Training Accuracy= 0.9378, Minibatch error= 6.2%\n",
      "2017-03-30 00:29:10,527 Iter 165, Minibatch Loss= 0.2010, Training Accuracy= 0.9629, Minibatch error= 3.7%\n",
      "2017-03-30 00:29:22,227 Iter 170, Minibatch Loss= 0.3930, Training Accuracy= 0.7407, Minibatch error= 25.9%\n",
      "2017-03-30 00:29:33,709 Iter 175, Minibatch Loss= 0.2201, Training Accuracy= 0.9450, Minibatch error= 5.5%\n",
      "2017-03-30 00:29:45,245 Iter 180, Minibatch Loss= 0.2005, Training Accuracy= 0.9499, Minibatch error= 5.0%\n",
      "2017-03-30 00:29:56,709 Iter 185, Minibatch Loss= 0.0910, Training Accuracy= 0.9826, Minibatch error= 1.7%\n",
      "2017-03-30 00:30:08,282 Iter 190, Minibatch Loss= 0.1099, Training Accuracy= 0.9551, Minibatch error= 4.5%\n",
      "2017-03-30 00:30:19,835 Iter 195, Minibatch Loss= 0.6779, Training Accuracy= 0.5921, Minibatch error= 40.8%\n",
      "2017-03-30 00:30:28,818 Epoch 1, Average loss: 0.3129, learning rate: 0.0010\n",
      "2017-03-30 00:30:32,956 Verification error= 7.2%, loss= 0.1862\n",
      "2017-03-30 00:30:36,587 Iter 200, Minibatch Loss= 0.1414, Training Accuracy= 0.9713, Minibatch error= 2.9%\n",
      "2017-03-30 00:30:48,568 Iter 205, Minibatch Loss= 0.3369, Training Accuracy= 0.7567, Minibatch error= 24.3%\n",
      "2017-03-30 00:31:00,126 Iter 210, Minibatch Loss= 0.2808, Training Accuracy= 0.9356, Minibatch error= 6.4%\n",
      "2017-03-30 00:31:11,732 Iter 215, Minibatch Loss= 0.3380, Training Accuracy= 0.8576, Minibatch error= 14.2%\n",
      "2017-03-30 00:31:23,374 Iter 220, Minibatch Loss= 0.3043, Training Accuracy= 0.7850, Minibatch error= 21.5%\n",
      "2017-03-30 00:31:35,081 Iter 225, Minibatch Loss= 0.3464, Training Accuracy= 0.7560, Minibatch error= 24.4%\n",
      "2017-03-30 00:31:46,724 Iter 230, Minibatch Loss= 0.3900, Training Accuracy= 0.7774, Minibatch error= 22.3%\n",
      "2017-03-30 00:31:58,445 Iter 235, Minibatch Loss= 0.2240, Training Accuracy= 0.9399, Minibatch error= 6.0%\n",
      "2017-03-30 00:32:10,072 Iter 240, Minibatch Loss= 0.1811, Training Accuracy= 0.8875, Minibatch error= 11.2%\n",
      "2017-03-30 00:32:21,756 Iter 245, Minibatch Loss= 0.2623, Training Accuracy= 0.8191, Minibatch error= 18.1%\n",
      "2017-03-30 00:32:33,630 Iter 250, Minibatch Loss= 0.1088, Training Accuracy= 0.9639, Minibatch error= 3.6%\n",
      "2017-03-30 00:32:45,258 Iter 255, Minibatch Loss= 0.6223, Training Accuracy= 0.5913, Minibatch error= 40.9%\n",
      "2017-03-30 00:32:57,032 Iter 260, Minibatch Loss= 0.7976, Training Accuracy= 0.5820, Minibatch error= 41.8%\n",
      "2017-03-30 00:33:08,970 Iter 265, Minibatch Loss= 0.2126, Training Accuracy= 0.9117, Minibatch error= 8.8%\n",
      "2017-03-30 00:33:20,792 Iter 270, Minibatch Loss= 0.1292, Training Accuracy= 0.9136, Minibatch error= 8.6%\n",
      "2017-03-30 00:33:32,568 Iter 275, Minibatch Loss= 0.1003, Training Accuracy= 0.9690, Minibatch error= 3.1%\n",
      "2017-03-30 00:33:44,408 Iter 280, Minibatch Loss= 0.1682, Training Accuracy= 0.9188, Minibatch error= 8.1%\n",
      "2017-03-30 00:33:56,053 Iter 285, Minibatch Loss= 0.2706, Training Accuracy= 0.7530, Minibatch error= 24.7%\n",
      "2017-03-30 00:34:07,969 Iter 290, Minibatch Loss= 0.0983, Training Accuracy= 0.9719, Minibatch error= 2.8%\n",
      "2017-03-30 00:34:19,862 Iter 295, Minibatch Loss= 0.0811, Training Accuracy= 0.9921, Minibatch error= 0.8%\n",
      "2017-03-30 00:34:28,950 Epoch 2, Average loss: 0.2648, learning rate: 0.0010\n",
      "2017-03-30 00:34:33,242 Verification error= 7.2%, loss= 0.1334\n",
      "2017-03-30 00:34:37,080 Iter 300, Minibatch Loss= 0.1643, Training Accuracy= 0.8711, Minibatch error= 12.9%\n",
      "2017-03-30 00:34:49,117 Iter 305, Minibatch Loss= 0.1904, Training Accuracy= 0.8953, Minibatch error= 10.5%\n",
      "2017-03-30 00:35:01,302 Iter 310, Minibatch Loss= 0.3615, Training Accuracy= 0.8216, Minibatch error= 17.8%\n",
      "2017-03-30 00:35:13,410 Iter 315, Minibatch Loss= 0.5105, Training Accuracy= 0.9116, Minibatch error= 8.8%\n",
      "2017-03-30 00:35:25,415 Iter 320, Minibatch Loss= 0.4161, Training Accuracy= 0.9907, Minibatch error= 0.9%\n",
      "2017-03-30 00:35:37,361 Iter 325, Minibatch Loss= 1.0724, Training Accuracy= 0.6120, Minibatch error= 38.8%\n",
      "2017-03-30 00:35:49,843 Iter 330, Minibatch Loss= 0.3523, Training Accuracy= 0.9664, Minibatch error= 3.4%\n",
      "2017-03-30 00:36:01,796 Iter 335, Minibatch Loss= 0.2937, Training Accuracy= 0.9526, Minibatch error= 4.7%\n",
      "2017-03-30 00:36:13,457 Iter 340, Minibatch Loss= 0.4710, Training Accuracy= 0.8502, Minibatch error= 15.0%\n",
      "2017-03-30 00:36:25,141 Iter 345, Minibatch Loss= 0.2733, Training Accuracy= 0.9772, Minibatch error= 2.3%\n",
      "2017-03-30 00:36:36,830 Iter 350, Minibatch Loss= 0.2957, Training Accuracy= 0.9311, Minibatch error= 6.9%\n",
      "2017-03-30 00:36:48,551 Iter 355, Minibatch Loss= 0.2721, Training Accuracy= 0.9751, Minibatch error= 2.5%\n",
      "2017-03-30 00:37:00,299 Iter 360, Minibatch Loss= 0.4851, Training Accuracy= 0.7764, Minibatch error= 22.4%\n",
      "2017-03-30 00:37:12,147 Iter 365, Minibatch Loss= 0.4243, Training Accuracy= 0.7957, Minibatch error= 20.4%\n",
      "2017-03-30 00:37:24,022 Iter 370, Minibatch Loss= 0.2151, Training Accuracy= 0.9570, Minibatch error= 4.3%\n",
      "2017-03-30 00:37:35,732 Iter 375, Minibatch Loss= 0.3962, Training Accuracy= 0.6528, Minibatch error= 34.7%\n",
      "2017-03-30 00:37:47,598 Iter 380, Minibatch Loss= 0.1792, Training Accuracy= 0.9133, Minibatch error= 8.7%\n",
      "2017-03-30 00:37:59,390 Iter 385, Minibatch Loss= 0.2733, Training Accuracy= 0.9227, Minibatch error= 7.7%\n",
      "2017-03-30 00:38:11,163 Iter 390, Minibatch Loss= 0.0910, Training Accuracy= 0.9918, Minibatch error= 0.8%\n",
      "2017-03-30 00:38:23,322 Iter 395, Minibatch Loss= 0.7865, Training Accuracy= 0.6528, Minibatch error= 34.7%\n",
      "2017-03-30 00:38:32,343 Epoch 3, Average loss: 0.3952, learning rate: 0.0010\n",
      "2017-03-30 00:38:36,525 Verification error= 7.2%, loss= 0.1511\n",
      "2017-03-30 00:38:40,174 Iter 400, Minibatch Loss= 0.2384, Training Accuracy= 0.8270, Minibatch error= 17.3%\n",
      "2017-03-30 00:38:52,159 Iter 405, Minibatch Loss= 0.2125, Training Accuracy= 0.9232, Minibatch error= 7.7%\n",
      "2017-03-30 00:39:03,944 Iter 410, Minibatch Loss= 0.4077, Training Accuracy= 0.4783, Minibatch error= 29.7%\n",
      "2017-03-30 00:39:16,432 Iter 415, Minibatch Loss= 0.3069, Training Accuracy= 0.5422, Minibatch error= 23.5%\n",
      "2017-03-30 00:39:28,564 Iter 420, Minibatch Loss= 0.1608, Training Accuracy= 0.9927, Minibatch error= 0.7%\n",
      "2017-03-30 00:39:40,483 Iter 425, Minibatch Loss= 0.0807, Training Accuracy= 0.9966, Minibatch error= 0.3%\n",
      "2017-03-30 00:39:52,662 Iter 430, Minibatch Loss= 0.1283, Training Accuracy= 0.9941, Minibatch error= 0.6%\n",
      "2017-03-30 00:40:04,722 Iter 435, Minibatch Loss= 0.1492, Training Accuracy= 0.9495, Minibatch error= 5.1%\n",
      "2017-03-30 00:40:16,669 Iter 440, Minibatch Loss= 0.4431, Training Accuracy= 0.6299, Minibatch error= 37.0%\n",
      "2017-03-30 00:40:28,781 Iter 445, Minibatch Loss= 0.2913, Training Accuracy= 0.8925, Minibatch error= 10.8%\n",
      "2017-03-30 00:40:40,620 Iter 450, Minibatch Loss= 0.2359, Training Accuracy= 0.9753, Minibatch error= 2.5%\n",
      "2017-03-30 00:40:52,505 Iter 455, Minibatch Loss= 0.1776, Training Accuracy= 0.8715, Minibatch error= 12.9%\n",
      "2017-03-30 00:41:04,447 Iter 460, Minibatch Loss= 0.4267, Training Accuracy= 0.5530, Minibatch error= 44.7%\n",
      "2017-03-30 00:41:16,384 Iter 465, Minibatch Loss= 0.0927, Training Accuracy= 0.9731, Minibatch error= 2.7%\n",
      "2017-03-30 00:41:28,499 Iter 470, Minibatch Loss= 0.2341, Training Accuracy= 0.7933, Minibatch error= 20.7%\n",
      "2017-03-30 00:41:40,450 Iter 475, Minibatch Loss= 0.1911, Training Accuracy= 0.8845, Minibatch error= 11.6%\n",
      "2017-03-30 00:41:52,366 Iter 480, Minibatch Loss= 0.2646, Training Accuracy= 0.7752, Minibatch error= 22.5%\n",
      "2017-03-30 00:42:04,385 Iter 485, Minibatch Loss= 0.4157, Training Accuracy= 0.8164, Minibatch error= 18.4%\n",
      "2017-03-30 00:42:16,305 Iter 490, Minibatch Loss= 0.2173, Training Accuracy= 0.9156, Minibatch error= 8.4%\n",
      "2017-03-30 00:42:28,305 Iter 495, Minibatch Loss= 0.1622, Training Accuracy= 0.8494, Minibatch error= 15.1%\n",
      "2017-03-30 00:42:37,396 Epoch 4, Average loss: 0.2920, learning rate: 0.0010\n",
      "2017-03-30 00:42:41,600 Verification error= 7.2%, loss= 0.1971\n",
      "2017-03-30 00:42:45,359 Iter 500, Minibatch Loss= 0.1668, Training Accuracy= 0.9790, Minibatch error= 2.1%\n",
      "2017-03-30 00:42:57,685 Iter 505, Minibatch Loss= 0.2105, Training Accuracy= 0.8399, Minibatch error= 16.0%\n",
      "2017-03-30 00:43:09,852 Iter 510, Minibatch Loss= 0.2761, Training Accuracy= 0.8841, Minibatch error= 11.6%\n",
      "2017-03-30 00:43:22,067 Iter 515, Minibatch Loss= 0.0944, Training Accuracy= 0.9931, Minibatch error= 0.7%\n",
      "2017-03-30 00:43:34,107 Iter 520, Minibatch Loss= 0.2331, Training Accuracy= 0.8143, Minibatch error= 18.6%\n",
      "2017-03-30 00:43:46,385 Iter 525, Minibatch Loss= 0.1242, Training Accuracy= 0.9927, Minibatch error= 0.7%\n",
      "2017-03-30 00:43:58,605 Iter 530, Minibatch Loss= 0.2297, Training Accuracy= 0.8710, Minibatch error= 12.9%\n",
      "2017-03-30 00:44:10,598 Iter 535, Minibatch Loss= 0.2361, Training Accuracy= 0.8640, Minibatch error= 13.6%\n",
      "2017-03-30 00:44:22,807 Iter 540, Minibatch Loss= 0.1705, Training Accuracy= 0.9494, Minibatch error= 5.1%\n",
      "2017-03-30 00:44:35,054 Iter 545, Minibatch Loss= 0.2889, Training Accuracy= 0.8177, Minibatch error= 18.2%\n",
      "2017-03-30 00:44:47,505 Iter 550, Minibatch Loss= 0.2252, Training Accuracy= 0.7558, Minibatch error= 24.4%\n",
      "2017-03-30 00:44:59,817 Iter 555, Minibatch Loss= 0.2785, Training Accuracy= 0.7329, Minibatch error= 26.7%\n",
      "2017-03-30 00:45:12,158 Iter 560, Minibatch Loss= 0.3284, Training Accuracy= 0.9197, Minibatch error= 8.0%\n",
      "2017-03-30 00:45:24,506 Iter 565, Minibatch Loss= 0.3614, Training Accuracy= 0.7399, Minibatch error= 26.0%\n",
      "2017-03-30 00:45:36,827 Iter 570, Minibatch Loss= 0.3245, Training Accuracy= 0.8336, Minibatch error= 16.6%\n",
      "2017-03-30 00:45:49,270 Iter 575, Minibatch Loss= 0.9644, Training Accuracy= 0.6497, Minibatch error= 35.0%\n",
      "2017-03-30 00:46:01,915 Iter 580, Minibatch Loss= 0.2324, Training Accuracy= 0.9874, Minibatch error= 1.3%\n",
      "2017-03-30 00:46:14,454 Iter 585, Minibatch Loss= 0.1569, Training Accuracy= 0.9385, Minibatch error= 6.2%\n",
      "2017-03-30 00:46:27,068 Iter 590, Minibatch Loss= 0.3329, Training Accuracy= 0.9630, Minibatch error= 3.7%\n",
      "2017-03-30 00:46:39,578 Iter 595, Minibatch Loss= 1.1211, Training Accuracy= 0.4790, Minibatch error= 52.1%\n",
      "2017-03-30 00:46:49,165 Epoch 5, Average loss: 0.2831, learning rate: 0.0010\n",
      "2017-03-30 00:46:53,514 Verification error= 7.8%, loss= 0.1765\n",
      "2017-03-30 00:46:57,465 Iter 600, Minibatch Loss= 0.1574, Training Accuracy= 0.9511, Minibatch error= 4.9%\n",
      "2017-03-30 00:47:10,137 Iter 605, Minibatch Loss= 0.3603, Training Accuracy= 0.7924, Minibatch error= 20.8%\n",
      "2017-03-30 00:47:22,719 Iter 610, Minibatch Loss= 0.6339, Training Accuracy= 0.7794, Minibatch error= 22.1%\n",
      "2017-03-30 00:47:35,411 Iter 615, Minibatch Loss= 0.2116, Training Accuracy= 0.9413, Minibatch error= 5.9%\n",
      "2017-03-30 00:47:48,073 Iter 620, Minibatch Loss= 0.3122, Training Accuracy= 0.8291, Minibatch error= 17.1%\n",
      "2017-03-30 00:48:00,626 Iter 625, Minibatch Loss= 0.1872, Training Accuracy= 0.9491, Minibatch error= 5.1%\n",
      "2017-03-30 00:48:13,398 Iter 630, Minibatch Loss= 0.7244, Training Accuracy= 0.6772, Minibatch error= 32.3%\n",
      "2017-03-30 00:48:25,332 Iter 635, Minibatch Loss= 0.1591, Training Accuracy= 0.9379, Minibatch error= 6.2%\n",
      "2017-03-30 00:48:36,436 Iter 640, Minibatch Loss= 0.2722, Training Accuracy= 0.8812, Minibatch error= 11.9%\n",
      "2017-03-30 00:48:47,390 Iter 645, Minibatch Loss= 0.2416, Training Accuracy= 0.9193, Minibatch error= 8.1%\n",
      "2017-03-30 00:48:58,419 Iter 650, Minibatch Loss= 0.1475, Training Accuracy= 0.9465, Minibatch error= 5.3%\n",
      "2017-03-30 00:49:09,415 Iter 655, Minibatch Loss= 0.2831, Training Accuracy= 0.8596, Minibatch error= 14.0%\n",
      "2017-03-30 00:49:20,500 Iter 660, Minibatch Loss= 0.1084, Training Accuracy= 0.9834, Minibatch error= 1.7%\n",
      "2017-03-30 00:49:31,548 Iter 665, Minibatch Loss= 0.1396, Training Accuracy= 0.9420, Minibatch error= 5.8%\n",
      "2017-03-30 00:49:42,589 Iter 670, Minibatch Loss= 0.0573, Training Accuracy= 0.9801, Minibatch error= 2.0%\n",
      "2017-03-30 00:49:53,614 Iter 675, Minibatch Loss= 0.0883, Training Accuracy= 0.9908, Minibatch error= 0.9%\n",
      "2017-03-30 00:50:04,590 Iter 680, Minibatch Loss= 0.4672, Training Accuracy= 0.6803, Minibatch error= 32.0%\n",
      "2017-03-30 00:50:15,553 Iter 685, Minibatch Loss= 0.2095, Training Accuracy= 0.8892, Minibatch error= 11.1%\n",
      "2017-03-30 00:50:26,463 Iter 690, Minibatch Loss= 0.2325, Training Accuracy= 0.9609, Minibatch error= 3.9%\n",
      "2017-03-30 00:50:37,401 Iter 695, Minibatch Loss= 0.1934, Training Accuracy= 0.9437, Minibatch error= 5.6%\n",
      "2017-03-30 00:50:45,719 Epoch 6, Average loss: 0.2418, learning rate: 0.0010\n",
      "2017-03-30 00:50:49,491 Verification error= 7.4%, loss= 0.1452\n",
      "2017-03-30 00:50:53,042 Iter 700, Minibatch Loss= 0.1109, Training Accuracy= 0.9786, Minibatch error= 2.1%\n",
      "2017-03-30 00:51:04,193 Iter 705, Minibatch Loss= 0.6254, Training Accuracy= 0.6900, Minibatch error= 31.0%\n",
      "2017-03-30 00:51:15,506 Iter 710, Minibatch Loss= 0.1646, Training Accuracy= 0.9588, Minibatch error= 4.1%\n",
      "2017-03-30 00:51:26,646 Iter 715, Minibatch Loss= 0.2228, Training Accuracy= 0.9029, Minibatch error= 9.7%\n",
      "2017-03-30 00:51:37,967 Iter 720, Minibatch Loss= 0.1444, Training Accuracy= 0.9624, Minibatch error= 3.8%\n",
      "2017-03-30 00:51:49,450 Iter 725, Minibatch Loss= 0.1904, Training Accuracy= 0.9556, Minibatch error= 4.4%\n",
      "2017-03-30 00:52:00,902 Iter 730, Minibatch Loss= 0.1164, Training Accuracy= 0.9639, Minibatch error= 3.6%\n",
      "2017-03-30 00:52:12,412 Iter 735, Minibatch Loss= 0.1485, Training Accuracy= 0.9668, Minibatch error= 3.3%\n",
      "2017-03-30 00:52:23,921 Iter 740, Minibatch Loss= 0.3797, Training Accuracy= 0.9067, Minibatch error= 9.3%\n",
      "2017-03-30 00:52:35,454 Iter 745, Minibatch Loss= 0.1094, Training Accuracy= 0.9620, Minibatch error= 3.8%\n",
      "2017-03-30 00:52:46,992 Iter 750, Minibatch Loss= 0.0834, Training Accuracy= 0.9829, Minibatch error= 1.7%\n",
      "2017-03-30 00:52:58,342 Iter 755, Minibatch Loss= 0.0511, Training Accuracy= 0.9795, Minibatch error= 2.0%\n",
      "2017-03-30 00:53:09,766 Iter 760, Minibatch Loss= 0.1106, Training Accuracy= 0.9858, Minibatch error= 1.4%\n",
      "2017-03-30 00:53:21,350 Iter 765, Minibatch Loss= 0.0415, Training Accuracy= 0.9929, Minibatch error= 0.7%\n",
      "2017-03-30 00:53:32,793 Iter 770, Minibatch Loss= 0.2636, Training Accuracy= 0.8626, Minibatch error= 13.7%\n",
      "2017-03-30 00:53:44,378 Iter 775, Minibatch Loss= 0.3059, Training Accuracy= 0.8107, Minibatch error= 18.9%\n",
      "2017-03-30 00:53:55,806 Iter 780, Minibatch Loss= 0.2028, Training Accuracy= 0.9565, Minibatch error= 4.3%\n",
      "2017-03-30 00:54:07,289 Iter 785, Minibatch Loss= 0.2417, Training Accuracy= 0.9249, Minibatch error= 7.5%\n",
      "2017-03-30 00:54:18,766 Iter 790, Minibatch Loss= 0.2819, Training Accuracy= 0.8684, Minibatch error= 13.2%\n",
      "2017-03-30 00:54:30,323 Iter 795, Minibatch Loss= 0.2262, Training Accuracy= 0.9115, Minibatch error= 8.9%\n",
      "2017-03-30 00:54:39,290 Epoch 7, Average loss: 0.2502, learning rate: 0.0010\n",
      "2017-03-30 00:54:43,342 Verification error= 7.7%, loss= 0.1851\n",
      "2017-03-30 00:54:47,130 Iter 800, Minibatch Loss= 0.4526, Training Accuracy= 0.7183, Minibatch error= 28.2%\n",
      "2017-03-30 00:54:58,971 Iter 805, Minibatch Loss= 0.2461, Training Accuracy= 0.9461, Minibatch error= 5.4%\n",
      "2017-03-30 00:55:10,720 Iter 810, Minibatch Loss= 0.1613, Training Accuracy= 0.9239, Minibatch error= 7.6%\n",
      "2017-03-30 00:55:22,490 Iter 815, Minibatch Loss= 0.0831, Training Accuracy= 0.9816, Minibatch error= 1.8%\n",
      "2017-03-30 00:55:34,359 Iter 820, Minibatch Loss= 0.5671, Training Accuracy= 0.7894, Minibatch error= 21.1%\n",
      "2017-03-30 00:55:46,410 Iter 825, Minibatch Loss= 0.1447, Training Accuracy= 0.9722, Minibatch error= 2.8%\n",
      "2017-03-30 00:55:58,247 Iter 830, Minibatch Loss= 0.1651, Training Accuracy= 0.9465, Minibatch error= 5.4%\n",
      "2017-03-30 00:56:10,159 Iter 835, Minibatch Loss= 0.2377, Training Accuracy= 0.9384, Minibatch error= 6.2%\n",
      "2017-03-30 00:56:21,975 Iter 840, Minibatch Loss= 0.1285, Training Accuracy= 0.9741, Minibatch error= 2.6%\n",
      "2017-03-30 00:56:33,794 Iter 845, Minibatch Loss= 0.0902, Training Accuracy= 0.9932, Minibatch error= 0.7%\n",
      "2017-03-30 00:56:45,756 Iter 850, Minibatch Loss= 0.1140, Training Accuracy= 0.9713, Minibatch error= 2.9%\n",
      "2017-03-30 00:56:57,671 Iter 855, Minibatch Loss= 0.1667, Training Accuracy= 0.9524, Minibatch error= 4.8%\n",
      "2017-03-30 00:57:09,845 Iter 860, Minibatch Loss= 0.1093, Training Accuracy= 0.9751, Minibatch error= 2.5%\n",
      "2017-03-30 00:57:22,154 Iter 865, Minibatch Loss= 0.0637, Training Accuracy= 0.9758, Minibatch error= 2.4%\n",
      "2017-03-30 00:57:34,424 Iter 870, Minibatch Loss= 0.7331, Training Accuracy= 0.7865, Minibatch error= 21.4%\n",
      "2017-03-30 00:57:46,653 Iter 875, Minibatch Loss= 0.0517, Training Accuracy= 0.9970, Minibatch error= 0.3%\n",
      "2017-03-30 00:57:58,909 Iter 880, Minibatch Loss= 0.1194, Training Accuracy= 0.9749, Minibatch error= 2.5%\n",
      "2017-03-30 00:58:11,265 Iter 885, Minibatch Loss= 0.0982, Training Accuracy= 0.9689, Minibatch error= 3.1%\n",
      "2017-03-30 00:58:23,525 Iter 890, Minibatch Loss= 0.2710, Training Accuracy= 0.8633, Minibatch error= 13.7%\n",
      "2017-03-30 00:58:35,730 Iter 895, Minibatch Loss= 0.3260, Training Accuracy= 0.8100, Minibatch error= 19.0%\n",
      "2017-03-30 00:58:45,124 Epoch 8, Average loss: 0.2364, learning rate: 0.0010\n",
      "2017-03-30 00:58:49,349 Verification error= 6.1%, loss= 0.1380\n",
      "2017-03-30 00:58:53,225 Iter 900, Minibatch Loss= 0.2108, Training Accuracy= 0.9473, Minibatch error= 5.3%\n",
      "2017-03-30 00:59:05,677 Iter 905, Minibatch Loss= 0.5258, Training Accuracy= 0.7262, Minibatch error= 27.4%\n",
      "2017-03-30 00:59:17,931 Iter 910, Minibatch Loss= 0.1164, Training Accuracy= 0.9743, Minibatch error= 2.6%\n",
      "2017-03-30 00:59:30,213 Iter 915, Minibatch Loss= 0.1695, Training Accuracy= 0.9456, Minibatch error= 5.4%\n",
      "2017-03-30 00:59:42,559 Iter 920, Minibatch Loss= 0.3500, Training Accuracy= 0.8358, Minibatch error= 16.4%\n",
      "2017-03-30 00:59:54,908 Iter 925, Minibatch Loss= 0.2288, Training Accuracy= 0.9313, Minibatch error= 6.9%\n",
      "2017-03-30 01:00:07,299 Iter 930, Minibatch Loss= 0.3909, Training Accuracy= 0.8425, Minibatch error= 15.8%\n",
      "2017-03-30 01:00:19,663 Iter 935, Minibatch Loss= 0.2292, Training Accuracy= 0.9179, Minibatch error= 8.2%\n",
      "2017-03-30 01:00:31,999 Iter 940, Minibatch Loss= 0.0861, Training Accuracy= 0.9948, Minibatch error= 0.5%\n",
      "2017-03-30 01:00:44,432 Iter 945, Minibatch Loss= 0.1437, Training Accuracy= 0.9186, Minibatch error= 8.1%\n",
      "2017-03-30 01:00:56,865 Iter 950, Minibatch Loss= 0.1241, Training Accuracy= 0.9405, Minibatch error= 5.9%\n",
      "2017-03-30 01:01:09,304 Iter 955, Minibatch Loss= 0.4568, Training Accuracy= 0.8444, Minibatch error= 15.6%\n",
      "2017-03-30 01:01:21,762 Iter 960, Minibatch Loss= 0.1853, Training Accuracy= 0.9629, Minibatch error= 3.7%\n",
      "2017-03-30 01:01:34,016 Iter 965, Minibatch Loss= 0.4296, Training Accuracy= 0.7436, Minibatch error= 25.6%\n",
      "2017-03-30 01:01:46,450 Iter 970, Minibatch Loss= 0.1957, Training Accuracy= 0.9443, Minibatch error= 5.6%\n",
      "2017-03-30 01:01:58,807 Iter 975, Minibatch Loss= 0.1708, Training Accuracy= 0.9570, Minibatch error= 4.3%\n",
      "2017-03-30 01:02:11,011 Iter 980, Minibatch Loss= 0.1454, Training Accuracy= 0.9590, Minibatch error= 4.1%\n",
      "2017-03-30 01:02:23,354 Iter 985, Minibatch Loss= 0.2429, Training Accuracy= 0.8683, Minibatch error= 13.2%\n",
      "2017-03-30 01:02:35,707 Iter 990, Minibatch Loss= 0.4984, Training Accuracy= 0.7280, Minibatch error= 27.2%\n",
      "2017-03-30 01:02:48,076 Iter 995, Minibatch Loss= 0.1531, Training Accuracy= 0.9548, Minibatch error= 4.5%\n",
      "2017-03-30 01:02:57,527 Epoch 9, Average loss: 0.2729, learning rate: 0.0010\n",
      "2017-03-30 01:03:01,708 Verification error= 8.0%, loss= 0.1494\n",
      "2017-03-30 01:03:05,740 Iter 1000, Minibatch Loss= 0.0690, Training Accuracy= 0.9986, Minibatch error= 0.1%\n",
      "2017-03-30 01:03:18,241 Iter 1005, Minibatch Loss= 0.2726, Training Accuracy= 0.9045, Minibatch error= 9.6%\n",
      "2017-03-30 01:03:30,542 Iter 1010, Minibatch Loss= 0.1446, Training Accuracy= 0.9519, Minibatch error= 4.8%\n",
      "2017-03-30 01:03:44,041 Iter 1015, Minibatch Loss= 0.0703, Training Accuracy= 0.9929, Minibatch error= 0.7%\n",
      "2017-03-30 01:03:57,218 Iter 1020, Minibatch Loss= 0.0992, Training Accuracy= 0.9803, Minibatch error= 2.0%\n",
      "2017-03-30 01:04:09,525 Iter 1025, Minibatch Loss= 0.2167, Training Accuracy= 0.9268, Minibatch error= 7.3%\n",
      "2017-03-30 01:04:21,873 Iter 1030, Minibatch Loss= 0.1223, Training Accuracy= 0.9670, Minibatch error= 3.3%\n",
      "2017-03-30 01:04:34,454 Iter 1035, Minibatch Loss= 0.0670, Training Accuracy= 0.9797, Minibatch error= 2.0%\n",
      "2017-03-30 01:04:46,689 Iter 1040, Minibatch Loss= 0.0379, Training Accuracy= 0.9954, Minibatch error= 0.5%\n",
      "2017-03-30 01:04:58,890 Iter 1045, Minibatch Loss= 0.3429, Training Accuracy= 0.8102, Minibatch error= 19.0%\n",
      "2017-03-30 01:05:11,044 Iter 1050, Minibatch Loss= 0.0523, Training Accuracy= 0.9934, Minibatch error= 0.7%\n",
      "2017-03-30 01:05:23,163 Iter 1055, Minibatch Loss= 0.0849, Training Accuracy= 0.9897, Minibatch error= 1.0%\n",
      "2017-03-30 01:05:35,291 Iter 1060, Minibatch Loss= 0.1732, Training Accuracy= 0.9780, Minibatch error= 2.2%\n",
      "2017-03-30 01:05:47,726 Iter 1065, Minibatch Loss= 0.2151, Training Accuracy= 0.9462, Minibatch error= 5.4%\n",
      "2017-03-30 01:06:00,223 Iter 1070, Minibatch Loss= 0.2750, Training Accuracy= 0.9184, Minibatch error= 8.2%\n",
      "2017-03-30 01:06:12,682 Iter 1075, Minibatch Loss= 0.1848, Training Accuracy= 0.9687, Minibatch error= 3.1%\n",
      "2017-03-30 01:06:25,153 Iter 1080, Minibatch Loss= 0.3582, Training Accuracy= 0.8431, Minibatch error= 15.7%\n",
      "2017-03-30 01:06:37,499 Iter 1085, Minibatch Loss= 0.2505, Training Accuracy= 0.9257, Minibatch error= 7.4%\n",
      "2017-03-30 01:06:49,988 Iter 1090, Minibatch Loss= 0.2339, Training Accuracy= 0.9256, Minibatch error= 7.4%\n",
      "2017-03-30 01:07:02,486 Iter 1095, Minibatch Loss= 0.0544, Training Accuracy= 0.9980, Minibatch error= 0.2%\n",
      "2017-03-30 01:07:12,072 Epoch 10, Average loss: 0.2483, learning rate: 0.0010\n",
      "2017-03-30 01:07:16,334 Verification error= 7.3%, loss= 0.1471\n",
      "2017-03-30 01:07:20,480 Iter 1100, Minibatch Loss= 0.0964, Training Accuracy= 0.9946, Minibatch error= 0.5%\n",
      "2017-03-30 01:07:33,073 Iter 1105, Minibatch Loss= 0.0889, Training Accuracy= 0.9693, Minibatch error= 3.1%\n",
      "2017-03-30 01:07:45,718 Iter 1110, Minibatch Loss= 0.1538, Training Accuracy= 0.9484, Minibatch error= 5.2%\n",
      "2017-03-30 01:07:58,317 Iter 1115, Minibatch Loss= 0.2500, Training Accuracy= 0.9164, Minibatch error= 8.4%\n",
      "2017-03-30 01:08:10,855 Iter 1120, Minibatch Loss= 0.1428, Training Accuracy= 0.9735, Minibatch error= 2.7%\n",
      "2017-03-30 01:08:23,441 Iter 1125, Minibatch Loss= 0.1386, Training Accuracy= 0.9846, Minibatch error= 1.5%\n",
      "2017-03-30 01:08:36,058 Iter 1130, Minibatch Loss= 0.4605, Training Accuracy= 0.7612, Minibatch error= 23.9%\n",
      "2017-03-30 01:08:48,659 Iter 1135, Minibatch Loss= 0.1625, Training Accuracy= 0.9702, Minibatch error= 3.0%\n",
      "2017-03-30 01:09:01,219 Iter 1140, Minibatch Loss= 0.0761, Training Accuracy= 0.9967, Minibatch error= 0.3%\n",
      "2017-03-30 01:09:13,956 Iter 1145, Minibatch Loss= 0.0859, Training Accuracy= 0.9812, Minibatch error= 1.9%\n",
      "2017-03-30 01:09:26,663 Iter 1150, Minibatch Loss= 0.1367, Training Accuracy= 0.9650, Minibatch error= 3.5%\n",
      "2017-03-30 01:09:39,308 Iter 1155, Minibatch Loss= 0.3031, Training Accuracy= 0.8438, Minibatch error= 15.6%\n",
      "2017-03-30 01:09:51,974 Iter 1160, Minibatch Loss= 0.1149, Training Accuracy= 0.9788, Minibatch error= 2.1%\n",
      "2017-03-30 01:10:04,718 Iter 1165, Minibatch Loss= 0.2501, Training Accuracy= 0.8709, Minibatch error= 12.9%\n",
      "2017-03-30 01:10:17,287 Iter 1170, Minibatch Loss= 0.1322, Training Accuracy= 0.9802, Minibatch error= 2.0%\n",
      "2017-03-30 01:10:29,986 Iter 1175, Minibatch Loss= 0.2904, Training Accuracy= 0.9005, Minibatch error= 10.0%\n",
      "2017-03-30 01:10:42,663 Iter 1180, Minibatch Loss= 0.0475, Training Accuracy= 0.9985, Minibatch error= 0.2%\n",
      "2017-03-30 01:10:55,280 Iter 1185, Minibatch Loss= 0.6606, Training Accuracy= 0.7818, Minibatch error= 21.8%\n",
      "2017-03-30 01:11:07,857 Iter 1190, Minibatch Loss= 0.1944, Training Accuracy= 0.9148, Minibatch error= 8.5%\n",
      "2017-03-30 01:11:20,577 Iter 1195, Minibatch Loss= 0.1002, Training Accuracy= 0.9848, Minibatch error= 1.5%\n",
      "2017-03-30 01:11:30,274 Epoch 11, Average loss: 0.2644, learning rate: 0.0010\n",
      "2017-03-30 01:11:34,613 Verification error= 7.8%, loss= 0.1793\n",
      "2017-03-30 01:11:38,788 Iter 1200, Minibatch Loss= 0.1130, Training Accuracy= 0.9945, Minibatch error= 0.6%\n",
      "2017-03-30 01:11:51,818 Iter 1205, Minibatch Loss= 0.1481, Training Accuracy= 0.9722, Minibatch error= 2.8%\n",
      "2017-03-30 01:12:04,606 Iter 1210, Minibatch Loss= 0.6582, Training Accuracy= 0.6708, Minibatch error= 32.9%\n",
      "2017-03-30 01:12:17,366 Iter 1215, Minibatch Loss= 0.1447, Training Accuracy= 0.9714, Minibatch error= 2.9%\n",
      "2017-03-30 01:12:30,068 Iter 1220, Minibatch Loss= 0.2464, Training Accuracy= 0.8954, Minibatch error= 10.5%\n",
      "2017-03-30 01:12:42,783 Iter 1225, Minibatch Loss= 0.5615, Training Accuracy= 0.7255, Minibatch error= 27.4%\n",
      "2017-03-30 01:12:55,482 Iter 1230, Minibatch Loss= 0.2463, Training Accuracy= 0.8868, Minibatch error= 11.3%\n",
      "2017-03-30 01:13:08,232 Iter 1235, Minibatch Loss= 0.1293, Training Accuracy= 0.9724, Minibatch error= 2.8%\n",
      "2017-03-30 01:13:21,047 Iter 1240, Minibatch Loss= 0.1224, Training Accuracy= 0.9911, Minibatch error= 0.9%\n",
      "2017-03-30 01:13:33,805 Iter 1245, Minibatch Loss= 0.1833, Training Accuracy= 0.9037, Minibatch error= 9.6%\n",
      "2017-03-30 01:13:46,612 Iter 1250, Minibatch Loss= 0.0793, Training Accuracy= 0.9898, Minibatch error= 1.0%\n",
      "2017-03-30 01:13:59,363 Iter 1255, Minibatch Loss= 0.0529, Training Accuracy= 0.9840, Minibatch error= 1.6%\n",
      "2017-03-30 01:14:11,964 Iter 1260, Minibatch Loss= 0.0841, Training Accuracy= 0.9747, Minibatch error= 2.5%\n",
      "2017-03-30 01:14:24,764 Iter 1265, Minibatch Loss= 0.1110, Training Accuracy= 0.9698, Minibatch error= 3.0%\n",
      "2017-03-30 01:14:37,542 Iter 1270, Minibatch Loss= 0.1006, Training Accuracy= 0.9858, Minibatch error= 1.4%\n",
      "2017-03-30 01:14:50,273 Iter 1275, Minibatch Loss= 0.2786, Training Accuracy= 0.9238, Minibatch error= 7.6%\n",
      "2017-03-30 01:15:02,976 Iter 1280, Minibatch Loss= 0.1851, Training Accuracy= 0.9853, Minibatch error= 1.5%\n",
      "2017-03-30 01:15:15,822 Iter 1285, Minibatch Loss= 0.2673, Training Accuracy= 0.9250, Minibatch error= 7.5%\n",
      "2017-03-30 01:15:28,631 Iter 1290, Minibatch Loss= 0.0779, Training Accuracy= 0.9883, Minibatch error= 1.2%\n",
      "2017-03-30 01:15:41,275 Iter 1295, Minibatch Loss= 0.3820, Training Accuracy= 0.7634, Minibatch error= 23.7%\n",
      "2017-03-30 01:15:51,219 Epoch 12, Average loss: 0.2500, learning rate: 0.0010\n",
      "2017-03-30 01:15:55,480 Verification error= 8.1%, loss= 0.1549\n",
      "2017-03-30 01:15:59,728 Iter 1300, Minibatch Loss= 0.0553, Training Accuracy= 0.9962, Minibatch error= 0.4%\n",
      "2017-03-30 01:16:12,656 Iter 1305, Minibatch Loss= 0.0887, Training Accuracy= 0.9867, Minibatch error= 1.3%\n",
      "2017-03-30 01:16:25,603 Iter 1310, Minibatch Loss= 0.2688, Training Accuracy= 0.8571, Minibatch error= 14.3%\n",
      "2017-03-30 01:16:38,543 Iter 1315, Minibatch Loss= 0.6726, Training Accuracy= 0.7595, Minibatch error= 24.1%\n",
      "2017-03-30 01:16:51,446 Iter 1320, Minibatch Loss= 0.0843, Training Accuracy= 0.9792, Minibatch error= 2.1%\n",
      "2017-03-30 01:17:04,282 Iter 1325, Minibatch Loss= 0.0839, Training Accuracy= 0.9706, Minibatch error= 2.9%\n",
      "2017-03-30 01:17:16,950 Iter 1330, Minibatch Loss= 0.2227, Training Accuracy= 0.8929, Minibatch error= 10.7%\n",
      "2017-03-30 01:17:29,699 Iter 1335, Minibatch Loss= 0.0861, Training Accuracy= 0.9755, Minibatch error= 2.4%\n",
      "2017-03-30 01:17:42,475 Iter 1340, Minibatch Loss= 0.0843, Training Accuracy= 0.9725, Minibatch error= 2.7%\n",
      "2017-03-30 01:17:55,350 Iter 1345, Minibatch Loss= 0.0949, Training Accuracy= 0.9719, Minibatch error= 2.8%\n",
      "2017-03-30 01:18:08,194 Iter 1350, Minibatch Loss= 0.0694, Training Accuracy= 0.9873, Minibatch error= 1.3%\n",
      "2017-03-30 01:18:21,005 Iter 1355, Minibatch Loss= 0.1998, Training Accuracy= 0.8936, Minibatch error= 10.6%\n",
      "2017-03-30 01:18:33,839 Iter 1360, Minibatch Loss= 0.3972, Training Accuracy= 0.8528, Minibatch error= 14.7%\n",
      "2017-03-30 01:18:46,652 Iter 1365, Minibatch Loss= 0.3764, Training Accuracy= 0.7650, Minibatch error= 23.5%\n",
      "2017-03-30 01:18:59,485 Iter 1370, Minibatch Loss= 0.1160, Training Accuracy= 0.9536, Minibatch error= 4.6%\n",
      "2017-03-30 01:19:12,329 Iter 1375, Minibatch Loss= 0.0970, Training Accuracy= 0.9768, Minibatch error= 2.3%\n",
      "2017-03-30 01:19:25,154 Iter 1380, Minibatch Loss= 0.1728, Training Accuracy= 0.9607, Minibatch error= 3.9%\n",
      "2017-03-30 01:19:37,974 Iter 1385, Minibatch Loss= 0.2211, Training Accuracy= 0.9260, Minibatch error= 7.4%\n",
      "2017-03-30 01:19:50,809 Iter 1390, Minibatch Loss= 0.1532, Training Accuracy= 0.9817, Minibatch error= 1.8%\n",
      "2017-03-30 01:20:03,741 Iter 1395, Minibatch Loss= 0.7020, Training Accuracy= 0.6086, Minibatch error= 39.1%\n",
      "2017-03-30 01:20:13,539 Epoch 13, Average loss: 0.2190, learning rate: 0.0010\n",
      "2017-03-30 01:20:17,825 Verification error= 7.9%, loss= 0.1639\n",
      "2017-03-30 01:20:22,198 Iter 1400, Minibatch Loss= 0.2542, Training Accuracy= 0.8927, Minibatch error= 10.7%\n",
      "2017-03-30 01:20:35,155 Iter 1405, Minibatch Loss= 0.2530, Training Accuracy= 0.9120, Minibatch error= 8.8%\n",
      "2017-03-30 01:20:48,080 Iter 1410, Minibatch Loss= 0.1879, Training Accuracy= 0.9583, Minibatch error= 4.2%\n",
      "2017-03-30 01:21:00,965 Iter 1415, Minibatch Loss= 0.2229, Training Accuracy= 0.9307, Minibatch error= 6.9%\n",
      "2017-03-30 01:21:13,896 Iter 1420, Minibatch Loss= 0.1144, Training Accuracy= 0.9799, Minibatch error= 2.0%\n",
      "2017-03-30 01:21:26,913 Iter 1425, Minibatch Loss= 0.2235, Training Accuracy= 0.9333, Minibatch error= 6.7%\n",
      "2017-03-30 01:21:40,058 Iter 1430, Minibatch Loss= 0.0996, Training Accuracy= 0.9884, Minibatch error= 1.2%\n",
      "2017-03-30 01:21:52,970 Iter 1435, Minibatch Loss= 0.0531, Training Accuracy= 0.9953, Minibatch error= 0.5%\n",
      "2017-03-30 01:22:05,944 Iter 1440, Minibatch Loss= 0.2100, Training Accuracy= 0.9355, Minibatch error= 6.4%\n",
      "2017-03-30 01:22:18,957 Iter 1445, Minibatch Loss= 0.2111, Training Accuracy= 0.9441, Minibatch error= 5.6%\n",
      "2017-03-30 01:22:31,862 Iter 1450, Minibatch Loss= 0.1539, Training Accuracy= 0.9981, Minibatch error= 0.2%\n",
      "2017-03-30 01:22:44,828 Iter 1455, Minibatch Loss= 0.7592, Training Accuracy= 0.5840, Minibatch error= 41.6%\n",
      "2017-03-30 01:22:57,747 Iter 1460, Minibatch Loss= 0.2144, Training Accuracy= 0.9192, Minibatch error= 8.1%\n",
      "2017-03-30 01:23:10,890 Iter 1465, Minibatch Loss= 0.1056, Training Accuracy= 0.9801, Minibatch error= 2.0%\n",
      "2017-03-30 01:23:23,888 Iter 1470, Minibatch Loss= 0.0919, Training Accuracy= 0.9809, Minibatch error= 1.9%\n",
      "2017-03-30 01:23:36,861 Iter 1475, Minibatch Loss= 0.0743, Training Accuracy= 0.9894, Minibatch error= 1.1%\n",
      "2017-03-30 01:23:49,759 Iter 1480, Minibatch Loss= 0.0987, Training Accuracy= 0.9758, Minibatch error= 2.4%\n",
      "2017-03-30 01:24:02,854 Iter 1485, Minibatch Loss= 0.2617, Training Accuracy= 0.8621, Minibatch error= 13.8%\n",
      "2017-03-30 01:24:15,838 Iter 1490, Minibatch Loss= 0.1056, Training Accuracy= 0.9874, Minibatch error= 1.3%\n",
      "2017-03-30 01:24:28,769 Iter 1495, Minibatch Loss= 0.1408, Training Accuracy= 0.9561, Minibatch error= 4.4%\n",
      "2017-03-30 01:24:38,730 Epoch 14, Average loss: 0.2320, learning rate: 0.0010\n",
      "2017-03-30 01:24:42,983 Verification error= 6.7%, loss= 0.1305\n",
      "2017-03-30 01:24:47,571 Iter 1500, Minibatch Loss= 0.2985, Training Accuracy= 0.8956, Minibatch error= 10.4%\n",
      "2017-03-30 01:25:00,581 Iter 1505, Minibatch Loss= 0.0612, Training Accuracy= 0.9836, Minibatch error= 1.6%\n",
      "2017-03-30 01:25:13,679 Iter 1510, Minibatch Loss= 0.0611, Training Accuracy= 0.9899, Minibatch error= 1.0%\n",
      "2017-03-30 01:25:26,745 Iter 1515, Minibatch Loss= 0.2054, Training Accuracy= 0.9246, Minibatch error= 7.5%\n",
      "2017-03-30 01:25:39,880 Iter 1520, Minibatch Loss= 0.1975, Training Accuracy= 0.8882, Minibatch error= 11.2%\n",
      "2017-03-30 01:25:52,984 Iter 1525, Minibatch Loss= 0.3098, Training Accuracy= 0.8787, Minibatch error= 12.1%\n",
      "2017-03-30 01:26:06,052 Iter 1530, Minibatch Loss= 0.1332, Training Accuracy= 0.9397, Minibatch error= 6.0%\n",
      "2017-03-30 01:26:19,214 Iter 1535, Minibatch Loss= 0.4664, Training Accuracy= 0.8057, Minibatch error= 19.4%\n",
      "2017-03-30 01:26:32,492 Iter 1540, Minibatch Loss= 0.0759, Training Accuracy= 0.9864, Minibatch error= 1.4%\n",
      "2017-03-30 01:26:45,430 Iter 1545, Minibatch Loss= 0.6232, Training Accuracy= 0.7145, Minibatch error= 28.6%\n",
      "2017-03-30 01:26:58,407 Iter 1550, Minibatch Loss= 0.5485, Training Accuracy= 0.6644, Minibatch error= 33.6%\n",
      "2017-03-30 01:27:11,480 Iter 1555, Minibatch Loss= 0.2392, Training Accuracy= 0.9352, Minibatch error= 6.5%\n",
      "2017-03-30 01:27:24,582 Iter 1560, Minibatch Loss= 0.3110, Training Accuracy= 0.8081, Minibatch error= 19.2%\n",
      "2017-03-30 01:27:37,610 Iter 1565, Minibatch Loss= 0.0983, Training Accuracy= 0.9909, Minibatch error= 0.9%\n",
      "2017-03-30 01:27:50,708 Iter 1570, Minibatch Loss= 0.1186, Training Accuracy= 0.9951, Minibatch error= 0.5%\n",
      "2017-03-30 01:28:03,610 Iter 1575, Minibatch Loss= 0.1778, Training Accuracy= 0.9539, Minibatch error= 4.6%\n",
      "2017-03-30 01:28:16,714 Iter 1580, Minibatch Loss= 0.3625, Training Accuracy= 0.7859, Minibatch error= 21.4%\n",
      "2017-03-30 01:28:29,803 Iter 1585, Minibatch Loss= 0.2077, Training Accuracy= 0.8943, Minibatch error= 10.6%\n",
      "2017-03-30 01:28:42,833 Iter 1590, Minibatch Loss= 0.0515, Training Accuracy= 0.9917, Minibatch error= 0.8%\n",
      "2017-03-30 01:28:55,918 Iter 1595, Minibatch Loss= 0.2288, Training Accuracy= 0.9042, Minibatch error= 9.6%\n",
      "2017-03-30 01:29:05,407 Epoch 15, Average loss: 0.2274, learning rate: 0.0010\n",
      "2017-03-30 01:29:09,112 Verification error= 6.2%, loss= 0.1318\n",
      "2017-03-30 01:29:13,142 Iter 1600, Minibatch Loss= 0.2374, Training Accuracy= 0.9007, Minibatch error= 9.9%\n",
      "2017-03-30 01:29:24,871 Iter 1605, Minibatch Loss= 0.0388, Training Accuracy= 0.9911, Minibatch error= 0.9%\n",
      "2017-03-30 01:29:36,547 Iter 1610, Minibatch Loss= 0.8139, Training Accuracy= 0.7137, Minibatch error= 28.6%\n",
      "2017-03-30 01:29:48,388 Iter 1615, Minibatch Loss= 0.2313, Training Accuracy= 0.8975, Minibatch error= 10.2%\n",
      "2017-03-30 01:30:00,135 Iter 1620, Minibatch Loss= 0.1355, Training Accuracy= 0.9646, Minibatch error= 3.5%\n",
      "2017-03-30 01:30:11,984 Iter 1625, Minibatch Loss= 0.1015, Training Accuracy= 0.9608, Minibatch error= 3.9%\n",
      "2017-03-30 01:30:23,726 Iter 1630, Minibatch Loss= 0.0584, Training Accuracy= 0.9932, Minibatch error= 0.7%\n",
      "2017-03-30 01:30:35,594 Iter 1635, Minibatch Loss= 0.1074, Training Accuracy= 0.9669, Minibatch error= 3.3%\n",
      "2017-03-30 01:30:47,371 Iter 1640, Minibatch Loss= 0.0791, Training Accuracy= 0.9798, Minibatch error= 2.0%\n",
      "2017-03-30 01:30:59,241 Iter 1645, Minibatch Loss= 0.4344, Training Accuracy= 0.8415, Minibatch error= 15.8%\n",
      "2017-03-30 01:31:11,067 Iter 1650, Minibatch Loss= 0.0857, Training Accuracy= 0.9863, Minibatch error= 1.4%\n",
      "2017-03-30 01:31:22,802 Iter 1655, Minibatch Loss= 0.0600, Training Accuracy= 0.9933, Minibatch error= 0.7%\n",
      "2017-03-30 01:31:34,500 Iter 1660, Minibatch Loss= 0.2573, Training Accuracy= 0.8990, Minibatch error= 10.1%\n",
      "2017-03-30 01:31:46,365 Iter 1665, Minibatch Loss= 0.1975, Training Accuracy= 0.9249, Minibatch error= 7.5%\n",
      "2017-03-30 01:31:58,178 Iter 1670, Minibatch Loss= 0.3818, Training Accuracy= 0.8433, Minibatch error= 15.7%\n",
      "2017-03-30 01:32:09,947 Iter 1675, Minibatch Loss= 0.0984, Training Accuracy= 0.9667, Minibatch error= 3.3%\n",
      "2017-03-30 01:32:21,729 Iter 1680, Minibatch Loss= 0.1253, Training Accuracy= 0.9548, Minibatch error= 4.5%\n",
      "2017-03-30 01:32:33,558 Iter 1685, Minibatch Loss= 0.3368, Training Accuracy= 0.8650, Minibatch error= 13.5%\n",
      "2017-03-30 01:32:45,424 Iter 1690, Minibatch Loss= 0.1212, Training Accuracy= 0.9698, Minibatch error= 3.0%\n",
      "2017-03-30 01:32:57,342 Iter 1695, Minibatch Loss= 0.0272, Training Accuracy= 0.9959, Minibatch error= 0.4%\n",
      "2017-03-30 01:33:06,421 Epoch 16, Average loss: 0.1739, learning rate: 0.0010\n",
      "2017-03-30 01:33:10,358 Verification error= 6.0%, loss= 0.1251\n",
      "2017-03-30 01:33:14,855 Iter 1700, Minibatch Loss= 0.0628, Training Accuracy= 0.9838, Minibatch error= 1.6%\n",
      "2017-03-30 01:33:26,946 Iter 1705, Minibatch Loss= 0.7925, Training Accuracy= 0.7456, Minibatch error= 25.4%\n",
      "2017-03-30 01:33:39,256 Iter 1710, Minibatch Loss= 0.1504, Training Accuracy= 0.9604, Minibatch error= 4.0%\n",
      "2017-03-30 01:33:51,417 Iter 1715, Minibatch Loss= 0.3131, Training Accuracy= 0.8826, Minibatch error= 11.7%\n",
      "2017-03-30 01:34:03,605 Iter 1720, Minibatch Loss= 0.1545, Training Accuracy= 0.9704, Minibatch error= 3.0%\n",
      "2017-03-30 01:34:15,695 Iter 1725, Minibatch Loss= 0.1687, Training Accuracy= 0.9804, Minibatch error= 2.0%\n",
      "2017-03-30 01:34:27,813 Iter 1730, Minibatch Loss= 0.3051, Training Accuracy= 0.8792, Minibatch error= 12.1%\n",
      "2017-03-30 01:34:40,104 Iter 1735, Minibatch Loss= 0.2838, Training Accuracy= 0.9239, Minibatch error= 7.6%\n",
      "2017-03-30 01:34:52,214 Iter 1740, Minibatch Loss= 0.2406, Training Accuracy= 0.8729, Minibatch error= 12.7%\n",
      "2017-03-30 01:35:04,407 Iter 1745, Minibatch Loss= 0.1478, Training Accuracy= 0.9136, Minibatch error= 8.6%\n",
      "2017-03-30 01:35:16,707 Iter 1750, Minibatch Loss= 0.1273, Training Accuracy= 0.9431, Minibatch error= 5.7%\n",
      "2017-03-30 01:35:28,991 Iter 1755, Minibatch Loss= 0.2286, Training Accuracy= 0.9329, Minibatch error= 6.7%\n",
      "2017-03-30 01:35:41,241 Iter 1760, Minibatch Loss= 0.1361, Training Accuracy= 0.9477, Minibatch error= 5.2%\n",
      "2017-03-30 01:35:53,374 Iter 1765, Minibatch Loss= 0.0395, Training Accuracy= 0.9955, Minibatch error= 0.4%\n",
      "2017-03-30 01:36:05,545 Iter 1770, Minibatch Loss= 0.1023, Training Accuracy= 0.9700, Minibatch error= 3.0%\n",
      "2017-03-30 01:36:18,017 Iter 1775, Minibatch Loss= 0.0996, Training Accuracy= 0.9731, Minibatch error= 2.7%\n",
      "2017-03-30 01:36:30,400 Iter 1780, Minibatch Loss= 0.1971, Training Accuracy= 0.9400, Minibatch error= 6.0%\n",
      "2017-03-30 01:36:42,859 Iter 1785, Minibatch Loss= 0.1030, Training Accuracy= 0.9697, Minibatch error= 3.0%\n",
      "2017-03-30 01:36:55,171 Iter 1790, Minibatch Loss= 0.0556, Training Accuracy= 0.9866, Minibatch error= 1.3%\n",
      "2017-03-30 01:37:07,517 Iter 1795, Minibatch Loss= 0.1430, Training Accuracy= 0.9298, Minibatch error= 7.0%\n",
      "2017-03-30 01:37:17,025 Epoch 17, Average loss: 0.2069, learning rate: 0.0010\n",
      "2017-03-30 01:37:21,155 Verification error= 5.1%, loss= 0.1158\n",
      "2017-03-30 01:37:25,635 Iter 1800, Minibatch Loss= 0.0721, Training Accuracy= 0.9897, Minibatch error= 1.0%\n",
      "2017-03-30 01:37:38,035 Iter 1805, Minibatch Loss= 0.1348, Training Accuracy= 0.9648, Minibatch error= 3.5%\n",
      "2017-03-30 01:37:50,706 Iter 1810, Minibatch Loss= 0.1756, Training Accuracy= 0.9429, Minibatch error= 5.7%\n",
      "2017-03-30 01:38:03,502 Iter 1815, Minibatch Loss= 0.1218, Training Accuracy= 0.9682, Minibatch error= 3.2%\n",
      "2017-03-30 01:38:16,429 Iter 1820, Minibatch Loss= 0.1878, Training Accuracy= 0.9307, Minibatch error= 6.9%\n",
      "2017-03-30 01:38:29,384 Iter 1825, Minibatch Loss= 0.1232, Training Accuracy= 0.9396, Minibatch error= 6.0%\n",
      "2017-03-30 01:38:42,324 Iter 1830, Minibatch Loss= 0.3616, Training Accuracy= 0.8205, Minibatch error= 17.9%\n",
      "2017-03-30 01:38:55,378 Iter 1835, Minibatch Loss= 0.0944, Training Accuracy= 0.9716, Minibatch error= 2.8%\n",
      "2017-03-30 01:39:08,394 Iter 1840, Minibatch Loss= 0.1905, Training Accuracy= 0.9558, Minibatch error= 4.4%\n",
      "2017-03-30 01:39:21,424 Iter 1845, Minibatch Loss= 0.0700, Training Accuracy= 0.9864, Minibatch error= 1.4%\n",
      "2017-03-30 01:39:34,482 Iter 1850, Minibatch Loss= 0.1565, Training Accuracy= 0.9569, Minibatch error= 4.3%\n",
      "2017-03-30 01:39:47,513 Iter 1855, Minibatch Loss= 0.0986, Training Accuracy= 0.9860, Minibatch error= 1.4%\n",
      "2017-03-30 05:57:04,418 Iter 1860, Minibatch Loss= 0.4426, Training Accuracy= 0.7745, Minibatch error= 22.5%\n",
      "2017-03-30 05:57:17,405 Iter 1865, Minibatch Loss= 0.1235, Training Accuracy= 0.9795, Minibatch error= 2.1%\n",
      "2017-03-30 05:57:29,862 Iter 1870, Minibatch Loss= 0.2009, Training Accuracy= 0.9544, Minibatch error= 4.6%\n",
      "2017-03-30 05:57:42,144 Iter 1875, Minibatch Loss= 0.2182, Training Accuracy= 0.9234, Minibatch error= 7.7%\n",
      "2017-03-30 05:57:54,528 Iter 1880, Minibatch Loss= 0.1843, Training Accuracy= 0.9210, Minibatch error= 7.9%\n",
      "2017-03-30 05:58:06,553 Iter 1885, Minibatch Loss= 0.0690, Training Accuracy= 0.9718, Minibatch error= 2.8%\n",
      "2017-03-30 05:58:18,732 Iter 1890, Minibatch Loss= 0.2707, Training Accuracy= 0.9099, Minibatch error= 9.0%\n",
      "2017-03-30 05:58:30,877 Iter 1895, Minibatch Loss= 0.2296, Training Accuracy= 0.9039, Minibatch error= 9.6%\n",
      "2017-03-30 05:58:40,679 Epoch 18, Average loss: 0.2232, learning rate: 0.0010\n",
      "2017-03-30 05:58:44,730 Verification error= 4.4%, loss= 0.1325\n",
      "2017-03-30 05:58:49,124 Iter 1900, Minibatch Loss= 0.0653, Training Accuracy= 0.9969, Minibatch error= 0.3%\n",
      "2017-03-30 05:59:02,704 Iter 1905, Minibatch Loss= 0.1680, Training Accuracy= 0.9419, Minibatch error= 5.8%\n",
      "2017-03-30 05:59:16,496 Iter 1910, Minibatch Loss= 0.1078, Training Accuracy= 0.9679, Minibatch error= 3.2%\n",
      "2017-03-30 05:59:29,897 Iter 1915, Minibatch Loss= 0.3027, Training Accuracy= 0.8875, Minibatch error= 11.2%\n",
      "2017-03-30 05:59:43,167 Iter 1920, Minibatch Loss= 0.1678, Training Accuracy= 0.9233, Minibatch error= 7.7%\n",
      "2017-03-30 05:59:56,245 Iter 1925, Minibatch Loss= 0.1087, Training Accuracy= 0.9654, Minibatch error= 3.5%\n",
      "2017-03-30 06:00:09,048 Iter 1930, Minibatch Loss= 0.0882, Training Accuracy= 0.9822, Minibatch error= 1.8%\n",
      "2017-03-30 06:00:21,731 Iter 1935, Minibatch Loss= 0.0969, Training Accuracy= 0.9688, Minibatch error= 3.1%\n",
      "2017-03-30 06:00:34,944 Iter 1940, Minibatch Loss= 0.1921, Training Accuracy= 0.9352, Minibatch error= 6.5%\n",
      "2017-03-30 06:00:48,452 Iter 1945, Minibatch Loss= 0.0732, Training Accuracy= 0.9952, Minibatch error= 0.5%\n",
      "2017-03-30 06:01:01,304 Iter 1950, Minibatch Loss= 0.3642, Training Accuracy= 0.8308, Minibatch error= 16.9%\n",
      "2017-03-30 06:01:14,133 Iter 1955, Minibatch Loss= 0.1745, Training Accuracy= 0.9656, Minibatch error= 3.4%\n",
      "2017-03-30 06:01:26,876 Iter 1960, Minibatch Loss= 0.1535, Training Accuracy= 0.9618, Minibatch error= 3.8%\n",
      "2017-03-30 06:01:39,456 Iter 1965, Minibatch Loss= 0.1815, Training Accuracy= 0.9422, Minibatch error= 5.8%\n",
      "2017-03-30 06:01:52,218 Iter 1970, Minibatch Loss= 0.1379, Training Accuracy= 0.9716, Minibatch error= 2.8%\n",
      "2017-03-30 06:02:05,120 Iter 1975, Minibatch Loss= 0.1359, Training Accuracy= 0.9672, Minibatch error= 3.3%\n",
      "2017-03-30 06:02:17,944 Iter 1980, Minibatch Loss= 0.2326, Training Accuracy= 0.9185, Minibatch error= 8.2%\n",
      "2017-03-30 06:02:30,676 Iter 1985, Minibatch Loss= 0.0649, Training Accuracy= 0.9876, Minibatch error= 1.2%\n",
      "2017-03-30 06:02:43,604 Iter 1990, Minibatch Loss= 0.0527, Training Accuracy= 0.9810, Minibatch error= 1.9%\n",
      "2017-03-30 06:02:56,388 Iter 1995, Minibatch Loss= 0.6145, Training Accuracy= 0.7452, Minibatch error= 25.5%\n",
      "2017-03-30 06:03:06,251 Epoch 19, Average loss: 0.1940, learning rate: 0.0010\n",
      "2017-03-30 06:03:10,570 Verification error= 4.5%, loss= 0.1244\n",
      "2017-03-30 06:03:15,468 Iter 2000, Minibatch Loss= 0.0620, Training Accuracy= 0.9956, Minibatch error= 0.4%\n",
      "2017-03-30 06:03:28,580 Iter 2005, Minibatch Loss= 0.1061, Training Accuracy= 0.9754, Minibatch error= 2.5%\n",
      "2017-03-30 06:03:41,770 Iter 2010, Minibatch Loss= 0.3111, Training Accuracy= 0.9022, Minibatch error= 9.8%\n",
      "2017-03-30 06:03:55,017 Iter 2015, Minibatch Loss= 0.1982, Training Accuracy= 0.9361, Minibatch error= 6.4%\n",
      "2017-03-30 06:04:08,408 Iter 2020, Minibatch Loss= 0.1595, Training Accuracy= 0.9680, Minibatch error= 3.2%\n",
      "2017-03-30 06:04:21,783 Iter 2025, Minibatch Loss= 0.3383, Training Accuracy= 0.8509, Minibatch error= 14.9%\n",
      "2017-03-30 06:04:35,306 Iter 2030, Minibatch Loss= 0.2437, Training Accuracy= 0.9124, Minibatch error= 8.8%\n",
      "2017-03-30 06:04:48,742 Iter 2035, Minibatch Loss= 0.2184, Training Accuracy= 0.9315, Minibatch error= 6.9%\n",
      "2017-03-30 06:05:02,145 Iter 2040, Minibatch Loss= 0.0722, Training Accuracy= 0.9795, Minibatch error= 2.1%\n",
      "2017-03-30 06:05:15,570 Iter 2045, Minibatch Loss= 0.1061, Training Accuracy= 0.9796, Minibatch error= 2.0%\n",
      "2017-03-30 06:05:29,085 Iter 2050, Minibatch Loss= 0.0661, Training Accuracy= 0.9792, Minibatch error= 2.1%\n",
      "2017-03-30 06:05:42,558 Iter 2055, Minibatch Loss= 0.4154, Training Accuracy= 0.7732, Minibatch error= 22.7%\n",
      "2017-03-30 06:05:55,991 Iter 2060, Minibatch Loss= 0.7176, Training Accuracy= 0.7440, Minibatch error= 25.6%\n",
      "2017-03-30 06:06:09,457 Iter 2065, Minibatch Loss= 0.1552, Training Accuracy= 0.9534, Minibatch error= 4.7%\n",
      "2017-03-30 06:06:22,973 Iter 2070, Minibatch Loss= 0.0615, Training Accuracy= 0.9771, Minibatch error= 2.3%\n",
      "2017-03-30 06:06:36,564 Iter 2075, Minibatch Loss= 0.0636, Training Accuracy= 0.9905, Minibatch error= 1.0%\n",
      "2017-03-30 06:06:50,154 Iter 2080, Minibatch Loss= 0.1065, Training Accuracy= 0.9710, Minibatch error= 2.9%\n",
      "2017-03-30 06:07:03,624 Iter 2085, Minibatch Loss= 0.1382, Training Accuracy= 0.9254, Minibatch error= 7.5%\n",
      "2017-03-30 06:07:17,084 Iter 2090, Minibatch Loss= 0.0818, Training Accuracy= 0.9886, Minibatch error= 1.1%\n",
      "2017-03-30 06:07:30,545 Iter 2095, Minibatch Loss= 0.0979, Training Accuracy= 0.9764, Minibatch error= 2.4%\n",
      "2017-03-30 06:07:39,882 Epoch 20, Average loss: 0.1882, learning rate: 0.0010\n",
      "2017-03-30 06:07:43,584 Verification error= 4.3%, loss= 0.1320\n",
      "2017-03-30 06:07:48,150 Iter 2100, Minibatch Loss= 0.0801, Training Accuracy= 0.9830, Minibatch error= 1.7%\n",
      "2017-03-30 06:08:00,032 Iter 2105, Minibatch Loss= 0.1597, Training Accuracy= 0.9485, Minibatch error= 5.1%\n",
      "2017-03-30 06:08:11,966 Iter 2110, Minibatch Loss= 0.0699, Training Accuracy= 0.9844, Minibatch error= 1.6%\n",
      "2017-03-30 06:08:23,885 Iter 2115, Minibatch Loss= 0.2254, Training Accuracy= 0.9368, Minibatch error= 6.3%\n",
      "2017-03-30 06:08:35,866 Iter 2120, Minibatch Loss= 0.1824, Training Accuracy= 0.9491, Minibatch error= 5.1%\n",
      "2017-03-30 06:08:47,852 Iter 2125, Minibatch Loss= 0.8901, Training Accuracy= 0.6705, Minibatch error= 32.9%\n",
      "2017-03-30 06:08:59,945 Iter 2130, Minibatch Loss= 0.2013, Training Accuracy= 0.9248, Minibatch error= 7.5%\n",
      "2017-03-30 06:09:12,106 Iter 2135, Minibatch Loss= 0.0983, Training Accuracy= 0.9922, Minibatch error= 0.8%\n",
      "2017-03-30 06:09:25,401 Iter 2140, Minibatch Loss= 0.1769, Training Accuracy= 0.9264, Minibatch error= 7.4%\n",
      "2017-03-30 06:09:38,360 Iter 2145, Minibatch Loss= 0.1558, Training Accuracy= 0.9427, Minibatch error= 5.7%\n",
      "2017-03-30 06:09:50,690 Iter 2150, Minibatch Loss= 0.0878, Training Accuracy= 0.9780, Minibatch error= 2.2%\n",
      "2017-03-30 06:10:03,070 Iter 2155, Minibatch Loss= 0.0849, Training Accuracy= 0.9925, Minibatch error= 0.8%\n",
      "2017-03-30 06:10:15,477 Iter 2160, Minibatch Loss= 0.2475, Training Accuracy= 0.8821, Minibatch error= 11.8%\n",
      "2017-03-30 06:10:27,843 Iter 2165, Minibatch Loss= 0.1752, Training Accuracy= 0.9480, Minibatch error= 5.2%\n",
      "2017-03-30 06:10:40,329 Iter 2170, Minibatch Loss= 0.1065, Training Accuracy= 0.9828, Minibatch error= 1.7%\n",
      "2017-03-30 06:10:52,662 Iter 2175, Minibatch Loss= 0.1856, Training Accuracy= 0.9058, Minibatch error= 9.4%\n",
      "2017-03-30 06:11:05,076 Iter 2180, Minibatch Loss= 0.1044, Training Accuracy= 0.9860, Minibatch error= 1.4%\n",
      "2017-03-30 06:11:17,560 Iter 2185, Minibatch Loss= 0.1689, Training Accuracy= 0.9551, Minibatch error= 4.5%\n",
      "2017-03-30 06:11:29,958 Iter 2190, Minibatch Loss= 0.1238, Training Accuracy= 0.9644, Minibatch error= 3.6%\n",
      "2017-03-30 06:11:42,343 Iter 2195, Minibatch Loss= 0.5463, Training Accuracy= 0.8042, Minibatch error= 19.6%\n",
      "2017-03-30 06:11:51,860 Epoch 21, Average loss: 0.1961, learning rate: 0.0010\n",
      "2017-03-30 06:11:55,965 Verification error= 4.8%, loss= 0.1193\n",
      "2017-03-30 06:12:00,551 Iter 2200, Minibatch Loss= 0.0820, Training Accuracy= 0.9788, Minibatch error= 2.1%\n",
      "2017-03-30 06:12:13,040 Iter 2205, Minibatch Loss= 0.1143, Training Accuracy= 0.9605, Minibatch error= 3.9%\n",
      "2017-03-30 06:12:25,551 Iter 2210, Minibatch Loss= 0.3011, Training Accuracy= 0.8604, Minibatch error= 14.0%\n",
      "2017-03-30 06:12:38,100 Iter 2215, Minibatch Loss= 0.0744, Training Accuracy= 0.9780, Minibatch error= 2.2%\n",
      "2017-03-30 06:12:50,666 Iter 2220, Minibatch Loss= 0.2196, Training Accuracy= 0.9260, Minibatch error= 7.4%\n",
      "2017-03-30 06:13:03,151 Iter 2225, Minibatch Loss= 0.0683, Training Accuracy= 0.9882, Minibatch error= 1.2%\n",
      "2017-03-30 06:13:15,792 Iter 2230, Minibatch Loss= 0.0980, Training Accuracy= 0.9817, Minibatch error= 1.8%\n",
      "2017-03-30 06:13:28,343 Iter 2235, Minibatch Loss= 0.0838, Training Accuracy= 0.9858, Minibatch error= 1.4%\n",
      "2017-03-30 06:13:40,942 Iter 2240, Minibatch Loss= 0.1763, Training Accuracy= 0.9308, Minibatch error= 6.9%\n",
      "2017-03-30 06:13:53,572 Iter 2245, Minibatch Loss= 0.1819, Training Accuracy= 0.9522, Minibatch error= 4.8%\n",
      "2017-03-30 06:14:06,164 Iter 2250, Minibatch Loss= 0.2133, Training Accuracy= 0.9324, Minibatch error= 6.8%\n",
      "2017-03-30 06:14:18,773 Iter 2255, Minibatch Loss= 0.1072, Training Accuracy= 0.9620, Minibatch error= 3.8%\n",
      "2017-03-30 06:14:31,368 Iter 2260, Minibatch Loss= 0.3706, Training Accuracy= 0.8213, Minibatch error= 17.9%\n",
      "2017-03-30 06:14:44,106 Iter 2265, Minibatch Loss= 0.0215, Training Accuracy= 0.9986, Minibatch error= 0.1%\n",
      "2017-03-30 06:14:56,684 Iter 2270, Minibatch Loss= 0.1120, Training Accuracy= 0.9554, Minibatch error= 4.5%\n",
      "2017-03-30 06:15:09,256 Iter 2275, Minibatch Loss= 0.0834, Training Accuracy= 0.9679, Minibatch error= 3.2%\n",
      "2017-03-30 06:15:21,891 Iter 2280, Minibatch Loss= 0.0814, Training Accuracy= 0.9855, Minibatch error= 1.4%\n",
      "2017-03-30 06:15:34,421 Iter 2285, Minibatch Loss= 0.2586, Training Accuracy= 0.9188, Minibatch error= 8.1%\n",
      "2017-03-30 06:15:46,954 Iter 2290, Minibatch Loss= 0.1592, Training Accuracy= 0.9701, Minibatch error= 3.0%\n",
      "2017-03-30 06:15:59,540 Iter 2295, Minibatch Loss= 0.0528, Training Accuracy= 0.9849, Minibatch error= 1.5%\n",
      "2017-03-30 06:16:09,231 Epoch 22, Average loss: 0.2102, learning rate: 0.0010\n",
      "2017-03-30 06:16:13,329 Verification error= 5.0%, loss= 0.1848\n",
      "2017-03-30 06:16:18,149 Iter 2300, Minibatch Loss= 0.1495, Training Accuracy= 0.9658, Minibatch error= 3.4%\n",
      "2017-03-30 06:16:30,861 Iter 2305, Minibatch Loss= 0.0836, Training Accuracy= 0.9851, Minibatch error= 1.5%\n",
      "2017-03-30 06:16:43,655 Iter 2310, Minibatch Loss= 0.2047, Training Accuracy= 0.9224, Minibatch error= 7.8%\n",
      "2017-03-30 06:16:56,391 Iter 2315, Minibatch Loss= 0.1272, Training Accuracy= 0.9529, Minibatch error= 4.7%\n",
      "2017-03-30 06:17:09,054 Iter 2320, Minibatch Loss= 0.1200, Training Accuracy= 0.9563, Minibatch error= 4.4%\n",
      "2017-03-30 06:17:21,760 Iter 2325, Minibatch Loss= 0.1083, Training Accuracy= 0.9657, Minibatch error= 3.4%\n",
      "2017-03-30 06:17:34,478 Iter 2330, Minibatch Loss= 0.1396, Training Accuracy= 0.9464, Minibatch error= 5.4%\n",
      "2017-03-30 06:17:47,195 Iter 2335, Minibatch Loss= 0.1176, Training Accuracy= 0.9665, Minibatch error= 3.4%\n",
      "2017-03-30 06:17:59,920 Iter 2340, Minibatch Loss= 0.0954, Training Accuracy= 0.9708, Minibatch error= 2.9%\n",
      "2017-03-30 06:18:12,669 Iter 2345, Minibatch Loss= 0.1673, Training Accuracy= 0.9332, Minibatch error= 6.7%\n",
      "2017-03-30 06:18:25,360 Iter 2350, Minibatch Loss= 0.0722, Training Accuracy= 0.9779, Minibatch error= 2.2%\n",
      "2017-03-30 06:18:38,167 Iter 2355, Minibatch Loss= 0.1632, Training Accuracy= 0.9266, Minibatch error= 7.3%\n",
      "2017-03-30 06:18:50,892 Iter 2360, Minibatch Loss= 0.4831, Training Accuracy= 0.8303, Minibatch error= 17.0%\n",
      "2017-03-30 06:19:03,355 Iter 2365, Minibatch Loss= 0.2633, Training Accuracy= 0.8636, Minibatch error= 13.6%\n",
      "2017-03-30 06:19:15,789 Iter 2370, Minibatch Loss= 0.2038, Training Accuracy= 0.9224, Minibatch error= 7.8%\n",
      "2017-03-30 06:19:28,235 Iter 2375, Minibatch Loss= 0.7949, Training Accuracy= 0.6827, Minibatch error= 31.7%\n",
      "2017-03-30 06:19:40,636 Iter 2380, Minibatch Loss= 0.1271, Training Accuracy= 0.9510, Minibatch error= 4.9%\n",
      "2017-03-30 06:19:53,034 Iter 2385, Minibatch Loss= 0.0817, Training Accuracy= 0.9862, Minibatch error= 1.4%\n",
      "2017-03-30 06:20:05,501 Iter 2390, Minibatch Loss= 0.2392, Training Accuracy= 0.8943, Minibatch error= 10.6%\n",
      "2017-03-30 06:20:18,004 Iter 2395, Minibatch Loss= 0.9632, Training Accuracy= 0.4733, Minibatch error= 52.7%\n",
      "2017-03-30 06:20:27,678 Epoch 23, Average loss: 0.2029, learning rate: 0.0010\n",
      "2017-03-30 06:20:31,693 Verification error= 4.2%, loss= 0.1713\n",
      "2017-03-30 06:20:36,557 Iter 2400, Minibatch Loss= 0.1605, Training Accuracy= 0.9550, Minibatch error= 4.5%\n",
      "2017-03-30 06:20:49,285 Iter 2405, Minibatch Loss= 0.2680, Training Accuracy= 0.8608, Minibatch error= 13.9%\n",
      "2017-03-30 06:21:01,873 Iter 2410, Minibatch Loss= 0.4786, Training Accuracy= 0.8122, Minibatch error= 18.8%\n",
      "2017-03-30 06:21:14,556 Iter 2415, Minibatch Loss= 0.1394, Training Accuracy= 0.9583, Minibatch error= 4.2%\n",
      "2017-03-30 06:21:27,286 Iter 2420, Minibatch Loss= 0.2579, Training Accuracy= 0.8716, Minibatch error= 12.8%\n",
      "2017-03-30 06:21:39,969 Iter 2425, Minibatch Loss= 0.1038, Training Accuracy= 0.9741, Minibatch error= 2.6%\n",
      "2017-03-30 06:21:52,822 Iter 2430, Minibatch Loss= 0.5557, Training Accuracy= 0.7657, Minibatch error= 23.4%\n",
      "2017-03-30 06:22:05,643 Iter 2435, Minibatch Loss= 0.0753, Training Accuracy= 0.9774, Minibatch error= 2.3%\n",
      "2017-03-30 06:22:18,542 Iter 2440, Minibatch Loss= 0.1625, Training Accuracy= 0.9322, Minibatch error= 6.8%\n",
      "2017-03-30 06:22:31,389 Iter 2445, Minibatch Loss= 0.1528, Training Accuracy= 0.9268, Minibatch error= 7.3%\n",
      "2017-03-30 06:22:44,562 Iter 2450, Minibatch Loss= 0.0746, Training Accuracy= 0.9822, Minibatch error= 1.8%\n",
      "2017-03-30 06:22:57,476 Iter 2455, Minibatch Loss= 0.1703, Training Accuracy= 0.9308, Minibatch error= 6.9%\n",
      "2017-03-30 06:23:10,371 Iter 2460, Minibatch Loss= 0.1344, Training Accuracy= 0.9445, Minibatch error= 5.5%\n",
      "2017-03-30 06:23:23,306 Iter 2465, Minibatch Loss= 0.1372, Training Accuracy= 0.9426, Minibatch error= 5.7%\n",
      "2017-03-30 06:23:36,236 Iter 2470, Minibatch Loss= 0.0408, Training Accuracy= 0.9878, Minibatch error= 1.2%\n",
      "2017-03-30 06:23:49,129 Iter 2475, Minibatch Loss= 0.0656, Training Accuracy= 0.9783, Minibatch error= 2.2%\n",
      "2017-03-30 06:24:02,098 Iter 2480, Minibatch Loss= 0.2348, Training Accuracy= 0.9271, Minibatch error= 7.3%\n",
      "2017-03-30 06:24:15,055 Iter 2485, Minibatch Loss= 0.1361, Training Accuracy= 0.9728, Minibatch error= 2.7%\n",
      "2017-03-30 06:24:28,031 Iter 2490, Minibatch Loss= 0.2002, Training Accuracy= 0.8825, Minibatch error= 11.8%\n",
      "2017-03-30 06:24:41,034 Iter 2495, Minibatch Loss= 0.0953, Training Accuracy= 0.9658, Minibatch error= 3.4%\n",
      "2017-03-30 06:24:50,956 Epoch 24, Average loss: 0.1796, learning rate: 0.0010\n",
      "2017-03-30 06:24:55,124 Verification error= 4.1%, loss= 0.1345\n",
      "2017-03-30 06:24:59,950 Iter 2500, Minibatch Loss= 0.0780, Training Accuracy= 0.9908, Minibatch error= 0.9%\n",
      "2017-03-30 06:25:13,034 Iter 2505, Minibatch Loss= 0.5535, Training Accuracy= 0.7286, Minibatch error= 27.1%\n",
      "2017-03-30 06:25:26,045 Iter 2510, Minibatch Loss= 0.0979, Training Accuracy= 0.9708, Minibatch error= 2.9%\n",
      "2017-03-30 06:25:39,107 Iter 2515, Minibatch Loss= 0.1273, Training Accuracy= 0.9576, Minibatch error= 4.2%\n",
      "2017-03-30 06:25:52,144 Iter 2520, Minibatch Loss= 0.0852, Training Accuracy= 0.9936, Minibatch error= 0.6%\n",
      "2017-03-30 06:26:05,172 Iter 2525, Minibatch Loss= 0.1590, Training Accuracy= 0.9325, Minibatch error= 6.8%\n",
      "2017-03-30 06:26:18,175 Iter 2530, Minibatch Loss= 0.1017, Training Accuracy= 0.9725, Minibatch error= 2.8%\n",
      "2017-03-30 06:26:31,225 Iter 2535, Minibatch Loss= 0.0597, Training Accuracy= 0.9861, Minibatch error= 1.4%\n",
      "2017-03-30 06:26:44,449 Iter 2540, Minibatch Loss= 0.2633, Training Accuracy= 0.9093, Minibatch error= 9.1%\n",
      "2017-03-30 06:26:57,549 Iter 2545, Minibatch Loss= 0.0782, Training Accuracy= 0.9778, Minibatch error= 2.2%\n",
      "2017-03-30 06:27:10,712 Iter 2550, Minibatch Loss= 0.0785, Training Accuracy= 0.9824, Minibatch error= 1.8%\n",
      "2017-03-30 06:27:24,039 Iter 2555, Minibatch Loss= 0.0744, Training Accuracy= 0.9748, Minibatch error= 2.5%\n",
      "2017-03-30 06:27:37,358 Iter 2560, Minibatch Loss= 0.0792, Training Accuracy= 0.9791, Minibatch error= 2.1%\n",
      "2017-03-30 06:27:50,610 Iter 2565, Minibatch Loss= 0.0337, Training Accuracy= 0.9922, Minibatch error= 0.8%\n",
      "2017-03-30 06:28:03,947 Iter 2570, Minibatch Loss= 0.1668, Training Accuracy= 0.9144, Minibatch error= 8.6%\n",
      "2017-03-30 06:28:17,284 Iter 2575, Minibatch Loss= 0.2242, Training Accuracy= 0.9062, Minibatch error= 9.4%\n",
      "2017-03-30 06:28:30,657 Iter 2580, Minibatch Loss= 0.1821, Training Accuracy= 0.9337, Minibatch error= 6.6%\n",
      "2017-03-30 06:28:44,136 Iter 2585, Minibatch Loss= 0.1868, Training Accuracy= 0.9900, Minibatch error= 1.0%\n",
      "2017-03-30 06:28:57,499 Iter 2590, Minibatch Loss= 0.2638, Training Accuracy= 0.9184, Minibatch error= 8.2%\n",
      "2017-03-30 06:29:10,885 Iter 2595, Minibatch Loss= 0.2296, Training Accuracy= 0.9194, Minibatch error= 8.1%\n",
      "2017-03-30 06:29:21,165 Epoch 25, Average loss: 0.2002, learning rate: 0.0010\n",
      "2017-03-30 06:29:25,416 Verification error= 3.9%, loss= 0.1514\n",
      "2017-03-30 06:29:30,680 Iter 2600, Minibatch Loss= 0.3117, Training Accuracy= 0.8130, Minibatch error= 18.7%\n",
      "2017-03-30 06:29:44,236 Iter 2605, Minibatch Loss= 0.2764, Training Accuracy= 0.8394, Minibatch error= 16.1%\n",
      "2017-03-30 06:29:57,819 Iter 2610, Minibatch Loss= 0.0982, Training Accuracy= 0.9582, Minibatch error= 4.2%\n",
      "2017-03-30 06:30:11,492 Iter 2615, Minibatch Loss= 0.0909, Training Accuracy= 0.9753, Minibatch error= 2.5%\n",
      "2017-03-30 06:30:25,196 Iter 2620, Minibatch Loss= 0.5241, Training Accuracy= 0.7226, Minibatch error= 27.7%\n",
      "2017-03-30 06:30:38,847 Iter 2625, Minibatch Loss= 0.1216, Training Accuracy= 0.9854, Minibatch error= 1.5%\n",
      "2017-03-30 06:30:52,546 Iter 2630, Minibatch Loss= 0.1517, Training Accuracy= 0.9652, Minibatch error= 3.5%\n",
      "2017-03-30 06:31:06,245 Iter 2635, Minibatch Loss= 0.2118, Training Accuracy= 0.8881, Minibatch error= 11.2%\n",
      "2017-03-30 06:31:19,864 Iter 2640, Minibatch Loss= 0.1319, Training Accuracy= 0.9662, Minibatch error= 3.4%\n",
      "2017-03-30 06:31:33,446 Iter 2645, Minibatch Loss= 0.1203, Training Accuracy= 0.9636, Minibatch error= 3.6%\n",
      "2017-03-30 06:31:47,177 Iter 2650, Minibatch Loss= 0.0730, Training Accuracy= 0.9760, Minibatch error= 2.4%\n",
      "2017-03-30 06:32:00,955 Iter 2655, Minibatch Loss= 0.1104, Training Accuracy= 0.9801, Minibatch error= 2.0%\n",
      "2017-03-30 06:32:14,611 Iter 2660, Minibatch Loss= 0.0932, Training Accuracy= 0.9763, Minibatch error= 2.4%\n",
      "2017-03-30 06:32:27,714 Iter 2665, Minibatch Loss= 0.0351, Training Accuracy= 0.9907, Minibatch error= 0.9%\n",
      "2017-03-30 06:32:39,902 Iter 2670, Minibatch Loss= 0.7659, Training Accuracy= 0.7284, Minibatch error= 27.2%\n",
      "2017-03-30 06:32:52,140 Iter 2675, Minibatch Loss= 0.0403, Training Accuracy= 0.9975, Minibatch error= 0.3%\n",
      "2017-03-30 06:33:04,339 Iter 2680, Minibatch Loss= 0.1374, Training Accuracy= 0.9612, Minibatch error= 3.9%\n",
      "2017-03-30 06:33:16,633 Iter 2685, Minibatch Loss= 0.0652, Training Accuracy= 0.9846, Minibatch error= 1.5%\n",
      "2017-03-30 06:33:28,836 Iter 2690, Minibatch Loss= 0.1778, Training Accuracy= 0.9528, Minibatch error= 4.7%\n",
      "2017-03-30 06:33:41,072 Iter 2695, Minibatch Loss= 0.1590, Training Accuracy= 0.9543, Minibatch error= 4.6%\n",
      "2017-03-30 06:33:50,444 Epoch 26, Average loss: 0.1839, learning rate: 0.0010\n",
      "2017-03-30 06:33:54,221 Verification error= 4.3%, loss= 0.1182\n",
      "2017-03-30 06:33:58,994 Iter 2700, Minibatch Loss= 0.1319, Training Accuracy= 0.9646, Minibatch error= 3.5%\n",
      "2017-03-30 06:34:11,263 Iter 2705, Minibatch Loss= 0.4320, Training Accuracy= 0.7844, Minibatch error= 21.6%\n",
      "2017-03-30 06:34:23,532 Iter 2710, Minibatch Loss= 0.0745, Training Accuracy= 0.9959, Minibatch error= 0.4%\n",
      "2017-03-30 06:34:35,845 Iter 2715, Minibatch Loss= 0.1147, Training Accuracy= 0.9664, Minibatch error= 3.4%\n",
      "2017-03-30 06:34:48,192 Iter 2720, Minibatch Loss= 0.2280, Training Accuracy= 0.9036, Minibatch error= 9.6%\n",
      "2017-03-30 06:35:00,540 Iter 2725, Minibatch Loss= 0.3097, Training Accuracy= 0.8712, Minibatch error= 12.9%\n",
      "2017-03-30 06:35:12,883 Iter 2730, Minibatch Loss= 0.3405, Training Accuracy= 0.8491, Minibatch error= 15.1%\n",
      "2017-03-30 06:35:25,202 Iter 2735, Minibatch Loss= 0.1676, Training Accuracy= 0.9654, Minibatch error= 3.5%\n",
      "2017-03-30 06:35:37,502 Iter 2740, Minibatch Loss= 0.0648, Training Accuracy= 0.9973, Minibatch error= 0.3%\n",
      "2017-03-30 06:35:49,825 Iter 2745, Minibatch Loss= 0.0933, Training Accuracy= 0.9528, Minibatch error= 4.7%\n",
      "2017-03-30 06:36:02,132 Iter 2750, Minibatch Loss= 0.0654, Training Accuracy= 0.9952, Minibatch error= 0.5%\n",
      "2017-03-30 06:36:14,487 Iter 2755, Minibatch Loss= 0.3176, Training Accuracy= 0.8777, Minibatch error= 12.2%\n",
      "2017-03-30 06:36:26,792 Iter 2760, Minibatch Loss= 0.1510, Training Accuracy= 0.9502, Minibatch error= 5.0%\n",
      "2017-03-30 06:36:39,088 Iter 2765, Minibatch Loss= 0.3548, Training Accuracy= 0.7952, Minibatch error= 20.5%\n",
      "2017-03-30 06:36:51,434 Iter 2770, Minibatch Loss= 0.1452, Training Accuracy= 0.9840, Minibatch error= 1.6%\n",
      "2017-03-30 06:37:03,721 Iter 2775, Minibatch Loss= 0.1492, Training Accuracy= 0.9728, Minibatch error= 2.7%\n",
      "2017-03-30 06:37:16,024 Iter 2780, Minibatch Loss= 0.1115, Training Accuracy= 0.9756, Minibatch error= 2.4%\n",
      "2017-03-30 06:37:28,339 Iter 2785, Minibatch Loss= 0.1334, Training Accuracy= 0.9368, Minibatch error= 6.3%\n",
      "2017-03-30 06:37:40,672 Iter 2790, Minibatch Loss= 0.3423, Training Accuracy= 0.8221, Minibatch error= 17.8%\n",
      "2017-03-30 06:37:53,065 Iter 2795, Minibatch Loss= 0.1311, Training Accuracy= 0.9628, Minibatch error= 3.7%\n",
      "2017-03-30 06:38:02,580 Epoch 27, Average loss: 0.2198, learning rate: 0.0010\n",
      "2017-03-30 06:38:06,483 Verification error= 4.7%, loss= 0.1241\n",
      "2017-03-30 06:38:11,591 Iter 2800, Minibatch Loss= 0.0538, Training Accuracy= 0.9915, Minibatch error= 0.8%\n",
      "2017-03-30 06:38:24,074 Iter 2805, Minibatch Loss= 0.2122, Training Accuracy= 0.9184, Minibatch error= 8.2%\n",
      "2017-03-30 06:38:36,503 Iter 2810, Minibatch Loss= 0.0816, Training Accuracy= 0.9942, Minibatch error= 0.6%\n",
      "2017-03-30 06:38:49,055 Iter 2815, Minibatch Loss= 0.0519, Training Accuracy= 0.9912, Minibatch error= 0.9%\n",
      "2017-03-30 06:39:01,538 Iter 2820, Minibatch Loss= 0.1160, Training Accuracy= 0.9691, Minibatch error= 3.1%\n",
      "2017-03-30 06:39:14,022 Iter 2825, Minibatch Loss= 0.1249, Training Accuracy= 0.9509, Minibatch error= 4.9%\n",
      "2017-03-30 06:39:26,564 Iter 2830, Minibatch Loss= 0.0857, Training Accuracy= 0.9770, Minibatch error= 2.3%\n",
      "2017-03-30 06:39:39,096 Iter 2835, Minibatch Loss= 0.0319, Training Accuracy= 0.9936, Minibatch error= 0.6%\n",
      "2017-03-30 06:39:51,769 Iter 2840, Minibatch Loss= 0.0210, Training Accuracy= 0.9984, Minibatch error= 0.2%\n",
      "2017-03-30 06:40:04,405 Iter 2845, Minibatch Loss= 0.2123, Training Accuracy= 0.8822, Minibatch error= 11.8%\n",
      "2017-03-30 06:40:17,024 Iter 2850, Minibatch Loss= 0.0639, Training Accuracy= 0.9836, Minibatch error= 1.6%\n",
      "2017-03-30 06:40:29,614 Iter 2855, Minibatch Loss= 0.0770, Training Accuracy= 0.9860, Minibatch error= 1.4%\n",
      "2017-03-30 06:40:42,378 Iter 2860, Minibatch Loss= 0.1544, Training Accuracy= 0.9595, Minibatch error= 4.0%\n",
      "2017-03-30 06:40:55,101 Iter 2865, Minibatch Loss= 0.2666, Training Accuracy= 0.9063, Minibatch error= 9.4%\n",
      "2017-03-30 06:41:07,931 Iter 2870, Minibatch Loss= 0.2424, Training Accuracy= 0.9176, Minibatch error= 8.2%\n",
      "2017-03-30 06:41:20,702 Iter 2875, Minibatch Loss= 0.1666, Training Accuracy= 0.9757, Minibatch error= 2.4%\n",
      "2017-03-30 06:41:33,698 Iter 2880, Minibatch Loss= 0.2978, Training Accuracy= 0.9075, Minibatch error= 9.2%\n",
      "2017-03-30 06:41:46,643 Iter 2885, Minibatch Loss= 0.2141, Training Accuracy= 0.9612, Minibatch error= 3.9%\n",
      "2017-03-30 06:41:59,554 Iter 2890, Minibatch Loss= 0.1737, Training Accuracy= 0.9733, Minibatch error= 2.7%\n",
      "2017-03-30 06:42:12,574 Iter 2895, Minibatch Loss= 0.0538, Training Accuracy= 0.9974, Minibatch error= 0.3%\n",
      "2017-03-30 06:42:22,470 Epoch 28, Average loss: 0.1895, learning rate: 0.0010\n",
      "2017-03-30 06:42:26,514 Verification error= 4.0%, loss= 0.1084\n",
      "2017-03-30 06:42:31,745 Iter 2900, Minibatch Loss= 0.1028, Training Accuracy= 0.9729, Minibatch error= 2.7%\n",
      "2017-03-30 06:42:44,852 Iter 2905, Minibatch Loss= 0.0578, Training Accuracy= 0.9904, Minibatch error= 1.0%\n",
      "2017-03-30 06:42:57,765 Iter 2910, Minibatch Loss= 0.0969, Training Accuracy= 0.9842, Minibatch error= 1.6%\n",
      "2017-03-30 06:43:10,777 Iter 2915, Minibatch Loss= 0.1800, Training Accuracy= 0.9577, Minibatch error= 4.2%\n",
      "2017-03-30 06:43:23,790 Iter 2920, Minibatch Loss= 0.1877, Training Accuracy= 0.9434, Minibatch error= 5.7%\n",
      "2017-03-30 06:43:36,804 Iter 2925, Minibatch Loss= 0.1502, Training Accuracy= 0.9585, Minibatch error= 4.2%\n",
      "2017-03-30 06:43:49,868 Iter 2930, Minibatch Loss= 0.4229, Training Accuracy= 0.7806, Minibatch error= 21.9%\n",
      "2017-03-30 06:44:02,937 Iter 2935, Minibatch Loss= 0.1351, Training Accuracy= 0.9607, Minibatch error= 3.9%\n",
      "2017-03-30 06:44:16,174 Iter 2940, Minibatch Loss= 0.0577, Training Accuracy= 0.9946, Minibatch error= 0.5%\n",
      "2017-03-30 06:44:29,506 Iter 2945, Minibatch Loss= 0.0637, Training Accuracy= 0.9955, Minibatch error= 0.4%\n",
      "2017-03-30 06:44:42,792 Iter 2950, Minibatch Loss= 0.1006, Training Accuracy= 0.9821, Minibatch error= 1.8%\n",
      "2017-03-30 06:44:56,074 Iter 2955, Minibatch Loss= 0.2214, Training Accuracy= 0.9171, Minibatch error= 8.3%\n",
      "2017-03-30 06:45:09,368 Iter 2960, Minibatch Loss= 0.1023, Training Accuracy= 0.9796, Minibatch error= 2.0%\n",
      "2017-03-30 06:45:22,639 Iter 2965, Minibatch Loss= 0.2384, Training Accuracy= 0.9026, Minibatch error= 9.7%\n",
      "2017-03-30 06:45:36,130 Iter 2970, Minibatch Loss= 0.1517, Training Accuracy= 0.9495, Minibatch error= 5.1%\n",
      "2017-03-30 06:45:49,593 Iter 2975, Minibatch Loss= 0.1937, Training Accuracy= 0.9404, Minibatch error= 6.0%\n",
      "2017-03-30 06:46:03,039 Iter 2980, Minibatch Loss= 0.0472, Training Accuracy= 0.9971, Minibatch error= 0.3%\n",
      "2017-03-30 06:46:16,628 Iter 2985, Minibatch Loss= 0.4690, Training Accuracy= 0.8092, Minibatch error= 19.1%\n",
      "2017-03-30 06:46:30,136 Iter 2990, Minibatch Loss= 0.1126, Training Accuracy= 0.9665, Minibatch error= 3.3%\n",
      "2017-03-30 06:46:43,648 Iter 2995, Minibatch Loss= 0.1164, Training Accuracy= 0.9725, Minibatch error= 2.8%\n",
      "2017-03-30 06:46:53,946 Epoch 29, Average loss: 0.2059, learning rate: 0.0010\n",
      "2017-03-30 06:46:58,253 Verification error= 4.0%, loss= 0.1758\n",
      "2017-03-30 06:47:03,442 Iter 3000, Minibatch Loss= 0.1281, Training Accuracy= 0.9795, Minibatch error= 2.0%\n",
      "2017-03-30 06:47:17,063 Iter 3005, Minibatch Loss= 0.1477, Training Accuracy= 0.9718, Minibatch error= 2.8%\n",
      "2017-03-30 06:47:30,721 Iter 3010, Minibatch Loss= 0.4811, Training Accuracy= 0.7988, Minibatch error= 20.1%\n",
      "2017-03-30 06:47:44,431 Iter 3015, Minibatch Loss= 0.0845, Training Accuracy= 0.9978, Minibatch error= 0.2%\n",
      "2017-03-30 06:47:58,175 Iter 3020, Minibatch Loss= 0.0998, Training Accuracy= 0.9493, Minibatch error= 5.1%\n",
      "2017-03-30 06:48:12,128 Iter 3025, Minibatch Loss= 0.4913, Training Accuracy= 0.7903, Minibatch error= 21.0%\n",
      "2017-03-30 06:48:26,483 Iter 3030, Minibatch Loss= 0.1736, Training Accuracy= 0.9180, Minibatch error= 8.2%\n",
      "2017-03-30 06:48:40,878 Iter 3035, Minibatch Loss= 0.0773, Training Accuracy= 0.9803, Minibatch error= 2.0%\n",
      "2017-03-30 06:48:54,854 Iter 3040, Minibatch Loss= 0.0977, Training Accuracy= 0.9663, Minibatch error= 3.4%\n",
      "2017-03-30 06:49:08,822 Iter 3045, Minibatch Loss= 0.0824, Training Accuracy= 0.9878, Minibatch error= 1.2%\n",
      "2017-03-30 06:49:22,756 Iter 3050, Minibatch Loss= 0.0966, Training Accuracy= 0.9695, Minibatch error= 3.0%\n",
      "2017-03-30 06:49:36,759 Iter 3055, Minibatch Loss= 0.0366, Training Accuracy= 0.9933, Minibatch error= 0.7%\n",
      "2017-03-30 06:49:51,964 Iter 3060, Minibatch Loss= 0.0576, Training Accuracy= 0.9894, Minibatch error= 1.1%\n",
      "2017-03-30 06:50:06,347 Iter 3065, Minibatch Loss= 0.0727, Training Accuracy= 0.9941, Minibatch error= 0.6%\n",
      "2017-03-30 06:50:20,447 Iter 3070, Minibatch Loss= 0.0919, Training Accuracy= 0.9912, Minibatch error= 0.9%\n",
      "2017-03-30 06:50:34,508 Iter 3075, Minibatch Loss= 0.2169, Training Accuracy= 0.9424, Minibatch error= 5.8%\n",
      "2017-03-30 06:50:48,457 Iter 3080, Minibatch Loss= 0.2223, Training Accuracy= 0.9053, Minibatch error= 9.5%\n",
      "2017-03-30 06:51:02,438 Iter 3085, Minibatch Loss= 0.1831, Training Accuracy= 0.9636, Minibatch error= 3.6%\n",
      "2017-03-30 06:51:16,439 Iter 3090, Minibatch Loss= 0.0622, Training Accuracy= 0.9968, Minibatch error= 0.3%\n",
      "2017-03-30 06:51:30,388 Iter 3095, Minibatch Loss= 0.2957, Training Accuracy= 0.8700, Minibatch error= 13.0%\n",
      "2017-03-30 06:51:41,154 Epoch 30, Average loss: 0.1854, learning rate: 0.0010\n",
      "2017-03-30 06:51:45,532 Verification error= 3.8%, loss= 0.1235\n",
      "2017-03-30 06:51:51,110 Iter 3100, Minibatch Loss= 0.0490, Training Accuracy= 0.9961, Minibatch error= 0.4%\n",
      "2017-03-30 06:52:05,185 Iter 3105, Minibatch Loss= 0.0803, Training Accuracy= 0.9865, Minibatch error= 1.4%\n",
      "2017-03-30 06:52:19,325 Iter 3110, Minibatch Loss= 0.1659, Training Accuracy= 0.9380, Minibatch error= 6.2%\n",
      "2017-03-30 06:52:33,393 Iter 3115, Minibatch Loss= 0.7000, Training Accuracy= 0.7223, Minibatch error= 27.8%\n",
      "2017-03-30 06:52:47,399 Iter 3120, Minibatch Loss= 0.0984, Training Accuracy= 0.9763, Minibatch error= 2.4%\n",
      "2017-03-30 06:53:00,976 Iter 3125, Minibatch Loss= 0.0837, Training Accuracy= 0.9788, Minibatch error= 2.1%\n",
      "2017-03-30 06:53:14,719 Iter 3130, Minibatch Loss= 0.1640, Training Accuracy= 0.9193, Minibatch error= 8.1%\n",
      "2017-03-30 06:53:28,367 Iter 3135, Minibatch Loss= 0.0552, Training Accuracy= 0.9879, Minibatch error= 1.2%\n",
      "2017-03-30 06:53:42,023 Iter 3140, Minibatch Loss= 0.0697, Training Accuracy= 0.9833, Minibatch error= 1.7%\n",
      "2017-03-30 06:53:55,698 Iter 3145, Minibatch Loss= 0.0600, Training Accuracy= 0.9967, Minibatch error= 0.3%\n",
      "2017-03-30 06:54:09,345 Iter 3150, Minibatch Loss= 0.1057, Training Accuracy= 0.9562, Minibatch error= 4.4%\n",
      "2017-03-30 06:54:23,269 Iter 3155, Minibatch Loss= 0.1319, Training Accuracy= 0.9536, Minibatch error= 4.6%\n",
      "2017-03-30 06:54:36,955 Iter 3160, Minibatch Loss= 0.2343, Training Accuracy= 0.9112, Minibatch error= 8.9%\n",
      "2017-03-30 06:54:50,702 Iter 3165, Minibatch Loss= 0.2261, Training Accuracy= 0.8928, Minibatch error= 10.7%\n",
      "2017-03-30 06:55:04,506 Iter 3170, Minibatch Loss= 0.0937, Training Accuracy= 0.9669, Minibatch error= 3.3%\n",
      "2017-03-30 06:55:18,259 Iter 3175, Minibatch Loss= 0.0715, Training Accuracy= 0.9939, Minibatch error= 0.6%\n",
      "2017-03-30 06:55:31,930 Iter 3180, Minibatch Loss= 0.0959, Training Accuracy= 0.9729, Minibatch error= 2.7%\n",
      "2017-03-30 06:55:45,594 Iter 3185, Minibatch Loss= 0.1414, Training Accuracy= 0.9734, Minibatch error= 2.7%\n",
      "2017-03-30 06:55:59,391 Iter 3190, Minibatch Loss= 0.1294, Training Accuracy= 0.9726, Minibatch error= 2.7%\n",
      "2017-03-30 06:56:13,147 Iter 3195, Minibatch Loss= 0.6677, Training Accuracy= 0.6648, Minibatch error= 33.5%\n",
      "2017-03-30 06:56:23,948 Epoch 31, Average loss: 0.1742, learning rate: 0.0010\n",
      "2017-03-30 06:56:28,250 Verification error= 3.9%, loss= 0.1404\n",
      "2017-03-30 06:56:34,002 Iter 3200, Minibatch Loss= 0.2110, Training Accuracy= 0.9541, Minibatch error= 4.6%\n",
      "2017-03-30 06:56:48,875 Iter 3205, Minibatch Loss= 0.2299, Training Accuracy= 0.9226, Minibatch error= 7.7%\n",
      "2017-03-30 06:57:02,961 Iter 3210, Minibatch Loss= 0.1663, Training Accuracy= 0.9569, Minibatch error= 4.3%\n",
      "2017-03-30 06:57:16,964 Iter 3215, Minibatch Loss= 0.3554, Training Accuracy= 0.8232, Minibatch error= 17.7%\n",
      "2017-03-30 06:57:30,930 Iter 3220, Minibatch Loss= 0.0872, Training Accuracy= 0.9912, Minibatch error= 0.9%\n",
      "2017-03-30 06:57:44,824 Iter 3225, Minibatch Loss= 0.1835, Training Accuracy= 0.9552, Minibatch error= 4.5%\n",
      "2017-03-30 06:58:00,019 Iter 3230, Minibatch Loss= 0.0741, Training Accuracy= 0.9916, Minibatch error= 0.8%\n",
      "2017-03-30 06:58:15,282 Iter 3235, Minibatch Loss= 0.0450, Training Accuracy= 0.9981, Minibatch error= 0.2%\n",
      "2017-03-30 06:58:30,639 Iter 3240, Minibatch Loss= 0.1579, Training Accuracy= 0.9730, Minibatch error= 2.7%\n",
      "2017-03-30 06:58:44,745 Iter 3245, Minibatch Loss= 0.2469, Training Accuracy= 0.9064, Minibatch error= 9.4%\n",
      "2017-03-30 06:58:58,714 Iter 3250, Minibatch Loss= 0.1982, Training Accuracy= 0.9726, Minibatch error= 2.7%\n",
      "2017-03-30 06:59:12,621 Iter 3255, Minibatch Loss= 0.6586, Training Accuracy= 0.5724, Minibatch error= 42.8%\n",
      "2017-03-30 06:59:26,613 Iter 3260, Minibatch Loss= 0.1693, Training Accuracy= 0.9518, Minibatch error= 4.8%\n",
      "2017-03-30 06:59:40,551 Iter 3265, Minibatch Loss= 0.1377, Training Accuracy= 0.9702, Minibatch error= 3.0%\n",
      "2017-03-30 06:59:54,503 Iter 3270, Minibatch Loss= 0.0783, Training Accuracy= 0.9868, Minibatch error= 1.3%\n",
      "2017-03-30 07:00:08,562 Iter 3275, Minibatch Loss= 0.0662, Training Accuracy= 0.9901, Minibatch error= 1.0%\n",
      "2017-03-30 07:00:22,507 Iter 3280, Minibatch Loss= 0.0652, Training Accuracy= 0.9899, Minibatch error= 1.0%\n",
      "2017-03-30 07:00:36,635 Iter 3285, Minibatch Loss= 0.2015, Training Accuracy= 0.8953, Minibatch error= 10.5%\n",
      "2017-03-30 07:00:50,682 Iter 3290, Minibatch Loss= 0.1164, Training Accuracy= 0.9850, Minibatch error= 1.5%\n",
      "2017-03-30 07:01:04,704 Iter 3295, Minibatch Loss= 0.1363, Training Accuracy= 0.9555, Minibatch error= 4.4%\n",
      "2017-03-30 07:01:15,430 Epoch 32, Average loss: 0.1967, learning rate: 0.0010\n",
      "2017-03-30 07:01:19,691 Verification error= 4.2%, loss= 0.1290\n",
      "2017-03-30 07:01:25,139 Iter 3300, Minibatch Loss= 0.2155, Training Accuracy= 0.9298, Minibatch error= 7.0%\n",
      "2017-03-30 07:01:39,246 Iter 3305, Minibatch Loss= 0.1029, Training Accuracy= 0.9593, Minibatch error= 4.1%\n",
      "2017-03-30 07:01:53,371 Iter 3310, Minibatch Loss= 0.0542, Training Accuracy= 0.9935, Minibatch error= 0.7%\n",
      "2017-03-30 07:02:07,460 Iter 3315, Minibatch Loss= 0.1736, Training Accuracy= 0.9222, Minibatch error= 7.8%\n",
      "2017-03-30 07:02:21,789 Iter 3320, Minibatch Loss= 0.1866, Training Accuracy= 0.9364, Minibatch error= 6.4%\n",
      "2017-03-30 07:02:36,026 Iter 3325, Minibatch Loss= 0.2637, Training Accuracy= 0.8874, Minibatch error= 11.3%\n",
      "2017-03-30 07:02:50,366 Iter 3330, Minibatch Loss= 0.1210, Training Accuracy= 0.9560, Minibatch error= 4.4%\n",
      "2017-03-30 07:03:04,459 Iter 3335, Minibatch Loss= 0.3594, Training Accuracy= 0.8500, Minibatch error= 15.0%\n",
      "2017-03-30 07:03:18,654 Iter 3340, Minibatch Loss= 0.0681, Training Accuracy= 0.9816, Minibatch error= 1.8%\n",
      "2017-03-30 07:03:32,876 Iter 3345, Minibatch Loss= 0.5405, Training Accuracy= 0.7280, Minibatch error= 27.2%\n",
      "2017-03-30 07:03:47,087 Iter 3350, Minibatch Loss= 0.4626, Training Accuracy= 0.7316, Minibatch error= 26.8%\n",
      "2017-03-30 07:04:01,286 Iter 3355, Minibatch Loss= 0.2592, Training Accuracy= 0.9278, Minibatch error= 7.2%\n",
      "2017-03-30 07:04:15,327 Iter 3360, Minibatch Loss= 0.2286, Training Accuracy= 0.8914, Minibatch error= 10.9%\n",
      "2017-03-30 07:04:29,472 Iter 3365, Minibatch Loss= 0.1119, Training Accuracy= 0.9952, Minibatch error= 0.5%\n",
      "2017-03-30 07:04:43,587 Iter 3370, Minibatch Loss= 0.1555, Training Accuracy= 0.9904, Minibatch error= 1.0%\n",
      "2017-03-30 07:04:57,746 Iter 3375, Minibatch Loss= 0.1357, Training Accuracy= 0.9663, Minibatch error= 3.4%\n",
      "2017-03-30 07:05:11,964 Iter 3380, Minibatch Loss= 0.3154, Training Accuracy= 0.8425, Minibatch error= 15.7%\n",
      "2017-03-30 07:05:26,198 Iter 3385, Minibatch Loss= 0.1787, Training Accuracy= 0.9120, Minibatch error= 8.8%\n",
      "2017-03-30 07:05:40,363 Iter 3390, Minibatch Loss= 0.0570, Training Accuracy= 0.9908, Minibatch error= 0.9%\n",
      "2017-03-30 07:05:54,559 Iter 3395, Minibatch Loss= 0.1863, Training Accuracy= 0.9230, Minibatch error= 7.7%\n",
      "2017-03-30 07:06:05,518 Epoch 33, Average loss: 0.2087, learning rate: 0.0010\n",
      "2017-03-30 07:06:09,896 Verification error= 4.0%, loss= 0.1169\n",
      "2017-03-30 07:06:15,694 Iter 3400, Minibatch Loss= 0.1939, Training Accuracy= 0.9234, Minibatch error= 7.7%\n",
      "2017-03-30 07:06:30,049 Iter 3405, Minibatch Loss= 0.0434, Training Accuracy= 0.9910, Minibatch error= 0.9%\n",
      "2017-03-30 07:06:44,532 Iter 3410, Minibatch Loss= 0.7437, Training Accuracy= 0.7139, Minibatch error= 28.6%\n",
      "2017-03-30 07:06:58,808 Iter 3415, Minibatch Loss= 0.1952, Training Accuracy= 0.9187, Minibatch error= 8.1%\n",
      "2017-03-30 07:07:13,139 Iter 3420, Minibatch Loss= 0.1241, Training Accuracy= 0.9653, Minibatch error= 3.5%\n",
      "2017-03-30 07:07:27,544 Iter 3425, Minibatch Loss= 0.0744, Training Accuracy= 0.9881, Minibatch error= 1.2%\n",
      "2017-03-30 07:07:41,928 Iter 3430, Minibatch Loss= 0.0583, Training Accuracy= 0.9934, Minibatch error= 0.7%\n",
      "2017-03-30 07:07:56,279 Iter 3435, Minibatch Loss= 0.1179, Training Accuracy= 0.9643, Minibatch error= 3.6%\n",
      "2017-03-30 07:08:10,558 Iter 3440, Minibatch Loss= 0.0825, Training Accuracy= 0.9793, Minibatch error= 2.1%\n",
      "2017-03-30 07:08:24,912 Iter 3445, Minibatch Loss= 0.3392, Training Accuracy= 0.8756, Minibatch error= 12.4%\n",
      "2017-03-30 07:08:39,213 Iter 3450, Minibatch Loss= 0.0874, Training Accuracy= 0.9847, Minibatch error= 1.5%\n",
      "2017-03-30 07:08:53,693 Iter 3455, Minibatch Loss= 0.0634, Training Accuracy= 0.9915, Minibatch error= 0.8%\n",
      "2017-03-30 07:09:07,971 Iter 3460, Minibatch Loss= 0.2080, Training Accuracy= 0.9252, Minibatch error= 7.5%\n",
      "2017-03-30 07:09:22,308 Iter 3465, Minibatch Loss= 0.1840, Training Accuracy= 0.9273, Minibatch error= 7.3%\n",
      "2017-03-30 07:09:36,535 Iter 3470, Minibatch Loss= 0.3743, Training Accuracy= 0.8446, Minibatch error= 15.5%\n",
      "2017-03-30 07:09:50,906 Iter 3475, Minibatch Loss= 0.0737, Training Accuracy= 0.9805, Minibatch error= 1.9%\n",
      "2017-03-30 07:10:05,274 Iter 3480, Minibatch Loss= 0.1196, Training Accuracy= 0.9681, Minibatch error= 3.2%\n",
      "2017-03-30 07:10:19,575 Iter 3485, Minibatch Loss= 0.2652, Training Accuracy= 0.8869, Minibatch error= 11.3%\n",
      "2017-03-30 07:10:33,979 Iter 3490, Minibatch Loss= 0.1318, Training Accuracy= 0.9795, Minibatch error= 2.1%\n",
      "2017-03-30 07:10:48,452 Iter 3495, Minibatch Loss= 0.0275, Training Accuracy= 0.9961, Minibatch error= 0.4%\n",
      "2017-03-30 07:10:59,434 Epoch 34, Average loss: 0.1549, learning rate: 0.0010\n",
      "2017-03-30 07:11:03,757 Verification error= 3.8%, loss= 0.1201\n",
      "2017-03-30 07:11:09,717 Iter 3500, Minibatch Loss= 0.0704, Training Accuracy= 0.9855, Minibatch error= 1.4%\n",
      "2017-03-30 07:11:24,105 Iter 3505, Minibatch Loss= 0.7404, Training Accuracy= 0.7449, Minibatch error= 25.5%\n",
      "2017-03-30 07:11:38,422 Iter 3510, Minibatch Loss= 0.1167, Training Accuracy= 0.9601, Minibatch error= 4.0%\n",
      "2017-03-30 07:11:52,827 Iter 3515, Minibatch Loss= 0.2696, Training Accuracy= 0.8939, Minibatch error= 10.6%\n",
      "2017-03-30 07:12:07,184 Iter 3520, Minibatch Loss= 0.1629, Training Accuracy= 0.9567, Minibatch error= 4.3%\n",
      "2017-03-30 07:12:21,630 Iter 3525, Minibatch Loss= 0.1859, Training Accuracy= 0.9755, Minibatch error= 2.4%\n",
      "2017-03-30 07:12:34,792 Iter 3530, Minibatch Loss= 0.2332, Training Accuracy= 0.9385, Minibatch error= 6.1%\n",
      "2017-03-30 07:12:47,684 Iter 3535, Minibatch Loss= 0.2429, Training Accuracy= 0.9237, Minibatch error= 7.6%\n",
      "2017-03-30 07:13:00,531 Iter 3540, Minibatch Loss= 0.1332, Training Accuracy= 0.9433, Minibatch error= 5.7%\n",
      "2017-03-30 07:13:13,373 Iter 3545, Minibatch Loss= 0.0751, Training Accuracy= 0.9745, Minibatch error= 2.6%\n",
      "2017-03-30 07:13:26,222 Iter 3550, Minibatch Loss= 0.0840, Training Accuracy= 0.9763, Minibatch error= 2.4%\n",
      "2017-03-30 07:13:39,131 Iter 3555, Minibatch Loss= 0.1667, Training Accuracy= 0.9817, Minibatch error= 1.8%\n",
      "2017-03-30 07:13:52,002 Iter 3560, Minibatch Loss= 0.0903, Training Accuracy= 0.9753, Minibatch error= 2.5%\n",
      "2017-03-30 07:14:04,930 Iter 3565, Minibatch Loss= 0.0421, Training Accuracy= 0.9954, Minibatch error= 0.5%\n",
      "2017-03-30 07:14:17,886 Iter 3570, Minibatch Loss= 0.0871, Training Accuracy= 0.9813, Minibatch error= 1.9%\n",
      "2017-03-30 07:14:30,753 Iter 3575, Minibatch Loss= 0.1092, Training Accuracy= 0.9658, Minibatch error= 3.4%\n",
      "2017-03-30 07:14:43,666 Iter 3580, Minibatch Loss= 0.1882, Training Accuracy= 0.9323, Minibatch error= 6.8%\n",
      "2017-03-30 07:14:56,615 Iter 3585, Minibatch Loss= 0.0974, Training Accuracy= 0.9705, Minibatch error= 3.0%\n",
      "2017-03-30 07:15:09,488 Iter 3590, Minibatch Loss= 0.0529, Training Accuracy= 0.9899, Minibatch error= 1.0%\n",
      "2017-03-30 07:15:22,367 Iter 3595, Minibatch Loss= 0.1069, Training Accuracy= 0.9564, Minibatch error= 4.4%\n",
      "2017-03-30 07:15:32,306 Epoch 35, Average loss: 0.1758, learning rate: 0.0010\n",
      "2017-03-30 07:15:36,141 Verification error= 3.8%, loss= 0.1063\n",
      "2017-03-30 07:15:41,500 Iter 3600, Minibatch Loss= 0.0752, Training Accuracy= 0.9884, Minibatch error= 1.2%\n",
      "2017-03-30 07:15:54,565 Iter 3605, Minibatch Loss= 0.0948, Training Accuracy= 0.9850, Minibatch error= 1.5%\n",
      "2017-03-30 07:16:07,718 Iter 3610, Minibatch Loss= 0.2400, Training Accuracy= 0.9013, Minibatch error= 9.9%\n",
      "2017-03-30 07:16:20,840 Iter 3615, Minibatch Loss= 0.1324, Training Accuracy= 0.9478, Minibatch error= 5.2%\n",
      "2017-03-30 07:16:34,010 Iter 3620, Minibatch Loss= 0.1610, Training Accuracy= 0.9416, Minibatch error= 5.8%\n",
      "2017-03-30 07:16:47,209 Iter 3625, Minibatch Loss= 0.0886, Training Accuracy= 0.9819, Minibatch error= 1.8%\n",
      "2017-03-30 07:17:00,335 Iter 3630, Minibatch Loss= 0.3044, Training Accuracy= 0.8565, Minibatch error= 14.4%\n",
      "2017-03-30 07:17:13,491 Iter 3635, Minibatch Loss= 0.0904, Training Accuracy= 0.9692, Minibatch error= 3.1%\n",
      "2017-03-30 07:17:26,630 Iter 3640, Minibatch Loss= 0.1701, Training Accuracy= 0.9572, Minibatch error= 4.3%\n",
      "2017-03-30 07:17:39,783 Iter 3645, Minibatch Loss= 0.0660, Training Accuracy= 0.9856, Minibatch error= 1.4%\n",
      "2017-03-30 07:17:52,772 Iter 3650, Minibatch Loss= 0.1600, Training Accuracy= 0.9438, Minibatch error= 5.6%\n",
      "2017-03-30 07:18:05,742 Iter 3655, Minibatch Loss= 0.1008, Training Accuracy= 0.9836, Minibatch error= 1.6%\n",
      "2017-03-30 07:18:18,707 Iter 3660, Minibatch Loss= 0.3962, Training Accuracy= 0.7887, Minibatch error= 21.1%\n",
      "2017-03-30 07:18:31,702 Iter 3665, Minibatch Loss= 0.1473, Training Accuracy= 0.9631, Minibatch error= 3.7%\n",
      "2017-03-30 07:18:44,806 Iter 3670, Minibatch Loss= 0.2053, Training Accuracy= 0.9535, Minibatch error= 4.7%\n",
      "2017-03-30 07:18:57,901 Iter 3675, Minibatch Loss= 0.2506, Training Accuracy= 0.8941, Minibatch error= 10.6%\n",
      "2017-03-30 07:19:11,017 Iter 3680, Minibatch Loss= 0.1635, Training Accuracy= 0.9515, Minibatch error= 4.8%\n",
      "2017-03-30 07:19:24,163 Iter 3685, Minibatch Loss= 0.0612, Training Accuracy= 0.9820, Minibatch error= 1.8%\n",
      "2017-03-30 07:19:37,341 Iter 3690, Minibatch Loss= 0.2697, Training Accuracy= 0.9184, Minibatch error= 8.2%\n",
      "2017-03-30 07:19:50,630 Iter 3695, Minibatch Loss= 0.2213, Training Accuracy= 0.9170, Minibatch error= 8.3%\n",
      "2017-03-30 07:20:00,835 Epoch 36, Average loss: 0.2074, learning rate: 0.0010\n",
      "2017-03-30 07:20:04,823 Verification error= 3.8%, loss= 0.1237\n",
      "2017-03-30 07:20:10,622 Iter 3700, Minibatch Loss= 0.0550, Training Accuracy= 0.9965, Minibatch error= 0.4%\n",
      "2017-03-30 07:20:23,981 Iter 3705, Minibatch Loss= 0.1591, Training Accuracy= 0.9447, Minibatch error= 5.5%\n",
      "2017-03-30 07:20:37,357 Iter 3710, Minibatch Loss= 0.1162, Training Accuracy= 0.9621, Minibatch error= 3.8%\n",
      "2017-03-30 07:20:51,871 Iter 3715, Minibatch Loss= 0.2676, Training Accuracy= 0.8978, Minibatch error= 10.2%\n",
      "2017-03-30 07:21:05,323 Iter 3720, Minibatch Loss= 0.1385, Training Accuracy= 0.9453, Minibatch error= 5.5%\n",
      "2017-03-30 07:21:18,945 Iter 3725, Minibatch Loss= 0.1091, Training Accuracy= 0.9657, Minibatch error= 3.4%\n",
      "2017-03-30 07:21:32,651 Iter 3730, Minibatch Loss= 0.1048, Training Accuracy= 0.9742, Minibatch error= 2.6%\n",
      "2017-03-30 07:21:46,445 Iter 3735, Minibatch Loss= 0.0932, Training Accuracy= 0.9732, Minibatch error= 2.7%\n",
      "2017-03-30 07:22:00,233 Iter 3740, Minibatch Loss= 0.1624, Training Accuracy= 0.9460, Minibatch error= 5.4%\n",
      "2017-03-30 07:22:14,074 Iter 3745, Minibatch Loss= 0.0576, Training Accuracy= 0.9946, Minibatch error= 0.5%\n",
      "2017-03-30 07:22:27,864 Iter 3750, Minibatch Loss= 0.3052, Training Accuracy= 0.8486, Minibatch error= 15.1%\n",
      "2017-03-30 07:22:41,704 Iter 3755, Minibatch Loss= 0.1632, Training Accuracy= 0.9558, Minibatch error= 4.4%\n",
      "2017-03-30 07:22:55,783 Iter 3760, Minibatch Loss= 0.1640, Training Accuracy= 0.9506, Minibatch error= 4.9%\n",
      "2017-03-30 07:23:09,662 Iter 3765, Minibatch Loss= 0.1884, Training Accuracy= 0.9295, Minibatch error= 7.0%\n",
      "2017-03-30 07:23:23,533 Iter 3770, Minibatch Loss= 0.1378, Training Accuracy= 0.9656, Minibatch error= 3.4%\n",
      "2017-03-30 07:23:37,396 Iter 3775, Minibatch Loss= 0.1161, Training Accuracy= 0.9714, Minibatch error= 2.9%\n",
      "2017-03-30 07:23:51,294 Iter 3780, Minibatch Loss= 0.2020, Training Accuracy= 0.9244, Minibatch error= 7.6%\n",
      "2017-03-30 07:24:05,217 Iter 3785, Minibatch Loss= 0.0593, Training Accuracy= 0.9920, Minibatch error= 0.8%\n",
      "2017-03-30 07:24:19,068 Iter 3790, Minibatch Loss= 0.0569, Training Accuracy= 0.9794, Minibatch error= 2.1%\n",
      "2017-03-30 07:24:32,983 Iter 3795, Minibatch Loss= 0.5403, Training Accuracy= 0.7822, Minibatch error= 21.8%\n",
      "2017-03-30 07:24:43,684 Epoch 37, Average loss: 0.1764, learning rate: 0.0010\n",
      "2017-03-30 07:24:47,894 Verification error= 3.9%, loss= 0.1173\n",
      "2017-03-30 07:24:53,587 Iter 3800, Minibatch Loss= 0.0595, Training Accuracy= 0.9947, Minibatch error= 0.5%\n",
      "2017-03-30 07:25:07,626 Iter 3805, Minibatch Loss= 0.1083, Training Accuracy= 0.9809, Minibatch error= 1.9%\n",
      "2017-03-30 07:25:21,727 Iter 3810, Minibatch Loss= 0.2742, Training Accuracy= 0.9225, Minibatch error= 7.8%\n",
      "2017-03-30 07:25:35,842 Iter 3815, Minibatch Loss= 0.2189, Training Accuracy= 0.9271, Minibatch error= 7.3%\n",
      "2017-03-30 07:25:49,913 Iter 3820, Minibatch Loss= 0.1640, Training Accuracy= 0.9664, Minibatch error= 3.4%\n",
      "2017-03-30 07:26:03,907 Iter 3825, Minibatch Loss= 0.2902, Training Accuracy= 0.8652, Minibatch error= 13.5%\n",
      "2017-03-30 07:26:17,885 Iter 3830, Minibatch Loss= 0.2099, Training Accuracy= 0.9207, Minibatch error= 7.9%\n",
      "2017-03-30 07:26:31,997 Iter 3835, Minibatch Loss= 0.1695, Training Accuracy= 0.9600, Minibatch error= 4.0%\n",
      "2017-03-30 07:26:46,218 Iter 3840, Minibatch Loss= 0.0745, Training Accuracy= 0.9833, Minibatch error= 1.7%\n",
      "2017-03-30 07:27:00,405 Iter 3845, Minibatch Loss= 0.1058, Training Accuracy= 0.9655, Minibatch error= 3.4%\n",
      "2017-03-30 07:27:14,613 Iter 3850, Minibatch Loss= 0.0568, Training Accuracy= 0.9843, Minibatch error= 1.6%\n",
      "2017-03-30 07:27:29,118 Iter 3855, Minibatch Loss= 0.4093, Training Accuracy= 0.7700, Minibatch error= 23.0%\n",
      "2017-03-30 07:27:43,307 Iter 3860, Minibatch Loss= 0.6198, Training Accuracy= 0.7851, Minibatch error= 21.5%\n",
      "2017-03-30 07:27:57,657 Iter 3865, Minibatch Loss= 0.1339, Training Accuracy= 0.9573, Minibatch error= 4.3%\n",
      "2017-03-30 07:28:12,002 Iter 3870, Minibatch Loss= 0.0538, Training Accuracy= 0.9806, Minibatch error= 1.9%\n",
      "2017-03-30 07:28:26,393 Iter 3875, Minibatch Loss= 0.0602, Training Accuracy= 0.9906, Minibatch error= 0.9%\n",
      "2017-03-30 07:28:40,758 Iter 3880, Minibatch Loss= 0.1161, Training Accuracy= 0.9641, Minibatch error= 3.6%\n",
      "2017-03-30 07:28:55,121 Iter 3885, Minibatch Loss= 0.1219, Training Accuracy= 0.9551, Minibatch error= 4.5%\n",
      "2017-03-30 07:29:09,447 Iter 3890, Minibatch Loss= 0.1033, Training Accuracy= 0.9739, Minibatch error= 2.6%\n",
      "2017-03-30 07:29:23,847 Iter 3895, Minibatch Loss= 0.0835, Training Accuracy= 0.9821, Minibatch error= 1.8%\n",
      "2017-03-30 07:29:34,962 Epoch 38, Average loss: 0.1751, learning rate: 0.0010\n",
      "2017-03-30 07:29:39,285 Verification error= 3.8%, loss= 0.1333\n",
      "2017-03-30 07:29:45,131 Iter 3900, Minibatch Loss= 0.0841, Training Accuracy= 0.9813, Minibatch error= 1.9%\n",
      "2017-03-30 07:29:59,683 Iter 3905, Minibatch Loss= 0.1577, Training Accuracy= 0.9502, Minibatch error= 5.0%\n",
      "2017-03-30 07:30:14,212 Iter 3910, Minibatch Loss= 0.0630, Training Accuracy= 0.9907, Minibatch error= 0.9%\n",
      "2017-03-30 07:30:28,809 Iter 3915, Minibatch Loss= 0.1956, Training Accuracy= 0.9419, Minibatch error= 5.8%\n",
      "2017-03-30 07:30:43,461 Iter 3920, Minibatch Loss= 0.1442, Training Accuracy= 0.9617, Minibatch error= 3.8%\n",
      "2017-03-30 07:30:58,039 Iter 3925, Minibatch Loss= 0.9852, Training Accuracy= 0.6694, Minibatch error= 33.1%\n",
      "2017-03-30 07:31:12,580 Iter 3930, Minibatch Loss= 0.1897, Training Accuracy= 0.9297, Minibatch error= 7.0%\n",
      "2017-03-30 07:31:26,960 Iter 3935, Minibatch Loss= 0.0991, Training Accuracy= 0.9917, Minibatch error= 0.8%\n",
      "2017-03-30 07:31:41,012 Iter 3940, Minibatch Loss= 0.1641, Training Accuracy= 0.9323, Minibatch error= 6.8%\n",
      "2017-03-30 07:31:55,153 Iter 3945, Minibatch Loss= 0.1480, Training Accuracy= 0.9533, Minibatch error= 4.7%\n",
      "2017-03-30 07:32:09,248 Iter 3950, Minibatch Loss= 0.0977, Training Accuracy= 0.9700, Minibatch error= 3.0%\n",
      "2017-03-30 07:32:23,371 Iter 3955, Minibatch Loss= 0.0866, Training Accuracy= 0.9911, Minibatch error= 0.9%\n",
      "2017-03-30 07:32:37,621 Iter 3960, Minibatch Loss= 0.1975, Training Accuracy= 0.9247, Minibatch error= 7.5%\n",
      "2017-03-30 07:32:52,066 Iter 3965, Minibatch Loss= 0.1627, Training Accuracy= 0.9508, Minibatch error= 4.9%\n",
      "2017-03-30 07:33:06,395 Iter 3970, Minibatch Loss= 0.0997, Training Accuracy= 0.9862, Minibatch error= 1.4%\n",
      "2017-03-30 07:33:20,837 Iter 3975, Minibatch Loss= 0.1769, Training Accuracy= 0.9167, Minibatch error= 8.3%\n",
      "2017-03-30 07:33:35,250 Iter 3980, Minibatch Loss= 0.1104, Training Accuracy= 0.9861, Minibatch error= 1.4%\n",
      "2017-03-30 07:33:49,632 Iter 3985, Minibatch Loss= 0.1646, Training Accuracy= 0.9564, Minibatch error= 4.4%\n",
      "2017-03-30 07:34:04,024 Iter 3990, Minibatch Loss= 0.1184, Training Accuracy= 0.9656, Minibatch error= 3.4%\n",
      "2017-03-30 07:34:18,427 Iter 3995, Minibatch Loss= 0.5059, Training Accuracy= 0.8125, Minibatch error= 18.8%\n",
      "2017-03-30 07:34:29,547 Epoch 39, Average loss: 0.1832, learning rate: 0.0010\n",
      "2017-03-30 07:34:33,949 Verification error= 3.9%, loss= 0.1094\n",
      "2017-03-30 07:34:40,217 Iter 4000, Minibatch Loss= 0.0776, Training Accuracy= 0.9827, Minibatch error= 1.7%\n",
      "2017-03-30 07:34:54,858 Iter 4005, Minibatch Loss= 0.1059, Training Accuracy= 0.9639, Minibatch error= 3.6%\n",
      "2017-03-30 07:35:09,403 Iter 4010, Minibatch Loss= 0.2899, Training Accuracy= 0.8666, Minibatch error= 13.3%\n",
      "2017-03-30 07:35:23,972 Iter 4015, Minibatch Loss= 0.0614, Training Accuracy= 0.9862, Minibatch error= 1.4%\n",
      "2017-03-30 07:35:38,645 Iter 4020, Minibatch Loss= 0.2040, Training Accuracy= 0.9376, Minibatch error= 6.2%\n",
      "2017-03-30 07:35:53,320 Iter 4025, Minibatch Loss= 0.0607, Training Accuracy= 0.9927, Minibatch error= 0.7%\n",
      "2017-03-30 07:36:07,963 Iter 4030, Minibatch Loss= 0.1134, Training Accuracy= 0.9769, Minibatch error= 2.3%\n",
      "2017-03-30 07:36:22,522 Iter 4035, Minibatch Loss= 0.0811, Training Accuracy= 0.9817, Minibatch error= 1.8%\n",
      "2017-03-30 07:36:36,842 Iter 4040, Minibatch Loss= 0.1536, Training Accuracy= 0.9393, Minibatch error= 6.1%\n",
      "2017-03-30 07:36:50,062 Iter 4045, Minibatch Loss= 0.1722, Training Accuracy= 0.9592, Minibatch error= 4.1%\n",
      "2017-03-30 07:37:03,231 Iter 4050, Minibatch Loss= 0.2031, Training Accuracy= 0.9348, Minibatch error= 6.5%\n",
      "2017-03-30 07:37:16,417 Iter 4055, Minibatch Loss= 0.1251, Training Accuracy= 0.9521, Minibatch error= 4.8%\n",
      "2017-03-30 07:37:29,619 Iter 4060, Minibatch Loss= 0.3490, Training Accuracy= 0.8211, Minibatch error= 17.9%\n",
      "2017-03-30 07:37:42,820 Iter 4065, Minibatch Loss= 0.0200, Training Accuracy= 0.9974, Minibatch error= 0.3%\n",
      "2017-03-30 07:37:56,020 Iter 4070, Minibatch Loss= 0.0980, Training Accuracy= 0.9752, Minibatch error= 2.5%\n",
      "2017-03-30 07:38:09,297 Iter 4075, Minibatch Loss= 0.0822, Training Accuracy= 0.9728, Minibatch error= 2.7%\n",
      "2017-03-30 07:38:22,568 Iter 4080, Minibatch Loss= 0.0728, Training Accuracy= 0.9924, Minibatch error= 0.8%\n",
      "2017-03-30 07:38:35,898 Iter 4085, Minibatch Loss= 0.2321, Training Accuracy= 0.9238, Minibatch error= 7.6%\n",
      "2017-03-30 07:38:49,257 Iter 4090, Minibatch Loss= 0.1547, Training Accuracy= 0.9725, Minibatch error= 2.8%\n",
      "2017-03-30 07:39:02,531 Iter 4095, Minibatch Loss= 0.0466, Training Accuracy= 0.9895, Minibatch error= 1.0%\n",
      "2017-03-30 07:39:12,768 Epoch 40, Average loss: 0.1937, learning rate: 0.0010\n",
      "2017-03-30 07:39:16,669 Verification error= 5.0%, loss= 0.1826\n",
      "2017-03-30 07:39:22,345 Iter 4100, Minibatch Loss= 0.1373, Training Accuracy= 0.9655, Minibatch error= 3.4%\n",
      "2017-03-30 07:39:35,720 Iter 4105, Minibatch Loss= 0.0730, Training Accuracy= 0.9840, Minibatch error= 1.6%\n",
      "2017-03-30 07:39:49,121 Iter 4110, Minibatch Loss= 0.1501, Training Accuracy= 0.9517, Minibatch error= 4.8%\n",
      "2017-03-30 07:40:02,603 Iter 4115, Minibatch Loss= 0.1098, Training Accuracy= 0.9607, Minibatch error= 3.9%\n",
      "2017-03-30 07:40:16,099 Iter 4120, Minibatch Loss= 0.1120, Training Accuracy= 0.9670, Minibatch error= 3.3%\n",
      "2017-03-30 07:40:29,587 Iter 4125, Minibatch Loss= 0.1299, Training Accuracy= 0.9577, Minibatch error= 4.2%\n",
      "2017-03-30 07:40:43,104 Iter 4130, Minibatch Loss= 0.1625, Training Accuracy= 0.9388, Minibatch error= 6.1%\n",
      "2017-03-30 07:40:56,610 Iter 4135, Minibatch Loss= 0.1088, Training Accuracy= 0.9783, Minibatch error= 2.2%\n",
      "2017-03-30 07:41:10,162 Iter 4140, Minibatch Loss= 0.0699, Training Accuracy= 0.9866, Minibatch error= 1.3%\n",
      "2017-03-30 07:41:23,669 Iter 4145, Minibatch Loss= 0.2142, Training Accuracy= 0.9235, Minibatch error= 7.7%\n",
      "2017-03-30 07:41:37,170 Iter 4150, Minibatch Loss= 0.0616, Training Accuracy= 0.9916, Minibatch error= 0.8%\n",
      "2017-03-30 07:41:50,543 Iter 4155, Minibatch Loss= 0.1494, Training Accuracy= 0.9367, Minibatch error= 6.3%\n",
      "2017-03-30 07:42:03,890 Iter 4160, Minibatch Loss= 0.4022, Training Accuracy= 0.8329, Minibatch error= 16.7%\n",
      "2017-03-30 07:42:17,161 Iter 4165, Minibatch Loss= 0.2455, Training Accuracy= 0.8747, Minibatch error= 12.5%\n",
      "2017-03-30 07:42:30,415 Iter 4170, Minibatch Loss= 0.1530, Training Accuracy= 0.9581, Minibatch error= 4.2%\n",
      "2017-03-30 07:42:43,767 Iter 4175, Minibatch Loss= 0.7575, Training Accuracy= 0.6828, Minibatch error= 31.7%\n",
      "2017-03-30 07:42:57,065 Iter 4180, Minibatch Loss= 0.1349, Training Accuracy= 0.9592, Minibatch error= 4.1%\n",
      "2017-03-30 07:43:10,404 Iter 4185, Minibatch Loss= 0.0786, Training Accuracy= 0.9852, Minibatch error= 1.5%\n",
      "2017-03-30 07:43:23,750 Iter 4190, Minibatch Loss= 0.2886, Training Accuracy= 0.8343, Minibatch error= 16.6%\n",
      "2017-03-30 07:43:37,101 Iter 4195, Minibatch Loss= 0.9200, Training Accuracy= 0.4703, Minibatch error= 53.0%\n",
      "2017-03-30 07:43:47,353 Epoch 41, Average loss: 0.1970, learning rate: 0.0010\n",
      "2017-03-30 07:43:51,204 Verification error= 4.1%, loss= 0.1632\n",
      "2017-03-30 07:43:57,213 Iter 4200, Minibatch Loss= 0.1466, Training Accuracy= 0.9634, Minibatch error= 3.7%\n",
      "2017-03-30 07:44:10,621 Iter 4205, Minibatch Loss= 0.2418, Training Accuracy= 0.8831, Minibatch error= 11.7%\n",
      "2017-03-30 07:44:24,113 Iter 4210, Minibatch Loss= 0.4595, Training Accuracy= 0.8147, Minibatch error= 18.5%\n",
      "2017-03-30 07:44:37,597 Iter 4215, Minibatch Loss= 0.1325, Training Accuracy= 0.9608, Minibatch error= 3.9%\n",
      "2017-03-30 07:44:51,114 Iter 4220, Minibatch Loss= 0.2380, Training Accuracy= 0.8773, Minibatch error= 12.3%\n",
      "2017-03-30 07:45:04,541 Iter 4225, Minibatch Loss= 0.1068, Training Accuracy= 0.9733, Minibatch error= 2.7%\n",
      "2017-03-30 07:45:17,984 Iter 4230, Minibatch Loss= 0.4905, Training Accuracy= 0.7757, Minibatch error= 22.4%\n",
      "2017-03-30 07:45:31,408 Iter 4235, Minibatch Loss= 0.0688, Training Accuracy= 0.9852, Minibatch error= 1.5%\n",
      "2017-03-30 07:45:44,853 Iter 4240, Minibatch Loss= 0.1603, Training Accuracy= 0.9307, Minibatch error= 6.9%\n",
      "2017-03-30 07:45:58,264 Iter 4245, Minibatch Loss= 0.1489, Training Accuracy= 0.9391, Minibatch error= 6.1%\n",
      "2017-03-30 07:46:11,709 Iter 4250, Minibatch Loss= 0.0686, Training Accuracy= 0.9846, Minibatch error= 1.5%\n",
      "2017-03-30 07:46:25,124 Iter 4255, Minibatch Loss= 0.1583, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-03-30 07:46:38,544 Iter 4260, Minibatch Loss= 0.1382, Training Accuracy= 0.9438, Minibatch error= 5.6%\n",
      "2017-03-30 07:46:52,057 Iter 4265, Minibatch Loss= 0.1185, Training Accuracy= 0.9509, Minibatch error= 4.9%\n",
      "2017-03-30 07:47:05,521 Iter 4270, Minibatch Loss= 0.0335, Training Accuracy= 0.9938, Minibatch error= 0.6%\n",
      "2017-03-30 07:47:19,002 Iter 4275, Minibatch Loss= 0.0713, Training Accuracy= 0.9773, Minibatch error= 2.3%\n",
      "2017-03-30 07:47:32,490 Iter 4280, Minibatch Loss= 0.2250, Training Accuracy= 0.9442, Minibatch error= 5.6%\n",
      "2017-03-30 07:47:45,954 Iter 4285, Minibatch Loss= 0.1428, Training Accuracy= 0.9797, Minibatch error= 2.0%\n",
      "2017-03-30 07:47:59,413 Iter 4290, Minibatch Loss= 0.2260, Training Accuracy= 0.8783, Minibatch error= 12.2%\n",
      "2017-03-30 07:48:12,871 Iter 4295, Minibatch Loss= 0.0886, Training Accuracy= 0.9691, Minibatch error= 3.1%\n",
      "2017-03-30 07:48:23,248 Epoch 42, Average loss: 0.1701, learning rate: 0.0010\n",
      "2017-03-30 07:48:27,141 Verification error= 3.9%, loss= 0.1319\n",
      "2017-03-30 07:48:33,308 Iter 4300, Minibatch Loss= 0.0772, Training Accuracy= 0.9898, Minibatch error= 1.0%\n",
      "2017-03-30 07:48:46,949 Iter 4305, Minibatch Loss= 0.5433, Training Accuracy= 0.7239, Minibatch error= 27.6%\n",
      "2017-03-30 07:49:00,608 Iter 4310, Minibatch Loss= 0.1048, Training Accuracy= 0.9706, Minibatch error= 2.9%\n",
      "2017-03-30 07:49:14,202 Iter 4315, Minibatch Loss= 0.1187, Training Accuracy= 0.9669, Minibatch error= 3.3%\n",
      "2017-03-30 07:49:27,809 Iter 4320, Minibatch Loss= 0.1023, Training Accuracy= 0.9945, Minibatch error= 0.6%\n",
      "2017-03-30 07:49:41,456 Iter 4325, Minibatch Loss= 0.1843, Training Accuracy= 0.9382, Minibatch error= 6.2%\n",
      "2017-03-30 07:49:55,079 Iter 4330, Minibatch Loss= 0.1032, Training Accuracy= 0.9746, Minibatch error= 2.5%\n",
      "2017-03-30 07:50:08,730 Iter 4335, Minibatch Loss= 0.0697, Training Accuracy= 0.9850, Minibatch error= 1.5%\n",
      "2017-03-30 07:50:22,348 Iter 4340, Minibatch Loss= 0.2748, Training Accuracy= 0.8927, Minibatch error= 10.7%\n",
      "2017-03-30 07:50:36,013 Iter 4345, Minibatch Loss= 0.0739, Training Accuracy= 0.9778, Minibatch error= 2.2%\n",
      "2017-03-30 07:50:49,702 Iter 4350, Minibatch Loss= 0.0681, Training Accuracy= 0.9869, Minibatch error= 1.3%\n",
      "2017-03-30 07:51:03,324 Iter 4355, Minibatch Loss= 0.0600, Training Accuracy= 0.9783, Minibatch error= 2.2%\n",
      "2017-03-30 07:51:17,036 Iter 4360, Minibatch Loss= 0.0840, Training Accuracy= 0.9746, Minibatch error= 2.5%\n",
      "2017-03-30 07:51:30,700 Iter 4365, Minibatch Loss= 0.0295, Training Accuracy= 0.9937, Minibatch error= 0.6%\n",
      "2017-03-30 07:51:44,341 Iter 4370, Minibatch Loss= 0.1503, Training Accuracy= 0.9337, Minibatch error= 6.6%\n",
      "2017-03-30 07:51:57,970 Iter 4375, Minibatch Loss= 0.2046, Training Accuracy= 0.9158, Minibatch error= 8.4%\n",
      "2017-03-30 07:52:11,651 Iter 4380, Minibatch Loss= 0.1774, Training Accuracy= 0.9333, Minibatch error= 6.7%\n",
      "2017-03-30 07:52:25,331 Iter 4385, Minibatch Loss= 0.1942, Training Accuracy= 0.9864, Minibatch error= 1.4%\n",
      "2017-03-30 07:52:38,919 Iter 4390, Minibatch Loss= 0.2445, Training Accuracy= 0.9272, Minibatch error= 7.3%\n",
      "2017-03-30 07:52:52,591 Iter 4395, Minibatch Loss= 0.2068, Training Accuracy= 0.9314, Minibatch error= 6.9%\n",
      "2017-03-30 07:53:03,126 Epoch 43, Average loss: 0.1919, learning rate: 0.0010\n",
      "2017-03-30 07:53:07,065 Verification error= 3.9%, loss= 0.1470\n",
      "2017-03-30 07:53:12,975 Iter 4400, Minibatch Loss= 0.3067, Training Accuracy= 0.8227, Minibatch error= 17.7%\n",
      "2017-03-30 07:53:27,017 Iter 4405, Minibatch Loss= 0.2823, Training Accuracy= 0.8359, Minibatch error= 16.4%\n",
      "2017-03-30 07:53:40,822 Iter 4410, Minibatch Loss= 0.0952, Training Accuracy= 0.9640, Minibatch error= 3.6%\n",
      "2017-03-30 07:53:54,508 Iter 4415, Minibatch Loss= 0.0819, Training Accuracy= 0.9785, Minibatch error= 2.1%\n",
      "2017-03-30 07:54:08,278 Iter 4420, Minibatch Loss= 0.4703, Training Accuracy= 0.7459, Minibatch error= 25.4%\n",
      "2017-03-30 07:54:22,040 Iter 4425, Minibatch Loss= 0.1152, Training Accuracy= 0.9871, Minibatch error= 1.3%\n",
      "2017-03-30 07:54:35,859 Iter 4430, Minibatch Loss= 0.1497, Training Accuracy= 0.9674, Minibatch error= 3.3%\n",
      "2017-03-30 07:54:49,770 Iter 4435, Minibatch Loss= 0.2070, Training Accuracy= 0.8996, Minibatch error= 10.0%\n",
      "2017-03-30 07:55:03,574 Iter 4440, Minibatch Loss= 0.1246, Training Accuracy= 0.9683, Minibatch error= 3.2%\n",
      "2017-03-30 07:55:17,366 Iter 4445, Minibatch Loss= 0.0970, Training Accuracy= 0.9689, Minibatch error= 3.1%\n",
      "2017-03-30 07:55:31,172 Iter 4450, Minibatch Loss= 0.0553, Training Accuracy= 0.9837, Minibatch error= 1.6%\n",
      "2017-03-30 07:55:45,004 Iter 4455, Minibatch Loss= 0.1193, Training Accuracy= 0.9781, Minibatch error= 2.2%\n",
      "2017-03-30 07:55:58,842 Iter 4460, Minibatch Loss= 0.0889, Training Accuracy= 0.9771, Minibatch error= 2.3%\n",
      "2017-03-30 07:56:12,665 Iter 4465, Minibatch Loss= 0.0308, Training Accuracy= 0.9952, Minibatch error= 0.5%\n",
      "2017-03-30 07:56:26,507 Iter 4470, Minibatch Loss= 0.6832, Training Accuracy= 0.7072, Minibatch error= 29.3%\n",
      "2017-03-30 07:56:40,352 Iter 4475, Minibatch Loss= 0.0365, Training Accuracy= 0.9973, Minibatch error= 0.3%\n",
      "2017-03-30 07:56:54,220 Iter 4480, Minibatch Loss= 0.1290, Training Accuracy= 0.9644, Minibatch error= 3.6%\n",
      "2017-03-30 07:57:08,115 Iter 4485, Minibatch Loss= 0.0609, Training Accuracy= 0.9900, Minibatch error= 1.0%\n",
      "2017-03-30 07:57:21,966 Iter 4490, Minibatch Loss= 0.1978, Training Accuracy= 0.9384, Minibatch error= 6.2%\n",
      "2017-03-30 07:57:35,890 Iter 4495, Minibatch Loss= 0.1300, Training Accuracy= 0.9812, Minibatch error= 1.9%\n",
      "2017-03-30 07:57:46,598 Epoch 44, Average loss: 0.1727, learning rate: 0.0010\n",
      "2017-03-30 07:57:50,610 Verification error= 4.0%, loss= 0.1109\n",
      "2017-03-30 07:57:56,959 Iter 4500, Minibatch Loss= 0.1405, Training Accuracy= 0.9654, Minibatch error= 3.5%\n",
      "2017-03-30 07:58:11,018 Iter 4505, Minibatch Loss= 0.3927, Training Accuracy= 0.8103, Minibatch error= 19.0%\n",
      "2017-03-30 07:58:25,246 Iter 4510, Minibatch Loss= 0.0841, Training Accuracy= 0.9950, Minibatch error= 0.5%\n",
      "2017-03-30 07:58:39,581 Iter 4515, Minibatch Loss= 0.1209, Training Accuracy= 0.9671, Minibatch error= 3.3%\n",
      "2017-03-30 07:58:54,078 Iter 4520, Minibatch Loss= 0.2061, Training Accuracy= 0.9163, Minibatch error= 8.4%\n",
      "2017-03-30 07:59:08,703 Iter 4525, Minibatch Loss= 0.3144, Training Accuracy= 0.8619, Minibatch error= 13.8%\n",
      "2017-03-30 07:59:23,372 Iter 4530, Minibatch Loss= 0.3165, Training Accuracy= 0.8647, Minibatch error= 13.5%\n",
      "2017-03-30 07:59:38,052 Iter 4535, Minibatch Loss= 0.1490, Training Accuracy= 0.9753, Minibatch error= 2.5%\n",
      "2017-03-30 07:59:52,743 Iter 4540, Minibatch Loss= 0.0601, Training Accuracy= 0.9974, Minibatch error= 0.3%\n",
      "2017-03-30 08:00:07,507 Iter 4545, Minibatch Loss= 0.0919, Training Accuracy= 0.9554, Minibatch error= 4.5%\n",
      "2017-03-30 08:00:22,143 Iter 4550, Minibatch Loss= 0.0646, Training Accuracy= 0.9914, Minibatch error= 0.9%\n",
      "2017-03-30 08:00:36,847 Iter 4555, Minibatch Loss= 0.2903, Training Accuracy= 0.8832, Minibatch error= 11.7%\n",
      "2017-03-30 08:00:51,711 Iter 4560, Minibatch Loss= 0.1519, Training Accuracy= 0.9588, Minibatch error= 4.1%\n",
      "2017-03-30 08:01:06,446 Iter 4565, Minibatch Loss= 0.3151, Training Accuracy= 0.8391, Minibatch error= 16.1%\n",
      "2017-03-30 08:01:21,101 Iter 4570, Minibatch Loss= 0.1388, Training Accuracy= 0.9869, Minibatch error= 1.3%\n",
      "2017-03-30 08:01:35,767 Iter 4575, Minibatch Loss= 0.1491, Training Accuracy= 0.9728, Minibatch error= 2.7%\n",
      "2017-03-30 08:01:50,496 Iter 4580, Minibatch Loss= 0.1149, Training Accuracy= 0.9704, Minibatch error= 3.0%\n",
      "2017-03-30 08:02:05,193 Iter 4585, Minibatch Loss= 0.1177, Training Accuracy= 0.9550, Minibatch error= 4.5%\n",
      "2017-03-30 08:02:19,986 Iter 4590, Minibatch Loss= 0.2758, Training Accuracy= 0.8574, Minibatch error= 14.3%\n",
      "2017-03-30 08:02:34,719 Iter 4595, Minibatch Loss= 0.1235, Training Accuracy= 0.9625, Minibatch error= 3.8%\n",
      "2017-03-30 08:02:46,120 Epoch 45, Average loss: 0.2072, learning rate: 0.0010\n",
      "2017-03-30 08:02:50,395 Verification error= 4.0%, loss= 0.1123\n",
      "2017-03-30 08:02:56,613 Iter 4600, Minibatch Loss= 0.0472, Training Accuracy= 0.9961, Minibatch error= 0.4%\n",
      "2017-03-30 08:03:11,363 Iter 4605, Minibatch Loss= 0.1823, Training Accuracy= 0.9224, Minibatch error= 7.8%\n",
      "2017-03-30 08:03:26,114 Iter 4610, Minibatch Loss= 0.0855, Training Accuracy= 0.9926, Minibatch error= 0.7%\n",
      "2017-03-30 08:03:40,942 Iter 4615, Minibatch Loss= 0.0522, Training Accuracy= 0.9902, Minibatch error= 1.0%\n",
      "2017-03-30 08:03:55,848 Iter 4620, Minibatch Loss= 0.1002, Training Accuracy= 0.9766, Minibatch error= 2.3%\n",
      "2017-03-30 08:04:10,698 Iter 4625, Minibatch Loss= 0.1079, Training Accuracy= 0.9580, Minibatch error= 4.2%\n",
      "2017-03-30 08:04:25,520 Iter 4630, Minibatch Loss= 0.0845, Training Accuracy= 0.9730, Minibatch error= 2.7%\n",
      "2017-03-30 08:04:40,365 Iter 4635, Minibatch Loss= 0.0352, Training Accuracy= 0.9924, Minibatch error= 0.8%\n",
      "2017-03-30 08:04:55,160 Iter 4640, Minibatch Loss= 0.0204, Training Accuracy= 0.9984, Minibatch error= 0.2%\n",
      "2017-03-30 08:05:09,890 Iter 4645, Minibatch Loss= 0.1784, Training Accuracy= 0.9102, Minibatch error= 9.0%\n",
      "2017-03-30 08:05:24,691 Iter 4650, Minibatch Loss= 0.0616, Training Accuracy= 0.9869, Minibatch error= 1.3%\n",
      "2017-03-30 08:05:39,802 Iter 4655, Minibatch Loss= 0.0781, Training Accuracy= 0.9868, Minibatch error= 1.3%\n",
      "2017-03-30 08:05:54,577 Iter 4660, Minibatch Loss= 0.1486, Training Accuracy= 0.9614, Minibatch error= 3.9%\n",
      "2017-03-30 08:06:09,393 Iter 4665, Minibatch Loss= 0.2533, Training Accuracy= 0.9107, Minibatch error= 8.9%\n",
      "2017-03-30 08:06:24,244 Iter 4670, Minibatch Loss= 0.2155, Training Accuracy= 0.9191, Minibatch error= 8.1%\n",
      "2017-03-30 08:06:39,019 Iter 4675, Minibatch Loss= 0.1492, Training Accuracy= 0.9818, Minibatch error= 1.8%\n",
      "2017-03-30 08:06:53,816 Iter 4680, Minibatch Loss= 0.2850, Training Accuracy= 0.9083, Minibatch error= 9.2%\n",
      "2017-03-30 08:07:08,603 Iter 4685, Minibatch Loss= 0.2240, Training Accuracy= 0.9651, Minibatch error= 3.5%\n",
      "2017-03-30 08:07:23,468 Iter 4690, Minibatch Loss= 0.1856, Training Accuracy= 0.9716, Minibatch error= 2.8%\n",
      "2017-03-30 08:07:38,286 Iter 4695, Minibatch Loss= 0.0466, Training Accuracy= 0.9983, Minibatch error= 0.2%\n",
      "2017-03-30 08:07:49,635 Epoch 46, Average loss: 0.1762, learning rate: 0.0010\n",
      "2017-03-30 08:07:53,886 Verification error= 3.8%, loss= 0.1014\n",
      "2017-03-30 08:08:00,212 Iter 4700, Minibatch Loss= 0.0981, Training Accuracy= 0.9810, Minibatch error= 1.9%\n",
      "2017-03-30 08:08:15,128 Iter 4705, Minibatch Loss= 0.0588, Training Accuracy= 0.9897, Minibatch error= 1.0%\n",
      "2017-03-30 08:08:30,094 Iter 4710, Minibatch Loss= 0.1022, Training Accuracy= 0.9859, Minibatch error= 1.4%\n",
      "2017-03-30 08:08:45,123 Iter 4715, Minibatch Loss= 0.1770, Training Accuracy= 0.9588, Minibatch error= 4.1%\n",
      "2017-03-30 08:09:00,111 Iter 4720, Minibatch Loss= 0.1700, Training Accuracy= 0.9525, Minibatch error= 4.8%\n",
      "2017-03-30 08:09:14,920 Iter 4725, Minibatch Loss= 0.1368, Training Accuracy= 0.9629, Minibatch error= 3.7%\n",
      "2017-03-30 08:09:29,720 Iter 4730, Minibatch Loss= 0.3821, Training Accuracy= 0.7962, Minibatch error= 20.4%\n",
      "2017-03-30 08:09:44,643 Iter 4735, Minibatch Loss= 0.1413, Training Accuracy= 0.9581, Minibatch error= 4.2%\n",
      "2017-03-30 08:09:59,580 Iter 4740, Minibatch Loss= 0.0524, Training Accuracy= 0.9953, Minibatch error= 0.5%\n",
      "2017-03-30 08:10:14,562 Iter 4745, Minibatch Loss= 0.0631, Training Accuracy= 0.9960, Minibatch error= 0.4%\n",
      "2017-03-30 08:10:29,480 Iter 4750, Minibatch Loss= 0.1196, Training Accuracy= 0.9777, Minibatch error= 2.2%\n",
      "2017-03-30 08:10:44,488 Iter 4755, Minibatch Loss= 0.2062, Training Accuracy= 0.9248, Minibatch error= 7.5%\n",
      "2017-03-30 08:10:59,328 Iter 4760, Minibatch Loss= 0.0983, Training Accuracy= 0.9753, Minibatch error= 2.5%\n",
      "2017-03-30 08:11:14,285 Iter 4765, Minibatch Loss= 0.2220, Training Accuracy= 0.9120, Minibatch error= 8.8%\n",
      "2017-03-30 08:11:29,199 Iter 4770, Minibatch Loss= 0.1825, Training Accuracy= 0.9374, Minibatch error= 6.3%\n",
      "2017-03-30 08:11:44,139 Iter 4775, Minibatch Loss= 0.2137, Training Accuracy= 0.9273, Minibatch error= 7.3%\n",
      "2017-03-30 08:11:59,082 Iter 4780, Minibatch Loss= 0.0382, Training Accuracy= 0.9973, Minibatch error= 0.3%\n",
      "2017-03-30 08:12:14,078 Iter 4785, Minibatch Loss= 0.4691, Training Accuracy= 0.7728, Minibatch error= 22.7%\n",
      "2017-03-30 08:12:29,041 Iter 4790, Minibatch Loss= 0.1203, Training Accuracy= 0.9642, Minibatch error= 3.6%\n",
      "2017-03-30 08:12:44,063 Iter 4795, Minibatch Loss= 0.1029, Training Accuracy= 0.9741, Minibatch error= 2.6%\n",
      "2017-03-30 08:12:55,551 Epoch 47, Average loss: 0.1926, learning rate: 0.0010\n",
      "2017-03-30 08:12:59,872 Verification error= 4.1%, loss= 0.1606\n",
      "2017-03-30 08:13:06,673 Iter 4800, Minibatch Loss= 0.0966, Training Accuracy= 0.9905, Minibatch error= 0.9%\n",
      "2017-03-30 08:13:21,666 Iter 4805, Minibatch Loss= 0.1061, Training Accuracy= 0.9858, Minibatch error= 1.4%\n",
      "2017-03-30 08:13:36,697 Iter 4810, Minibatch Loss= 0.4165, Training Accuracy= 0.8185, Minibatch error= 18.1%\n",
      "2017-03-30 08:13:51,680 Iter 4815, Minibatch Loss= 0.0962, Training Accuracy= 0.9979, Minibatch error= 0.2%\n",
      "2017-03-30 08:14:06,669 Iter 4820, Minibatch Loss= 0.0874, Training Accuracy= 0.9667, Minibatch error= 3.3%\n",
      "2017-03-30 08:14:21,603 Iter 4825, Minibatch Loss= 0.3956, Training Accuracy= 0.8311, Minibatch error= 16.9%\n",
      "2017-03-30 08:14:36,707 Iter 4830, Minibatch Loss= 0.1523, Training Accuracy= 0.9329, Minibatch error= 6.7%\n",
      "2017-03-30 08:14:51,851 Iter 4835, Minibatch Loss= 0.0706, Training Accuracy= 0.9782, Minibatch error= 2.2%\n",
      "2017-03-30 08:15:06,823 Iter 4840, Minibatch Loss= 0.0936, Training Accuracy= 0.9713, Minibatch error= 2.9%\n",
      "2017-03-30 08:15:21,863 Iter 4845, Minibatch Loss= 0.0799, Training Accuracy= 0.9854, Minibatch error= 1.5%\n",
      "2017-03-30 08:15:36,934 Iter 4850, Minibatch Loss= 0.0836, Training Accuracy= 0.9760, Minibatch error= 2.4%\n",
      "2017-03-30 08:15:51,951 Iter 4855, Minibatch Loss= 0.0334, Training Accuracy= 0.9914, Minibatch error= 0.9%\n",
      "2017-03-30 08:16:06,998 Iter 4860, Minibatch Loss= 0.0456, Training Accuracy= 0.9922, Minibatch error= 0.8%\n",
      "2017-03-30 08:16:22,002 Iter 4865, Minibatch Loss= 0.0866, Training Accuracy= 0.9916, Minibatch error= 0.8%\n",
      "2017-03-30 08:16:37,209 Iter 4870, Minibatch Loss= 0.0892, Training Accuracy= 0.9937, Minibatch error= 0.6%\n",
      "2017-03-30 08:16:53,530 Iter 4875, Minibatch Loss= 0.2189, Training Accuracy= 0.9436, Minibatch error= 5.6%\n",
      "2017-03-30 08:17:08,767 Iter 4880, Minibatch Loss= 0.2588, Training Accuracy= 0.8863, Minibatch error= 11.4%\n",
      "2017-03-30 08:17:24,494 Iter 4885, Minibatch Loss= 0.1870, Training Accuracy= 0.9642, Minibatch error= 3.6%\n",
      "2017-03-30 08:17:39,969 Iter 4890, Minibatch Loss= 0.0647, Training Accuracy= 0.9967, Minibatch error= 0.3%\n",
      "2017-03-30 08:17:55,026 Iter 4895, Minibatch Loss= 0.2857, Training Accuracy= 0.8736, Minibatch error= 12.6%\n",
      "2017-03-30 08:18:06,588 Epoch 48, Average loss: 0.1733, learning rate: 0.0010\n",
      "2017-03-30 08:18:10,922 Verification error= 3.8%, loss= 0.1221\n",
      "2017-03-30 08:18:17,441 Iter 4900, Minibatch Loss= 0.0520, Training Accuracy= 0.9955, Minibatch error= 0.4%\n",
      "2017-03-30 08:18:32,421 Iter 4905, Minibatch Loss= 0.0769, Training Accuracy= 0.9909, Minibatch error= 0.9%\n",
      "2017-03-30 08:18:47,524 Iter 4910, Minibatch Loss= 0.1646, Training Accuracy= 0.9613, Minibatch error= 3.9%\n",
      "2017-03-30 08:19:02,613 Iter 4915, Minibatch Loss= 0.6792, Training Accuracy= 0.6908, Minibatch error= 30.9%\n",
      "2017-03-30 08:19:17,715 Iter 4920, Minibatch Loss= 0.0899, Training Accuracy= 0.9805, Minibatch error= 1.9%\n",
      "2017-03-30 08:19:32,829 Iter 4925, Minibatch Loss= 0.0800, Training Accuracy= 0.9774, Minibatch error= 2.3%\n",
      "2017-03-30 08:19:47,888 Iter 4930, Minibatch Loss= 0.1650, Training Accuracy= 0.9189, Minibatch error= 8.1%\n",
      "2017-03-30 08:20:02,939 Iter 4935, Minibatch Loss= 0.0547, Training Accuracy= 0.9892, Minibatch error= 1.1%\n",
      "2017-03-30 08:20:18,082 Iter 4940, Minibatch Loss= 0.0691, Training Accuracy= 0.9849, Minibatch error= 1.5%\n",
      "2017-03-30 08:20:33,273 Iter 4945, Minibatch Loss= 0.0660, Training Accuracy= 0.9963, Minibatch error= 0.4%\n",
      "2017-03-30 08:20:48,463 Iter 4950, Minibatch Loss= 0.1179, Training Accuracy= 0.9500, Minibatch error= 5.0%\n",
      "2017-03-30 08:21:03,702 Iter 4955, Minibatch Loss= 0.1197, Training Accuracy= 0.9588, Minibatch error= 4.1%\n",
      "2017-03-30 08:21:18,901 Iter 4960, Minibatch Loss= 0.2159, Training Accuracy= 0.9154, Minibatch error= 8.5%\n",
      "2017-03-30 08:21:34,070 Iter 4965, Minibatch Loss= 0.2042, Training Accuracy= 0.9111, Minibatch error= 8.9%\n",
      "2017-03-30 08:21:49,260 Iter 4970, Minibatch Loss= 0.0965, Training Accuracy= 0.9684, Minibatch error= 3.2%\n",
      "2017-03-30 08:22:04,352 Iter 4975, Minibatch Loss= 0.0717, Training Accuracy= 0.9938, Minibatch error= 0.6%\n",
      "2017-03-30 08:22:19,552 Iter 4980, Minibatch Loss= 0.0932, Training Accuracy= 0.9780, Minibatch error= 2.2%\n",
      "2017-03-30 08:22:34,702 Iter 4985, Minibatch Loss= 0.1432, Training Accuracy= 0.9730, Minibatch error= 2.7%\n",
      "2017-03-30 08:22:49,950 Iter 4990, Minibatch Loss= 0.1288, Training Accuracy= 0.9795, Minibatch error= 2.1%\n",
      "2017-03-30 08:23:05,207 Iter 4995, Minibatch Loss= 0.6262, Training Accuracy= 0.6553, Minibatch error= 34.5%\n",
      "2017-03-30 08:23:16,905 Epoch 49, Average loss: 0.1659, learning rate: 0.0010\n",
      "2017-03-30 08:23:21,312 Verification error= 4.4%, loss= 0.1375\n",
      "2017-03-30 08:23:28,133 Iter 5000, Minibatch Loss= 0.2051, Training Accuracy= 0.9567, Minibatch error= 4.3%\n",
      "2017-03-30 08:23:42,830 Iter 5005, Minibatch Loss= 0.2065, Training Accuracy= 0.9558, Minibatch error= 4.4%\n",
      "2017-03-30 08:23:57,622 Iter 5010, Minibatch Loss= 0.1504, Training Accuracy= 0.9579, Minibatch error= 4.2%\n",
      "2017-03-30 08:24:12,309 Iter 5015, Minibatch Loss= 0.3096, Training Accuracy= 0.8317, Minibatch error= 16.8%\n",
      "2017-03-30 08:24:27,015 Iter 5020, Minibatch Loss= 0.0798, Training Accuracy= 0.9908, Minibatch error= 0.9%\n",
      "2017-03-30 08:24:41,688 Iter 5025, Minibatch Loss= 0.1903, Training Accuracy= 0.9521, Minibatch error= 4.8%\n",
      "2017-03-30 08:24:56,631 Iter 5030, Minibatch Loss= 0.0679, Training Accuracy= 0.9942, Minibatch error= 0.6%\n",
      "2017-03-30 08:25:11,374 Iter 5035, Minibatch Loss= 0.0391, Training Accuracy= 0.9980, Minibatch error= 0.2%\n",
      "2017-03-30 08:25:25,989 Iter 5040, Minibatch Loss= 0.1599, Training Accuracy= 0.9790, Minibatch error= 2.1%\n",
      "2017-03-30 08:25:40,715 Iter 5045, Minibatch Loss= 0.2317, Training Accuracy= 0.9224, Minibatch error= 7.8%\n",
      "2017-03-30 08:25:55,468 Iter 5050, Minibatch Loss= 0.2045, Training Accuracy= 0.9712, Minibatch error= 2.9%\n",
      "2017-03-30 08:26:10,167 Iter 5055, Minibatch Loss= 0.6713, Training Accuracy= 0.5325, Minibatch error= 46.7%\n",
      "2017-03-30 08:26:24,940 Iter 5060, Minibatch Loss= 0.1686, Training Accuracy= 0.9561, Minibatch error= 4.4%\n",
      "2017-03-30 08:26:39,718 Iter 5065, Minibatch Loss= 0.1239, Training Accuracy= 0.9812, Minibatch error= 1.9%\n",
      "2017-03-30 08:26:54,471 Iter 5070, Minibatch Loss= 0.0750, Training Accuracy= 0.9909, Minibatch error= 0.9%\n",
      "2017-03-30 08:27:09,181 Iter 5075, Minibatch Loss= 0.0701, Training Accuracy= 0.9891, Minibatch error= 1.1%\n",
      "2017-03-30 08:27:23,789 Iter 5080, Minibatch Loss= 0.0662, Training Accuracy= 0.9904, Minibatch error= 1.0%\n",
      "2017-03-30 08:27:38,547 Iter 5085, Minibatch Loss= 0.1751, Training Accuracy= 0.9174, Minibatch error= 8.3%\n",
      "2017-03-30 08:27:53,390 Iter 5090, Minibatch Loss= 0.1244, Training Accuracy= 0.9768, Minibatch error= 2.3%\n",
      "2017-03-30 08:28:08,124 Iter 5095, Minibatch Loss= 0.1232, Training Accuracy= 0.9639, Minibatch error= 3.6%\n",
      "2017-03-30 08:28:19,394 Epoch 50, Average loss: 0.1873, learning rate: 0.0010\n",
      "2017-03-30 08:28:23,580 Verification error= 3.9%, loss= 0.1145\n",
      "2017-03-30 08:28:30,493 Iter 5100, Minibatch Loss= 0.1958, Training Accuracy= 0.9284, Minibatch error= 7.2%\n",
      "2017-03-30 08:28:45,445 Iter 5105, Minibatch Loss= 0.0943, Training Accuracy= 0.9679, Minibatch error= 3.2%\n",
      "2017-03-30 08:29:00,395 Iter 5110, Minibatch Loss= 0.0521, Training Accuracy= 0.9904, Minibatch error= 1.0%\n",
      "2017-03-30 08:29:15,283 Iter 5115, Minibatch Loss= 0.1572, Training Accuracy= 0.9401, Minibatch error= 6.0%\n",
      "2017-03-30 08:29:30,160 Iter 5120, Minibatch Loss= 0.1788, Training Accuracy= 0.9281, Minibatch error= 7.2%\n",
      "2017-03-30 08:29:44,923 Iter 5125, Minibatch Loss= 0.2370, Training Accuracy= 0.8893, Minibatch error= 11.1%\n",
      "2017-03-30 08:29:59,820 Iter 5130, Minibatch Loss= 0.1227, Training Accuracy= 0.9549, Minibatch error= 4.5%\n",
      "2017-03-30 08:30:14,665 Iter 5135, Minibatch Loss= 0.3183, Training Accuracy= 0.8636, Minibatch error= 13.6%\n",
      "2017-03-30 08:30:29,537 Iter 5140, Minibatch Loss= 0.0694, Training Accuracy= 0.9825, Minibatch error= 1.8%\n",
      "2017-03-30 08:30:44,390 Iter 5145, Minibatch Loss= 0.5403, Training Accuracy= 0.7184, Minibatch error= 28.2%\n",
      "2017-03-30 08:30:59,196 Iter 5150, Minibatch Loss= 0.4259, Training Accuracy= 0.7712, Minibatch error= 22.9%\n",
      "2017-03-30 08:31:14,151 Iter 5155, Minibatch Loss= 0.2257, Training Accuracy= 0.9337, Minibatch error= 6.6%\n",
      "2017-03-30 08:31:29,091 Iter 5160, Minibatch Loss= 0.2282, Training Accuracy= 0.9045, Minibatch error= 9.6%\n",
      "2017-03-30 08:31:44,022 Iter 5165, Minibatch Loss= 0.1093, Training Accuracy= 0.9961, Minibatch error= 0.4%\n",
      "2017-03-30 08:31:58,972 Iter 5170, Minibatch Loss= 0.1672, Training Accuracy= 0.9880, Minibatch error= 1.2%\n",
      "2017-03-30 08:32:13,930 Iter 5175, Minibatch Loss= 0.1362, Training Accuracy= 0.9688, Minibatch error= 3.1%\n",
      "2017-03-30 08:32:28,929 Iter 5180, Minibatch Loss= 0.2734, Training Accuracy= 0.8844, Minibatch error= 11.6%\n",
      "2017-03-30 08:32:44,098 Iter 5185, Minibatch Loss= 0.1762, Training Accuracy= 0.9109, Minibatch error= 8.9%\n",
      "2017-03-30 08:32:59,137 Iter 5190, Minibatch Loss= 0.0533, Training Accuracy= 0.9906, Minibatch error= 0.9%\n",
      "2017-03-30 08:33:14,224 Iter 5195, Minibatch Loss= 0.2061, Training Accuracy= 0.9099, Minibatch error= 9.0%\n",
      "2017-03-30 08:33:25,837 Epoch 51, Average loss: 0.1945, learning rate: 0.0010\n",
      "2017-03-30 08:33:30,071 Verification error= 4.1%, loss= 0.1066\n",
      "2017-03-30 08:33:36,605 Iter 5200, Minibatch Loss= 0.1873, Training Accuracy= 0.9331, Minibatch error= 6.7%\n",
      "2017-03-30 08:33:50,558 Iter 5205, Minibatch Loss= 0.0422, Training Accuracy= 0.9903, Minibatch error= 1.0%\n",
      "2017-03-30 08:34:04,482 Iter 5210, Minibatch Loss= 0.6594, Training Accuracy= 0.7151, Minibatch error= 28.5%\n",
      "2017-03-30 08:34:18,431 Iter 5215, Minibatch Loss= 0.1925, Training Accuracy= 0.9222, Minibatch error= 7.8%\n",
      "2017-03-30 08:34:32,413 Iter 5220, Minibatch Loss= 0.1220, Training Accuracy= 0.9707, Minibatch error= 2.9%\n",
      "2017-03-30 08:34:46,395 Iter 5225, Minibatch Loss= 0.0767, Training Accuracy= 0.9859, Minibatch error= 1.4%\n",
      "2017-03-30 08:35:00,387 Iter 5230, Minibatch Loss= 0.0606, Training Accuracy= 0.9925, Minibatch error= 0.8%\n",
      "2017-03-30 08:35:14,359 Iter 5235, Minibatch Loss= 0.1197, Training Accuracy= 0.9641, Minibatch error= 3.6%\n",
      "2017-03-30 08:35:28,414 Iter 5240, Minibatch Loss= 0.0844, Training Accuracy= 0.9797, Minibatch error= 2.0%\n",
      "2017-03-30 08:35:42,481 Iter 5245, Minibatch Loss= 0.3068, Training Accuracy= 0.8733, Minibatch error= 12.7%\n",
      "2017-03-30 08:35:56,533 Iter 5250, Minibatch Loss= 0.0783, Training Accuracy= 0.9923, Minibatch error= 0.8%\n",
      "2017-03-30 08:36:10,667 Iter 5255, Minibatch Loss= 0.0649, Training Accuracy= 0.9925, Minibatch error= 0.8%\n",
      "2017-03-30 08:36:24,758 Iter 5260, Minibatch Loss= 0.2045, Training Accuracy= 0.9250, Minibatch error= 7.5%\n",
      "2017-03-30 08:36:38,855 Iter 5265, Minibatch Loss= 0.1864, Training Accuracy= 0.9281, Minibatch error= 7.2%\n",
      "2017-03-30 08:36:52,947 Iter 5270, Minibatch Loss= 0.3690, Training Accuracy= 0.8411, Minibatch error= 15.9%\n",
      "2017-03-30 08:37:07,114 Iter 5275, Minibatch Loss= 0.0632, Training Accuracy= 0.9905, Minibatch error= 0.9%\n",
      "2017-03-30 08:37:21,296 Iter 5280, Minibatch Loss= 0.1254, Training Accuracy= 0.9691, Minibatch error= 3.1%\n",
      "2017-03-30 08:37:35,570 Iter 5285, Minibatch Loss= 0.2533, Training Accuracy= 0.8912, Minibatch error= 10.9%\n",
      "2017-03-30 08:37:49,803 Iter 5290, Minibatch Loss= 0.1276, Training Accuracy= 0.9913, Minibatch error= 0.9%\n",
      "2017-03-30 08:38:04,043 Iter 5295, Minibatch Loss= 0.0205, Training Accuracy= 0.9978, Minibatch error= 0.2%\n",
      "2017-03-30 08:38:15,003 Epoch 52, Average loss: 0.1466, learning rate: 0.0010\n",
      "2017-03-30 08:38:18,963 Verification error= 4.2%, loss= 0.1113\n",
      "2017-03-30 08:38:25,970 Iter 5300, Minibatch Loss= 0.0599, Training Accuracy= 0.9878, Minibatch error= 1.2%\n",
      "2017-03-30 08:38:40,319 Iter 5305, Minibatch Loss= 0.6823, Training Accuracy= 0.7235, Minibatch error= 27.7%\n",
      "2017-03-30 08:38:54,724 Iter 5310, Minibatch Loss= 0.1178, Training Accuracy= 0.9589, Minibatch error= 4.1%\n",
      "2017-03-30 08:39:09,081 Iter 5315, Minibatch Loss= 0.2063, Training Accuracy= 0.9258, Minibatch error= 7.4%\n",
      "2017-03-30 08:39:23,517 Iter 5320, Minibatch Loss= 0.1741, Training Accuracy= 0.9451, Minibatch error= 5.5%\n",
      "2017-03-30 08:39:37,886 Iter 5325, Minibatch Loss= 0.1499, Training Accuracy= 0.9723, Minibatch error= 2.8%\n",
      "2017-03-30 08:39:52,204 Iter 5330, Minibatch Loss= 0.1704, Training Accuracy= 0.9810, Minibatch error= 1.9%\n",
      "2017-03-30 08:40:06,596 Iter 5335, Minibatch Loss= 0.3121, Training Accuracy= 0.9267, Minibatch error= 7.3%\n",
      "2017-03-30 08:40:21,026 Iter 5340, Minibatch Loss= 0.1348, Training Accuracy= 0.9432, Minibatch error= 5.7%\n",
      "2017-03-30 08:40:35,391 Iter 5345, Minibatch Loss= 0.0820, Training Accuracy= 0.9814, Minibatch error= 1.9%\n",
      "2017-03-30 08:40:49,813 Iter 5350, Minibatch Loss= 0.0882, Training Accuracy= 0.9859, Minibatch error= 1.4%\n",
      "2017-03-30 08:41:04,223 Iter 5355, Minibatch Loss= 0.1919, Training Accuracy= 0.9776, Minibatch error= 2.2%\n",
      "2017-03-30 08:41:18,768 Iter 5360, Minibatch Loss= 0.1048, Training Accuracy= 0.9729, Minibatch error= 2.7%\n",
      "2017-03-30 08:41:33,262 Iter 5365, Minibatch Loss= 0.0378, Training Accuracy= 0.9958, Minibatch error= 0.4%\n",
      "2017-03-30 08:41:47,801 Iter 5370, Minibatch Loss= 0.0980, Training Accuracy= 0.9764, Minibatch error= 2.4%\n",
      "2017-03-30 08:42:02,390 Iter 5375, Minibatch Loss= 0.0844, Training Accuracy= 0.9805, Minibatch error= 2.0%\n",
      "2017-03-30 08:42:16,951 Iter 5380, Minibatch Loss= 0.1852, Training Accuracy= 0.9361, Minibatch error= 6.4%\n",
      "2017-03-30 08:42:31,588 Iter 5385, Minibatch Loss= 0.0904, Training Accuracy= 0.9759, Minibatch error= 2.4%\n",
      "2017-03-30 08:42:46,300 Iter 5390, Minibatch Loss= 0.0508, Training Accuracy= 0.9970, Minibatch error= 0.3%\n",
      "2017-03-30 08:43:01,072 Iter 5395, Minibatch Loss= 0.1081, Training Accuracy= 0.9566, Minibatch error= 4.3%\n",
      "2017-03-30 08:43:12,440 Epoch 53, Average loss: 0.1715, learning rate: 0.0010\n",
      "2017-03-30 08:43:16,611 Verification error= 3.8%, loss= 0.1060\n",
      "2017-03-30 08:43:23,296 Iter 5400, Minibatch Loss= 0.0729, Training Accuracy= 0.9928, Minibatch error= 0.7%\n",
      "2017-03-30 08:43:38,227 Iter 5405, Minibatch Loss= 0.1048, Training Accuracy= 0.9811, Minibatch error= 1.9%\n",
      "2017-03-30 08:43:53,357 Iter 5410, Minibatch Loss= 0.2523, Training Accuracy= 0.8856, Minibatch error= 11.4%\n",
      "2017-03-30 08:44:08,538 Iter 5415, Minibatch Loss= 0.1277, Training Accuracy= 0.9646, Minibatch error= 3.5%\n",
      "2017-03-30 08:44:23,810 Iter 5420, Minibatch Loss= 0.1665, Training Accuracy= 0.9390, Minibatch error= 6.1%\n",
      "2017-03-30 08:44:39,117 Iter 5425, Minibatch Loss= 0.0885, Training Accuracy= 0.9801, Minibatch error= 2.0%\n",
      "2017-03-30 08:44:54,454 Iter 5430, Minibatch Loss= 0.3061, Training Accuracy= 0.8485, Minibatch error= 15.1%\n",
      "2017-03-30 08:45:09,717 Iter 5435, Minibatch Loss= 0.0770, Training Accuracy= 0.9753, Minibatch error= 2.5%\n",
      "2017-03-30 08:45:24,697 Iter 5440, Minibatch Loss= 0.1705, Training Accuracy= 0.9558, Minibatch error= 4.4%\n",
      "2017-03-30 08:45:39,372 Iter 5445, Minibatch Loss= 0.0565, Training Accuracy= 0.9911, Minibatch error= 0.9%\n",
      "2017-03-30 08:45:54,057 Iter 5450, Minibatch Loss= 0.1493, Training Accuracy= 0.9525, Minibatch error= 4.8%\n",
      "2017-03-30 08:46:08,767 Iter 5455, Minibatch Loss= 0.0904, Training Accuracy= 0.9879, Minibatch error= 1.2%\n",
      "2017-03-30 08:46:23,528 Iter 5460, Minibatch Loss= 0.3543, Training Accuracy= 0.7975, Minibatch error= 20.2%\n",
      "2017-03-30 08:46:38,387 Iter 5465, Minibatch Loss= 0.1515, Training Accuracy= 0.9616, Minibatch error= 3.8%\n",
      "2017-03-30 08:46:53,116 Iter 5470, Minibatch Loss= 0.1741, Training Accuracy= 0.9689, Minibatch error= 3.1%\n",
      "2017-03-30 08:47:07,785 Iter 5475, Minibatch Loss= 0.2626, Training Accuracy= 0.8845, Minibatch error= 11.6%\n",
      "2017-03-30 08:47:23,259 Iter 5480, Minibatch Loss= 0.1641, Training Accuracy= 0.9501, Minibatch error= 5.0%\n",
      "2017-03-30 08:47:38,812 Iter 5485, Minibatch Loss= 0.0575, Training Accuracy= 0.9870, Minibatch error= 1.3%\n",
      "2017-03-30 08:47:54,965 Iter 5490, Minibatch Loss= 0.2660, Training Accuracy= 0.9197, Minibatch error= 8.0%\n",
      "2017-03-30 08:48:10,308 Iter 5495, Minibatch Loss= 0.2192, Training Accuracy= 0.9178, Minibatch error= 8.2%\n",
      "2017-03-30 08:48:21,998 Epoch 54, Average loss: 0.1958, learning rate: 0.0010\n",
      "2017-03-30 08:48:26,276 Verification error= 3.9%, loss= 0.1180\n",
      "2017-03-30 08:48:33,474 Iter 5500, Minibatch Loss= 0.0510, Training Accuracy= 0.9976, Minibatch error= 0.2%\n",
      "2017-03-30 08:48:48,909 Iter 5505, Minibatch Loss= 0.1505, Training Accuracy= 0.9455, Minibatch error= 5.4%\n",
      "2017-03-30 08:49:04,350 Iter 5510, Minibatch Loss= 0.1016, Training Accuracy= 0.9702, Minibatch error= 3.0%\n",
      "2017-03-30 08:49:19,869 Iter 5515, Minibatch Loss= 0.2776, Training Accuracy= 0.8919, Minibatch error= 10.8%\n",
      "2017-03-30 08:49:35,328 Iter 5520, Minibatch Loss= 0.1442, Training Accuracy= 0.9415, Minibatch error= 5.9%\n",
      "2017-03-30 08:49:50,793 Iter 5525, Minibatch Loss= 0.0990, Training Accuracy= 0.9763, Minibatch error= 2.4%\n",
      "2017-03-30 08:50:06,310 Iter 5530, Minibatch Loss= 0.1073, Training Accuracy= 0.9780, Minibatch error= 2.2%\n",
      "2017-03-30 08:50:21,773 Iter 5535, Minibatch Loss= 0.0973, Training Accuracy= 0.9706, Minibatch error= 2.9%\n",
      "2017-03-30 08:50:37,238 Iter 5540, Minibatch Loss= 0.1437, Training Accuracy= 0.9512, Minibatch error= 4.9%\n",
      "2017-03-30 08:50:52,752 Iter 5545, Minibatch Loss= 0.0486, Training Accuracy= 0.9945, Minibatch error= 0.6%\n",
      "2017-03-30 08:51:08,285 Iter 5550, Minibatch Loss= 0.3106, Training Accuracy= 0.8496, Minibatch error= 15.0%\n",
      "2017-03-30 08:51:23,803 Iter 5555, Minibatch Loss= 0.1729, Training Accuracy= 0.9558, Minibatch error= 4.4%\n",
      "2017-03-30 08:51:39,027 Iter 5560, Minibatch Loss= 0.1545, Training Accuracy= 0.9635, Minibatch error= 3.6%\n",
      "2017-03-30 08:51:53,168 Iter 5565, Minibatch Loss= 0.1844, Training Accuracy= 0.9389, Minibatch error= 6.1%\n",
      "2017-03-30 08:52:07,320 Iter 5570, Minibatch Loss= 0.1456, Training Accuracy= 0.9608, Minibatch error= 3.9%\n",
      "2017-03-30 08:52:21,478 Iter 5575, Minibatch Loss= 0.1182, Training Accuracy= 0.9703, Minibatch error= 3.0%\n",
      "2017-03-30 08:52:35,695 Iter 5580, Minibatch Loss= 0.1852, Training Accuracy= 0.9322, Minibatch error= 6.8%\n",
      "2017-03-30 08:52:49,987 Iter 5585, Minibatch Loss= 0.0500, Training Accuracy= 0.9950, Minibatch error= 0.5%\n",
      "2017-03-30 08:53:04,277 Iter 5590, Minibatch Loss= 0.0588, Training Accuracy= 0.9755, Minibatch error= 2.4%\n",
      "2017-03-30 08:53:18,756 Iter 5595, Minibatch Loss= 0.5038, Training Accuracy= 0.7966, Minibatch error= 20.3%\n",
      "2017-03-30 08:53:29,822 Epoch 55, Average loss: 0.1727, learning rate: 0.0010\n",
      "2017-03-30 08:53:33,735 Verification error= 3.8%, loss= 0.1121\n",
      "2017-03-30 08:53:40,737 Iter 5600, Minibatch Loss= 0.0556, Training Accuracy= 0.9936, Minibatch error= 0.6%\n",
      "2017-03-30 08:53:55,181 Iter 5605, Minibatch Loss= 0.1130, Training Accuracy= 0.9772, Minibatch error= 2.3%\n",
      "2017-03-30 08:54:09,588 Iter 5610, Minibatch Loss= 0.2466, Training Accuracy= 0.9290, Minibatch error= 7.1%\n",
      "2017-03-30 08:54:23,956 Iter 5615, Minibatch Loss= 0.2148, Training Accuracy= 0.9302, Minibatch error= 7.0%\n",
      "2017-03-30 08:54:38,425 Iter 5620, Minibatch Loss= 0.1649, Training Accuracy= 0.9671, Minibatch error= 3.3%\n",
      "2017-03-30 08:54:53,025 Iter 5625, Minibatch Loss= 0.2861, Training Accuracy= 0.8653, Minibatch error= 13.5%\n",
      "2017-03-30 08:55:07,748 Iter 5630, Minibatch Loss= 0.2113, Training Accuracy= 0.9197, Minibatch error= 8.0%\n",
      "2017-03-30 08:55:22,514 Iter 5635, Minibatch Loss= 0.1654, Training Accuracy= 0.9602, Minibatch error= 4.0%\n",
      "2017-03-30 08:55:37,214 Iter 5640, Minibatch Loss= 0.0770, Training Accuracy= 0.9824, Minibatch error= 1.8%\n",
      "2017-03-30 08:55:51,911 Iter 5645, Minibatch Loss= 0.1138, Training Accuracy= 0.9610, Minibatch error= 3.9%\n",
      "2017-03-30 08:56:06,506 Iter 5650, Minibatch Loss= 0.0563, Training Accuracy= 0.9855, Minibatch error= 1.4%\n",
      "2017-03-30 08:56:21,929 Iter 5655, Minibatch Loss= 0.3960, Training Accuracy= 0.7636, Minibatch error= 23.6%\n",
      "2017-03-30 08:56:37,634 Iter 5660, Minibatch Loss= 0.5786, Training Accuracy= 0.7904, Minibatch error= 21.0%\n",
      "2017-03-30 08:56:53,280 Iter 5665, Minibatch Loss= 0.1351, Training Accuracy= 0.9553, Minibatch error= 4.5%\n",
      "2017-03-30 08:57:08,836 Iter 5670, Minibatch Loss= 0.0562, Training Accuracy= 0.9791, Minibatch error= 2.1%\n",
      "2017-03-30 08:57:23,865 Iter 5675, Minibatch Loss= 0.0479, Training Accuracy= 0.9946, Minibatch error= 0.5%\n",
      "2017-03-30 08:57:38,840 Iter 5680, Minibatch Loss= 0.1043, Training Accuracy= 0.9716, Minibatch error= 2.8%\n",
      "2017-03-30 08:57:53,830 Iter 5685, Minibatch Loss= 0.1229, Training Accuracy= 0.9596, Minibatch error= 4.0%\n",
      "2017-03-30 08:58:08,922 Iter 5690, Minibatch Loss= 0.1090, Training Accuracy= 0.9743, Minibatch error= 2.6%\n",
      "2017-03-30 08:58:24,072 Iter 5695, Minibatch Loss= 0.0723, Training Accuracy= 0.9858, Minibatch error= 1.4%\n",
      "2017-03-30 08:58:35,675 Epoch 56, Average loss: 0.1675, learning rate: 0.0010\n",
      "2017-03-30 08:58:39,817 Verification error= 3.9%, loss= 0.1290\n",
      "2017-03-30 08:58:46,783 Iter 5700, Minibatch Loss= 0.0920, Training Accuracy= 0.9782, Minibatch error= 2.2%\n",
      "2017-03-30 08:59:01,992 Iter 5705, Minibatch Loss= 0.1603, Training Accuracy= 0.9489, Minibatch error= 5.1%\n",
      "2017-03-30 08:59:17,336 Iter 5710, Minibatch Loss= 0.0693, Training Accuracy= 0.9883, Minibatch error= 1.2%\n",
      "2017-03-30 08:59:32,801 Iter 5715, Minibatch Loss= 0.1942, Training Accuracy= 0.9409, Minibatch error= 5.9%\n",
      "2017-03-30 08:59:48,211 Iter 5720, Minibatch Loss= 0.1191, Training Accuracy= 0.9835, Minibatch error= 1.7%\n",
      "2017-03-30 09:00:03,757 Iter 5725, Minibatch Loss= 0.9854, Training Accuracy= 0.6671, Minibatch error= 33.3%\n",
      "2017-03-30 09:00:19,366 Iter 5730, Minibatch Loss= 0.1644, Training Accuracy= 0.9557, Minibatch error= 4.4%\n",
      "2017-03-30 09:00:34,971 Iter 5735, Minibatch Loss= 0.0952, Training Accuracy= 0.9950, Minibatch error= 0.5%\n",
      "2017-03-30 09:00:50,646 Iter 5740, Minibatch Loss= 0.1782, Training Accuracy= 0.9255, Minibatch error= 7.4%\n",
      "2017-03-30 09:01:06,232 Iter 5745, Minibatch Loss= 0.0938, Training Accuracy= 0.9772, Minibatch error= 2.3%\n",
      "2017-03-30 09:01:21,851 Iter 5750, Minibatch Loss= 0.0959, Training Accuracy= 0.9740, Minibatch error= 2.6%\n",
      "2017-03-30 09:01:37,386 Iter 5755, Minibatch Loss= 0.0848, Training Accuracy= 0.9928, Minibatch error= 0.7%\n",
      "2017-03-30 09:01:52,947 Iter 5760, Minibatch Loss= 0.1858, Training Accuracy= 0.9417, Minibatch error= 5.8%\n",
      "2017-03-30 09:02:08,582 Iter 5765, Minibatch Loss= 0.1658, Training Accuracy= 0.9492, Minibatch error= 5.1%\n",
      "2017-03-30 09:02:24,233 Iter 5770, Minibatch Loss= 0.0874, Training Accuracy= 0.9911, Minibatch error= 0.9%\n",
      "2017-03-30 09:02:39,880 Iter 5775, Minibatch Loss= 0.1808, Training Accuracy= 0.9239, Minibatch error= 7.6%\n",
      "2017-03-30 09:02:55,533 Iter 5780, Minibatch Loss= 0.0939, Training Accuracy= 0.9888, Minibatch error= 1.1%\n",
      "2017-03-30 09:03:11,198 Iter 5785, Minibatch Loss= 0.1660, Training Accuracy= 0.9547, Minibatch error= 4.5%\n",
      "2017-03-30 09:03:26,924 Iter 5790, Minibatch Loss= 0.1075, Training Accuracy= 0.9692, Minibatch error= 3.1%\n",
      "2017-03-30 09:03:42,525 Iter 5795, Minibatch Loss= 0.5121, Training Accuracy= 0.8106, Minibatch error= 18.9%\n",
      "2017-03-30 09:03:54,621 Epoch 57, Average loss: 0.1799, learning rate: 0.0010\n",
      "2017-03-30 09:03:58,954 Verification error= 4.0%, loss= 0.1034\n",
      "2017-03-30 09:04:06,391 Iter 5800, Minibatch Loss= 0.0724, Training Accuracy= 0.9875, Minibatch error= 1.2%\n",
      "2017-03-30 09:04:22,005 Iter 5805, Minibatch Loss= 0.1108, Training Accuracy= 0.9622, Minibatch error= 3.8%\n",
      "2017-03-30 09:04:37,719 Iter 5810, Minibatch Loss= 0.3103, Training Accuracy= 0.8513, Minibatch error= 14.9%\n",
      "2017-03-30 09:04:53,465 Iter 5815, Minibatch Loss= 0.0718, Training Accuracy= 0.9833, Minibatch error= 1.7%\n",
      "2017-03-30 09:05:09,184 Iter 5820, Minibatch Loss= 0.1591, Training Accuracy= 0.9570, Minibatch error= 4.3%\n",
      "2017-03-30 09:05:24,874 Iter 5825, Minibatch Loss= 0.0520, Training Accuracy= 0.9970, Minibatch error= 0.3%\n",
      "2017-03-30 09:05:40,577 Iter 5830, Minibatch Loss= 0.1142, Training Accuracy= 0.9831, Minibatch error= 1.7%\n",
      "2017-03-30 09:05:56,319 Iter 5835, Minibatch Loss= 0.0775, Training Accuracy= 0.9811, Minibatch error= 1.9%\n",
      "2017-03-30 09:06:12,014 Iter 5840, Minibatch Loss= 0.1656, Training Accuracy= 0.9304, Minibatch error= 7.0%\n",
      "2017-03-30 09:06:27,811 Iter 5845, Minibatch Loss= 0.1565, Training Accuracy= 0.9618, Minibatch error= 3.8%\n",
      "2017-03-30 09:06:43,559 Iter 5850, Minibatch Loss= 0.1620, Training Accuracy= 0.9614, Minibatch error= 3.9%\n",
      "2017-03-30 09:06:59,234 Iter 5855, Minibatch Loss= 0.1254, Training Accuracy= 0.9531, Minibatch error= 4.7%\n",
      "2017-03-30 09:07:14,936 Iter 5860, Minibatch Loss= 0.3144, Training Accuracy= 0.8474, Minibatch error= 15.3%\n",
      "2017-03-30 09:07:30,601 Iter 5865, Minibatch Loss= 0.0191, Training Accuracy= 0.9973, Minibatch error= 0.3%\n",
      "2017-03-30 09:07:46,312 Iter 5870, Minibatch Loss= 0.0936, Training Accuracy= 0.9761, Minibatch error= 2.4%\n",
      "2017-03-30 09:08:02,030 Iter 5875, Minibatch Loss= 0.0862, Training Accuracy= 0.9707, Minibatch error= 2.9%\n",
      "2017-03-30 09:08:17,794 Iter 5880, Minibatch Loss= 0.0792, Training Accuracy= 0.9885, Minibatch error= 1.1%\n",
      "2017-03-30 09:08:33,659 Iter 5885, Minibatch Loss= 0.2323, Training Accuracy= 0.9200, Minibatch error= 8.0%\n",
      "2017-03-30 09:08:49,508 Iter 5890, Minibatch Loss= 0.1535, Training Accuracy= 0.9753, Minibatch error= 2.5%\n",
      "2017-03-30 09:09:05,258 Iter 5895, Minibatch Loss= 0.0565, Training Accuracy= 0.9873, Minibatch error= 1.3%\n",
      "2017-03-30 09:09:17,440 Epoch 58, Average loss: 0.1841, learning rate: 0.0010\n",
      "2017-03-30 09:09:21,836 Verification error= 4.5%, loss= 0.1759\n",
      "2017-03-30 09:09:28,965 Iter 5900, Minibatch Loss= 0.1311, Training Accuracy= 0.9725, Minibatch error= 2.7%\n",
      "2017-03-30 09:09:44,849 Iter 5905, Minibatch Loss= 0.1035, Training Accuracy= 0.9754, Minibatch error= 2.5%\n",
      "2017-03-30 09:10:00,750 Iter 5910, Minibatch Loss= 0.1465, Training Accuracy= 0.9617, Minibatch error= 3.8%\n",
      "2017-03-30 09:10:16,541 Iter 5915, Minibatch Loss= 0.1241, Training Accuracy= 0.9541, Minibatch error= 4.6%\n",
      "2017-03-30 09:10:32,430 Iter 5920, Minibatch Loss= 0.1095, Training Accuracy= 0.9680, Minibatch error= 3.2%\n",
      "2017-03-30 09:10:48,340 Iter 5925, Minibatch Loss= 0.0844, Training Accuracy= 0.9791, Minibatch error= 2.1%\n",
      "2017-03-30 09:11:04,242 Iter 5930, Minibatch Loss= 0.1294, Training Accuracy= 0.9559, Minibatch error= 4.4%\n",
      "2017-03-30 09:11:20,097 Iter 5935, Minibatch Loss= 0.1151, Training Accuracy= 0.9711, Minibatch error= 2.9%\n",
      "2017-03-30 09:11:35,925 Iter 5940, Minibatch Loss= 0.0812, Training Accuracy= 0.9846, Minibatch error= 1.5%\n",
      "2017-03-30 09:11:51,766 Iter 5945, Minibatch Loss= 0.1597, Training Accuracy= 0.9353, Minibatch error= 6.5%\n",
      "2017-03-30 09:12:07,468 Iter 5950, Minibatch Loss= 0.0608, Training Accuracy= 0.9922, Minibatch error= 0.8%\n",
      "2017-03-30 09:12:22,516 Iter 5955, Minibatch Loss= 0.1565, Training Accuracy= 0.9317, Minibatch error= 6.8%\n",
      "2017-03-30 09:12:37,573 Iter 5960, Minibatch Loss= 0.3586, Training Accuracy= 0.8546, Minibatch error= 14.5%\n",
      "2017-03-30 09:12:52,588 Iter 5965, Minibatch Loss= 0.2224, Training Accuracy= 0.8984, Minibatch error= 10.2%\n",
      "2017-03-30 09:13:07,551 Iter 5970, Minibatch Loss= 0.1338, Training Accuracy= 0.9658, Minibatch error= 3.4%\n",
      "2017-03-30 09:13:22,558 Iter 5975, Minibatch Loss= 0.7733, Training Accuracy= 0.6820, Minibatch error= 31.8%\n",
      "2017-03-30 09:13:37,573 Iter 5980, Minibatch Loss= 0.1412, Training Accuracy= 0.9529, Minibatch error= 4.7%\n",
      "2017-03-30 09:13:52,689 Iter 5985, Minibatch Loss= 0.0820, Training Accuracy= 0.9853, Minibatch error= 1.5%\n",
      "2017-03-30 09:14:07,738 Iter 5990, Minibatch Loss= 0.2870, Training Accuracy= 0.8510, Minibatch error= 14.9%\n",
      "2017-03-30 09:14:22,802 Iter 5995, Minibatch Loss= 0.9563, Training Accuracy= 0.4679, Minibatch error= 53.2%\n",
      "2017-03-30 09:14:34,394 Epoch 59, Average loss: 0.1832, learning rate: 0.0010\n",
      "2017-03-30 09:14:38,511 Verification error= 4.0%, loss= 0.1464\n",
      "2017-03-30 09:14:45,960 Iter 6000, Minibatch Loss= 0.1196, Training Accuracy= 0.9734, Minibatch error= 2.7%\n",
      "2017-03-30 09:15:01,186 Iter 6005, Minibatch Loss= 0.2324, Training Accuracy= 0.8998, Minibatch error= 10.0%\n",
      "2017-03-30 09:15:16,449 Iter 6010, Minibatch Loss= 0.4202, Training Accuracy= 0.8238, Minibatch error= 17.6%\n",
      "2017-03-30 09:15:32,604 Iter 6015, Minibatch Loss= 0.1264, Training Accuracy= 0.9644, Minibatch error= 3.6%\n",
      "2017-03-30 09:15:49,213 Iter 6020, Minibatch Loss= 0.2056, Training Accuracy= 0.8954, Minibatch error= 10.5%\n",
      "2017-03-30 09:16:06,098 Iter 6025, Minibatch Loss= 0.1069, Training Accuracy= 0.9726, Minibatch error= 2.7%\n",
      "2017-03-30 09:16:22,952 Iter 6030, Minibatch Loss= 0.4589, Training Accuracy= 0.7753, Minibatch error= 22.5%\n",
      "2017-03-30 09:16:39,021 Iter 6035, Minibatch Loss= 0.0728, Training Accuracy= 0.9909, Minibatch error= 0.9%\n",
      "2017-03-30 09:16:55,069 Iter 6040, Minibatch Loss= 0.1623, Training Accuracy= 0.9293, Minibatch error= 7.1%\n",
      "2017-03-30 09:17:11,128 Iter 6045, Minibatch Loss= 0.1551, Training Accuracy= 0.9434, Minibatch error= 5.7%\n",
      "2017-03-30 09:17:27,113 Iter 6050, Minibatch Loss= 0.0684, Training Accuracy= 0.9829, Minibatch error= 1.7%\n",
      "2017-03-30 09:17:42,933 Iter 6055, Minibatch Loss= 0.1741, Training Accuracy= 0.9373, Minibatch error= 6.3%\n",
      "2017-03-30 09:17:58,765 Iter 6060, Minibatch Loss= 0.1387, Training Accuracy= 0.9454, Minibatch error= 5.5%\n",
      "2017-03-30 09:18:14,596 Iter 6065, Minibatch Loss= 0.1163, Training Accuracy= 0.9509, Minibatch error= 4.9%\n",
      "2017-03-30 09:18:30,406 Iter 6070, Minibatch Loss= 0.0324, Training Accuracy= 0.9944, Minibatch error= 0.6%\n",
      "2017-03-30 09:18:46,340 Iter 6075, Minibatch Loss= 0.0785, Training Accuracy= 0.9783, Minibatch error= 2.2%\n",
      "2017-03-30 09:19:02,212 Iter 6080, Minibatch Loss= 0.2203, Training Accuracy= 0.9541, Minibatch error= 4.6%\n",
      "2017-03-30 09:19:18,087 Iter 6085, Minibatch Loss= 0.1569, Training Accuracy= 0.9742, Minibatch error= 2.6%\n",
      "2017-03-30 09:19:33,932 Iter 6090, Minibatch Loss= 0.2649, Training Accuracy= 0.8530, Minibatch error= 14.7%\n",
      "2017-03-30 09:19:49,771 Iter 6095, Minibatch Loss= 0.0902, Training Accuracy= 0.9697, Minibatch error= 3.0%\n",
      "2017-03-30 09:20:01,986 Epoch 60, Average loss: 0.1623, learning rate: 0.0010\n",
      "2017-03-30 09:20:06,349 Verification error= 4.0%, loss= 0.1281\n",
      "2017-03-30 09:20:13,984 Iter 6100, Minibatch Loss= 0.0781, Training Accuracy= 0.9885, Minibatch error= 1.1%\n",
      "2017-03-30 09:20:29,646 Iter 6105, Minibatch Loss= 0.5498, Training Accuracy= 0.7127, Minibatch error= 28.7%\n",
      "2017-03-30 09:20:45,589 Iter 6110, Minibatch Loss= 0.1140, Training Accuracy= 0.9711, Minibatch error= 2.9%\n",
      "2017-03-30 09:21:01,343 Iter 6115, Minibatch Loss= 0.1208, Training Accuracy= 0.9652, Minibatch error= 3.5%\n",
      "2017-03-30 09:21:17,130 Iter 6120, Minibatch Loss= 0.1025, Training Accuracy= 0.9963, Minibatch error= 0.4%\n",
      "2017-03-30 09:21:33,002 Iter 6125, Minibatch Loss= 0.1905, Training Accuracy= 0.9407, Minibatch error= 5.9%\n",
      "2017-03-30 09:21:48,833 Iter 6130, Minibatch Loss= 0.1001, Training Accuracy= 0.9766, Minibatch error= 2.3%\n",
      "2017-03-30 09:22:04,761 Iter 6135, Minibatch Loss= 0.0782, Training Accuracy= 0.9807, Minibatch error= 1.9%\n",
      "2017-03-30 09:22:20,744 Iter 6140, Minibatch Loss= 0.2671, Training Accuracy= 0.8966, Minibatch error= 10.3%\n",
      "2017-03-30 09:22:36,782 Iter 6145, Minibatch Loss= 0.0800, Training Accuracy= 0.9767, Minibatch error= 2.3%\n",
      "2017-03-30 09:22:52,791 Iter 6150, Minibatch Loss= 0.0722, Training Accuracy= 0.9856, Minibatch error= 1.4%\n",
      "2017-03-30 09:23:08,771 Iter 6155, Minibatch Loss= 0.0491, Training Accuracy= 0.9815, Minibatch error= 1.8%\n",
      "2017-03-30 09:23:24,756 Iter 6160, Minibatch Loss= 0.0959, Training Accuracy= 0.9733, Minibatch error= 2.7%\n",
      "2017-03-30 09:23:40,735 Iter 6165, Minibatch Loss= 0.0283, Training Accuracy= 0.9938, Minibatch error= 0.6%\n",
      "2017-03-30 09:23:56,702 Iter 6170, Minibatch Loss= 0.1567, Training Accuracy= 0.9280, Minibatch error= 7.2%\n",
      "2017-03-30 09:24:12,605 Iter 6175, Minibatch Loss= 0.1583, Training Accuracy= 0.9495, Minibatch error= 5.1%\n",
      "2017-03-30 09:24:28,525 Iter 6180, Minibatch Loss= 0.2048, Training Accuracy= 0.9088, Minibatch error= 9.1%\n",
      "2017-03-30 09:24:44,448 Iter 6185, Minibatch Loss= 0.1616, Training Accuracy= 0.9884, Minibatch error= 1.2%\n",
      "2017-03-30 09:25:00,326 Iter 6190, Minibatch Loss= 0.2213, Training Accuracy= 0.9343, Minibatch error= 6.6%\n",
      "2017-03-30 09:25:16,164 Iter 6195, Minibatch Loss= 0.2059, Training Accuracy= 0.9312, Minibatch error= 6.9%\n",
      "2017-03-30 09:25:28,411 Epoch 61, Average loss: 0.1788, learning rate: 0.0010\n",
      "2017-03-30 09:25:32,761 Verification error= 4.0%, loss= 0.1500\n",
      "2017-03-30 09:25:40,138 Iter 6200, Minibatch Loss= 0.2649, Training Accuracy= 0.8706, Minibatch error= 12.9%\n",
      "2017-03-30 09:25:56,157 Iter 6205, Minibatch Loss= 0.2691, Training Accuracy= 0.8657, Minibatch error= 13.4%\n",
      "2017-03-30 09:26:12,228 Iter 6210, Minibatch Loss= 0.0880, Training Accuracy= 0.9714, Minibatch error= 2.9%\n",
      "2017-03-30 09:26:28,296 Iter 6215, Minibatch Loss= 0.0767, Training Accuracy= 0.9797, Minibatch error= 2.0%\n",
      "2017-03-30 09:26:44,350 Iter 6220, Minibatch Loss= 0.4670, Training Accuracy= 0.7494, Minibatch error= 25.1%\n",
      "2017-03-30 09:27:00,406 Iter 6225, Minibatch Loss= 0.0989, Training Accuracy= 0.9918, Minibatch error= 0.8%\n",
      "2017-03-30 09:27:16,533 Iter 6230, Minibatch Loss= 0.1328, Training Accuracy= 0.9710, Minibatch error= 2.9%\n",
      "2017-03-30 09:27:32,610 Iter 6235, Minibatch Loss= 0.1933, Training Accuracy= 0.9318, Minibatch error= 6.8%\n",
      "2017-03-30 09:27:48,688 Iter 6240, Minibatch Loss= 0.1060, Training Accuracy= 0.9752, Minibatch error= 2.5%\n",
      "2017-03-30 09:28:04,776 Iter 6245, Minibatch Loss= 0.1047, Training Accuracy= 0.9684, Minibatch error= 3.2%\n",
      "2017-03-30 09:28:20,907 Iter 6250, Minibatch Loss= 0.0649, Training Accuracy= 0.9844, Minibatch error= 1.6%\n",
      "2017-03-30 09:28:37,052 Iter 6255, Minibatch Loss= 0.1173, Training Accuracy= 0.9857, Minibatch error= 1.4%\n",
      "2017-03-30 09:28:53,162 Iter 6260, Minibatch Loss= 0.0843, Training Accuracy= 0.9776, Minibatch error= 2.2%\n",
      "2017-03-30 09:29:08,081 Iter 6265, Minibatch Loss= 0.0390, Training Accuracy= 0.9905, Minibatch error= 1.0%\n",
      "2017-03-30 09:29:22,763 Iter 6270, Minibatch Loss= 0.6519, Training Accuracy= 0.6798, Minibatch error= 32.0%\n",
      "2017-03-30 09:29:37,452 Iter 6275, Minibatch Loss= 0.0365, Training Accuracy= 0.9980, Minibatch error= 0.2%\n",
      "2017-03-30 09:29:52,142 Iter 6280, Minibatch Loss= 0.1009, Training Accuracy= 0.9836, Minibatch error= 1.6%\n",
      "2017-03-30 09:30:06,911 Iter 6285, Minibatch Loss= 0.0610, Training Accuracy= 0.9871, Minibatch error= 1.3%\n",
      "2017-03-30 09:30:21,650 Iter 6290, Minibatch Loss= 0.1809, Training Accuracy= 0.9491, Minibatch error= 5.1%\n",
      "2017-03-30 09:30:36,380 Iter 6295, Minibatch Loss= 0.1227, Training Accuracy= 0.9857, Minibatch error= 1.4%\n",
      "2017-03-30 09:30:47,811 Epoch 62, Average loss: 0.1581, learning rate: 0.0010\n",
      "2017-03-30 09:30:51,767 Verification error= 4.2%, loss= 0.1102\n",
      "2017-03-30 09:30:59,304 Iter 6300, Minibatch Loss= 0.1355, Training Accuracy= 0.9724, Minibatch error= 2.8%\n",
      "2017-03-30 09:31:14,311 Iter 6305, Minibatch Loss= 0.3714, Training Accuracy= 0.8082, Minibatch error= 19.2%\n",
      "2017-03-30 09:31:29,290 Iter 6310, Minibatch Loss= 0.0789, Training Accuracy= 0.9934, Minibatch error= 0.7%\n",
      "2017-03-30 09:31:44,276 Iter 6315, Minibatch Loss= 0.1067, Training Accuracy= 0.9683, Minibatch error= 3.2%\n",
      "2017-03-30 09:31:59,265 Iter 6320, Minibatch Loss= 0.2186, Training Accuracy= 0.9088, Minibatch error= 9.1%\n",
      "2017-03-30 09:32:14,245 Iter 6325, Minibatch Loss= 0.2191, Training Accuracy= 0.9231, Minibatch error= 7.7%\n",
      "2017-03-30 09:32:29,337 Iter 6330, Minibatch Loss= 0.3225, Training Accuracy= 0.8520, Minibatch error= 14.8%\n",
      "2017-03-30 09:32:44,383 Iter 6335, Minibatch Loss= 0.1206, Training Accuracy= 0.9823, Minibatch error= 1.8%\n",
      "2017-03-30 09:32:59,559 Iter 6340, Minibatch Loss= 0.0543, Training Accuracy= 0.9972, Minibatch error= 0.3%\n",
      "2017-03-30 09:33:14,801 Iter 6345, Minibatch Loss= 0.0917, Training Accuracy= 0.9619, Minibatch error= 3.8%\n",
      "2017-03-30 09:33:30,025 Iter 6350, Minibatch Loss= 0.0688, Training Accuracy= 0.9908, Minibatch error= 0.9%\n",
      "2017-03-30 09:33:45,214 Iter 6355, Minibatch Loss= 0.2565, Training Accuracy= 0.8885, Minibatch error= 11.1%\n",
      "2017-03-30 09:34:00,500 Iter 6360, Minibatch Loss= 0.1611, Training Accuracy= 0.9493, Minibatch error= 5.1%\n",
      "2017-03-30 09:34:15,745 Iter 6365, Minibatch Loss= 0.3087, Training Accuracy= 0.8396, Minibatch error= 16.0%\n",
      "2017-03-30 09:34:31,075 Iter 6370, Minibatch Loss= 0.1254, Training Accuracy= 0.9861, Minibatch error= 1.4%\n",
      "2017-03-30 09:34:46,405 Iter 6375, Minibatch Loss= 0.1460, Training Accuracy= 0.9714, Minibatch error= 2.9%\n",
      "2017-03-30 09:35:01,715 Iter 6380, Minibatch Loss= 0.1132, Training Accuracy= 0.9738, Minibatch error= 2.6%\n",
      "2017-03-30 09:35:17,253 Iter 6385, Minibatch Loss= 0.1173, Training Accuracy= 0.9597, Minibatch error= 4.0%\n",
      "2017-03-30 09:35:32,808 Iter 6390, Minibatch Loss= 0.2443, Training Accuracy= 0.8650, Minibatch error= 13.5%\n",
      "2017-03-30 09:35:48,409 Iter 6395, Minibatch Loss= 0.1164, Training Accuracy= 0.9687, Minibatch error= 3.1%\n",
      "2017-03-30 09:36:00,467 Epoch 63, Average loss: 0.1920, learning rate: 0.0010\n",
      "2017-03-30 09:36:04,692 Verification error= 4.1%, loss= 0.1076\n",
      "2017-03-30 09:36:12,527 Iter 6400, Minibatch Loss= 0.0403, Training Accuracy= 0.9970, Minibatch error= 0.3%\n",
      "2017-03-30 09:36:28,378 Iter 6405, Minibatch Loss= 0.1873, Training Accuracy= 0.9162, Minibatch error= 8.4%\n",
      "2017-03-30 09:36:43,838 Iter 6410, Minibatch Loss= 0.0782, Training Accuracy= 0.9920, Minibatch error= 0.8%\n",
      "2017-03-30 09:36:59,287 Iter 6415, Minibatch Loss= 0.0512, Training Accuracy= 0.9920, Minibatch error= 0.8%\n",
      "2017-03-30 09:37:14,650 Iter 6420, Minibatch Loss= 0.0888, Training Accuracy= 0.9835, Minibatch error= 1.7%\n",
      "2017-03-30 09:37:30,007 Iter 6425, Minibatch Loss= 0.1094, Training Accuracy= 0.9587, Minibatch error= 4.1%\n",
      "2017-03-30 09:37:45,550 Iter 6430, Minibatch Loss= 0.0900, Training Accuracy= 0.9737, Minibatch error= 2.6%\n",
      "2017-03-30 09:38:01,311 Iter 6435, Minibatch Loss= 0.0424, Training Accuracy= 0.9899, Minibatch error= 1.0%\n",
      "2017-03-30 09:38:16,969 Iter 6440, Minibatch Loss= 0.0218, Training Accuracy= 0.9980, Minibatch error= 0.2%\n",
      "2017-03-30 09:38:32,665 Iter 6445, Minibatch Loss= 0.1858, Training Accuracy= 0.9040, Minibatch error= 9.6%\n",
      "2017-03-30 09:38:48,427 Iter 6450, Minibatch Loss= 0.0557, Training Accuracy= 0.9910, Minibatch error= 0.9%\n",
      "2017-03-30 09:39:04,145 Iter 6455, Minibatch Loss= 0.0734, Training Accuracy= 0.9884, Minibatch error= 1.2%\n",
      "2017-03-30 09:39:19,977 Iter 6460, Minibatch Loss= 0.1422, Training Accuracy= 0.9656, Minibatch error= 3.4%\n",
      "2017-03-30 09:39:35,905 Iter 6465, Minibatch Loss= 0.2168, Training Accuracy= 0.9307, Minibatch error= 6.9%\n",
      "2017-03-30 09:39:51,996 Iter 6470, Minibatch Loss= 0.2147, Training Accuracy= 0.9193, Minibatch error= 8.1%\n",
      "2017-03-30 09:40:07,996 Iter 6475, Minibatch Loss= 0.1397, Training Accuracy= 0.9832, Minibatch error= 1.7%\n",
      "2017-03-30 09:40:23,976 Iter 6480, Minibatch Loss= 0.2792, Training Accuracy= 0.9059, Minibatch error= 9.4%\n",
      "2017-03-30 09:40:40,072 Iter 6485, Minibatch Loss= 0.2124, Training Accuracy= 0.9668, Minibatch error= 3.3%\n",
      "2017-03-30 09:40:56,050 Iter 6490, Minibatch Loss= 0.1778, Training Accuracy= 0.9709, Minibatch error= 2.9%\n",
      "2017-03-30 09:41:12,047 Iter 6495, Minibatch Loss= 0.0418, Training Accuracy= 0.9987, Minibatch error= 0.1%\n",
      "2017-03-30 09:41:24,390 Epoch 64, Average loss: 0.1680, learning rate: 0.0010\n",
      "2017-03-30 09:41:28,678 Verification error= 4.2%, loss= 0.1008\n",
      "2017-03-30 09:41:36,167 Iter 6500, Minibatch Loss= 0.0871, Training Accuracy= 0.9864, Minibatch error= 1.4%\n",
      "2017-03-30 09:41:52,338 Iter 6505, Minibatch Loss= 0.0614, Training Accuracy= 0.9902, Minibatch error= 1.0%\n",
      "2017-03-30 09:42:08,582 Iter 6510, Minibatch Loss= 0.1074, Training Accuracy= 0.9854, Minibatch error= 1.5%\n",
      "2017-03-30 09:42:24,870 Iter 6515, Minibatch Loss= 0.1745, Training Accuracy= 0.9576, Minibatch error= 4.2%\n",
      "2017-03-30 09:42:41,139 Iter 6520, Minibatch Loss= 0.1518, Training Accuracy= 0.9637, Minibatch error= 3.6%\n",
      "2017-03-30 09:42:57,304 Iter 6525, Minibatch Loss= 0.1198, Training Accuracy= 0.9792, Minibatch error= 2.1%\n",
      "2017-03-30 09:43:13,414 Iter 6530, Minibatch Loss= 0.4024, Training Accuracy= 0.7655, Minibatch error= 23.4%\n",
      "2017-03-30 09:43:29,578 Iter 6535, Minibatch Loss= 0.1382, Training Accuracy= 0.9663, Minibatch error= 3.4%\n",
      "2017-03-30 09:43:45,802 Iter 6540, Minibatch Loss= 0.0560, Training Accuracy= 0.9965, Minibatch error= 0.4%\n",
      "2017-03-30 09:44:01,987 Iter 6545, Minibatch Loss= 0.0646, Training Accuracy= 0.9967, Minibatch error= 0.3%\n",
      "2017-03-30 09:44:17,127 Iter 6550, Minibatch Loss= 0.1273, Training Accuracy= 0.9747, Minibatch error= 2.5%\n",
      "2017-03-30 09:44:32,003 Iter 6555, Minibatch Loss= 0.2217, Training Accuracy= 0.9072, Minibatch error= 9.3%\n",
      "2017-03-30 09:44:46,901 Iter 6560, Minibatch Loss= 0.0960, Training Accuracy= 0.9795, Minibatch error= 2.1%\n",
      "2017-03-30 09:45:01,732 Iter 6565, Minibatch Loss= 0.2065, Training Accuracy= 0.9222, Minibatch error= 7.8%\n",
      "2017-03-30 09:45:16,611 Iter 6570, Minibatch Loss= 0.1696, Training Accuracy= 0.9436, Minibatch error= 5.6%\n",
      "2017-03-30 09:45:31,497 Iter 6575, Minibatch Loss= 0.2345, Training Accuracy= 0.9090, Minibatch error= 9.1%\n",
      "2017-03-30 09:45:46,397 Iter 6580, Minibatch Loss= 0.0368, Training Accuracy= 0.9975, Minibatch error= 0.2%\n",
      "2017-03-30 09:46:01,314 Iter 6585, Minibatch Loss= 0.4601, Training Accuracy= 0.7721, Minibatch error= 22.8%\n",
      "2017-03-30 09:46:16,212 Iter 6590, Minibatch Loss= 0.1233, Training Accuracy= 0.9667, Minibatch error= 3.3%\n",
      "2017-03-30 09:46:31,087 Iter 6595, Minibatch Loss= 0.0999, Training Accuracy= 0.9774, Minibatch error= 2.3%\n",
      "2017-03-30 09:46:42,668 Epoch 65, Average loss: 0.1840, learning rate: 0.0010\n",
      "2017-03-30 09:46:46,558 Verification error= 4.3%, loss= 0.1584\n",
      "2017-03-30 09:46:54,294 Iter 6600, Minibatch Loss= 0.0846, Training Accuracy= 0.9939, Minibatch error= 0.6%\n",
      "2017-03-30 09:47:09,272 Iter 6605, Minibatch Loss= 0.0861, Training Accuracy= 0.9897, Minibatch error= 1.0%\n",
      "2017-03-30 09:47:24,304 Iter 6610, Minibatch Loss= 0.4149, Training Accuracy= 0.8151, Minibatch error= 18.5%\n",
      "2017-03-30 09:47:39,330 Iter 6615, Minibatch Loss= 0.0831, Training Accuracy= 0.9987, Minibatch error= 0.1%\n",
      "2017-03-30 09:47:54,402 Iter 6620, Minibatch Loss= 0.0868, Training Accuracy= 0.9737, Minibatch error= 2.6%\n",
      "2017-03-30 09:48:09,542 Iter 6625, Minibatch Loss= 0.3567, Training Accuracy= 0.8499, Minibatch error= 15.0%\n",
      "2017-03-30 09:48:24,683 Iter 6630, Minibatch Loss= 0.1451, Training Accuracy= 0.9398, Minibatch error= 6.0%\n",
      "2017-03-30 09:48:39,887 Iter 6635, Minibatch Loss= 0.0703, Training Accuracy= 0.9779, Minibatch error= 2.2%\n",
      "2017-03-30 09:48:55,060 Iter 6640, Minibatch Loss= 0.0959, Training Accuracy= 0.9705, Minibatch error= 2.9%\n",
      "2017-03-30 09:49:10,232 Iter 6645, Minibatch Loss= 0.0802, Training Accuracy= 0.9834, Minibatch error= 1.7%\n",
      "2017-03-30 09:49:25,440 Iter 6650, Minibatch Loss= 0.0658, Training Accuracy= 0.9812, Minibatch error= 1.9%\n",
      "2017-03-30 09:49:40,637 Iter 6655, Minibatch Loss= 0.0498, Training Accuracy= 0.9808, Minibatch error= 1.9%\n",
      "2017-03-30 09:49:55,882 Iter 6660, Minibatch Loss= 0.0365, Training Accuracy= 0.9937, Minibatch error= 0.6%\n",
      "2017-03-30 09:50:11,134 Iter 6665, Minibatch Loss= 0.0962, Training Accuracy= 0.9893, Minibatch error= 1.1%\n",
      "2017-03-30 09:50:26,365 Iter 6670, Minibatch Loss= 0.0866, Training Accuracy= 0.9968, Minibatch error= 0.3%\n",
      "2017-03-30 09:50:41,638 Iter 6675, Minibatch Loss= 0.2127, Training Accuracy= 0.9509, Minibatch error= 4.9%\n",
      "2017-03-30 09:50:56,809 Iter 6680, Minibatch Loss= 0.2382, Training Accuracy= 0.9064, Minibatch error= 9.4%\n",
      "2017-03-30 09:51:12,128 Iter 6685, Minibatch Loss= 0.1889, Training Accuracy= 0.9543, Minibatch error= 4.6%\n",
      "2017-03-30 09:51:27,459 Iter 6690, Minibatch Loss= 0.0580, Training Accuracy= 0.9887, Minibatch error= 1.1%\n",
      "2017-03-30 09:51:42,753 Iter 6695, Minibatch Loss= 0.4651, Training Accuracy= 0.7449, Minibatch error= 25.5%\n",
      "2017-03-30 09:51:54,533 Epoch 66, Average loss: 0.1673, learning rate: 0.0010\n",
      "2017-03-30 09:51:58,549 Verification error= 4.7%, loss= 0.1135\n",
      "2017-03-30 09:52:06,020 Iter 6700, Minibatch Loss= 0.0480, Training Accuracy= 0.9963, Minibatch error= 0.4%\n",
      "2017-03-30 09:52:21,461 Iter 6705, Minibatch Loss= 0.0689, Training Accuracy= 0.9959, Minibatch error= 0.4%\n",
      "2017-03-30 09:52:36,891 Iter 6710, Minibatch Loss= 0.1310, Training Accuracy= 0.9848, Minibatch error= 1.5%\n",
      "2017-03-30 09:52:52,403 Iter 6715, Minibatch Loss= 0.7251, Training Accuracy= 0.6113, Minibatch error= 38.9%\n",
      "2017-03-30 09:53:07,844 Iter 6720, Minibatch Loss= 0.0768, Training Accuracy= 0.9861, Minibatch error= 1.4%\n",
      "2017-03-30 09:53:23,272 Iter 6725, Minibatch Loss= 0.0784, Training Accuracy= 0.9762, Minibatch error= 2.4%\n",
      "2017-03-30 09:53:38,709 Iter 6730, Minibatch Loss= 0.2374, Training Accuracy= 0.8654, Minibatch error= 13.5%\n",
      "2017-03-30 09:53:54,135 Iter 6735, Minibatch Loss= 0.0544, Training Accuracy= 0.9861, Minibatch error= 1.4%\n",
      "2017-03-30 09:54:09,620 Iter 6740, Minibatch Loss= 0.0447, Training Accuracy= 0.9919, Minibatch error= 0.8%\n",
      "2017-03-30 09:54:25,058 Iter 6745, Minibatch Loss= 0.0574, Training Accuracy= 0.9958, Minibatch error= 0.4%\n",
      "2017-03-30 09:54:40,541 Iter 6750, Minibatch Loss= 0.1172, Training Accuracy= 0.9495, Minibatch error= 5.0%\n",
      "2017-03-30 09:54:56,025 Iter 6755, Minibatch Loss= 0.1095, Training Accuracy= 0.9608, Minibatch error= 3.9%\n",
      "2017-03-30 09:55:11,474 Iter 6760, Minibatch Loss= 0.2186, Training Accuracy= 0.9202, Minibatch error= 8.0%\n",
      "2017-03-30 09:55:26,965 Iter 6765, Minibatch Loss= 0.2034, Training Accuracy= 0.9141, Minibatch error= 8.6%\n",
      "2017-03-30 09:55:42,380 Iter 6770, Minibatch Loss= 0.0913, Training Accuracy= 0.9701, Minibatch error= 3.0%\n",
      "2017-03-30 09:55:57,843 Iter 6775, Minibatch Loss= 0.0601, Training Accuracy= 0.9922, Minibatch error= 0.8%\n",
      "2017-03-30 09:56:13,294 Iter 6780, Minibatch Loss= 0.0889, Training Accuracy= 0.9788, Minibatch error= 2.1%\n",
      "2017-03-30 09:56:28,734 Iter 6785, Minibatch Loss= 0.1361, Training Accuracy= 0.9696, Minibatch error= 3.0%\n",
      "2017-03-30 09:56:44,205 Iter 6790, Minibatch Loss= 0.1238, Training Accuracy= 0.9670, Minibatch error= 3.3%\n",
      "2017-03-30 09:56:59,726 Iter 6795, Minibatch Loss= 0.6984, Training Accuracy= 0.5955, Minibatch error= 40.5%\n",
      "2017-03-30 09:57:11,729 Epoch 67, Average loss: 0.1605, learning rate: 0.0010\n",
      "2017-03-30 09:57:15,794 Verification error= 4.7%, loss= 0.1247\n",
      "2017-03-30 09:57:23,777 Iter 6800, Minibatch Loss= 0.1678, Training Accuracy= 0.9773, Minibatch error= 2.3%\n",
      "2017-03-30 09:57:39,301 Iter 6805, Minibatch Loss= 0.1682, Training Accuracy= 0.9739, Minibatch error= 2.6%\n",
      "2017-03-30 09:57:54,827 Iter 6810, Minibatch Loss= 0.1434, Training Accuracy= 0.9583, Minibatch error= 4.2%\n",
      "2017-03-30 09:58:10,319 Iter 6815, Minibatch Loss= 0.2257, Training Accuracy= 0.9281, Minibatch error= 7.2%\n",
      "2017-03-30 09:58:25,808 Iter 6820, Minibatch Loss= 0.0901, Training Accuracy= 0.9574, Minibatch error= 4.3%\n",
      "2017-03-30 09:58:41,499 Iter 6825, Minibatch Loss= 0.2121, Training Accuracy= 0.9224, Minibatch error= 7.8%\n",
      "2017-03-30 09:58:57,090 Iter 6830, Minibatch Loss= 0.0603, Training Accuracy= 0.9962, Minibatch error= 0.4%\n",
      "2017-03-30 09:59:12,719 Iter 6835, Minibatch Loss= 0.0336, Training Accuracy= 0.9980, Minibatch error= 0.2%\n",
      "2017-03-30 09:59:28,426 Iter 6840, Minibatch Loss= 0.1536, Training Accuracy= 0.9787, Minibatch error= 2.1%\n",
      "2017-03-30 09:59:44,057 Iter 6845, Minibatch Loss= 0.2098, Training Accuracy= 0.9455, Minibatch error= 5.4%\n",
      "2017-03-30 09:59:59,678 Iter 6850, Minibatch Loss= 0.1978, Training Accuracy= 0.9790, Minibatch error= 2.1%\n",
      "2017-03-30 10:00:15,327 Iter 6855, Minibatch Loss= 0.6809, Training Accuracy= 0.5303, Minibatch error= 47.0%\n",
      "2017-03-30 10:00:31,036 Iter 6860, Minibatch Loss= 0.1875, Training Accuracy= 0.9543, Minibatch error= 4.6%\n",
      "2017-03-30 10:00:46,590 Iter 6865, Minibatch Loss= 0.1161, Training Accuracy= 0.9886, Minibatch error= 1.1%\n",
      "2017-03-30 10:01:02,249 Iter 6870, Minibatch Loss= 0.0734, Training Accuracy= 0.9934, Minibatch error= 0.7%\n",
      "2017-03-30 10:01:17,854 Iter 6875, Minibatch Loss= 0.0750, Training Accuracy= 0.9870, Minibatch error= 1.3%\n",
      "2017-03-30 10:01:33,490 Iter 6880, Minibatch Loss= 0.0724, Training Accuracy= 0.9890, Minibatch error= 1.1%\n",
      "2017-03-30 10:01:49,147 Iter 6885, Minibatch Loss= 0.1762, Training Accuracy= 0.9211, Minibatch error= 7.9%\n",
      "2017-03-30 10:02:04,850 Iter 6890, Minibatch Loss= 0.1220, Training Accuracy= 0.9764, Minibatch error= 2.4%\n",
      "2017-03-30 10:02:20,566 Iter 6895, Minibatch Loss= 0.1151, Training Accuracy= 0.9666, Minibatch error= 3.3%\n",
      "2017-03-30 10:02:32,727 Epoch 68, Average loss: 0.1805, learning rate: 0.0010\n",
      "2017-03-30 10:02:36,857 Verification error= 4.1%, loss= 0.1117\n",
      "2017-03-30 10:02:44,515 Iter 6900, Minibatch Loss= 0.2003, Training Accuracy= 0.9249, Minibatch error= 7.5%\n",
      "2017-03-30 10:03:00,473 Iter 6905, Minibatch Loss= 0.0749, Training Accuracy= 0.9778, Minibatch error= 2.2%\n",
      "2017-03-30 10:03:16,269 Iter 6910, Minibatch Loss= 0.0509, Training Accuracy= 0.9863, Minibatch error= 1.4%\n",
      "2017-03-30 10:03:32,107 Iter 6915, Minibatch Loss= 0.1533, Training Accuracy= 0.9446, Minibatch error= 5.5%\n",
      "2017-03-30 10:03:48,016 Iter 6920, Minibatch Loss= 0.2120, Training Accuracy= 0.9121, Minibatch error= 8.8%\n",
      "2017-03-30 10:04:03,854 Iter 6925, Minibatch Loss= 0.2435, Training Accuracy= 0.8836, Minibatch error= 11.6%\n",
      "2017-03-30 10:04:19,779 Iter 6930, Minibatch Loss= 0.1304, Training Accuracy= 0.9478, Minibatch error= 5.2%\n",
      "2017-03-30 10:04:35,739 Iter 6935, Minibatch Loss= 0.3400, Training Accuracy= 0.8556, Minibatch error= 14.4%\n",
      "2017-03-30 10:04:51,701 Iter 6940, Minibatch Loss= 0.0682, Training Accuracy= 0.9832, Minibatch error= 1.7%\n",
      "2017-03-30 10:05:07,614 Iter 6945, Minibatch Loss= 0.5359, Training Accuracy= 0.7176, Minibatch error= 28.2%\n",
      "2017-03-30 10:05:23,580 Iter 6950, Minibatch Loss= 0.4302, Training Accuracy= 0.7750, Minibatch error= 22.5%\n",
      "2017-03-30 10:05:39,543 Iter 6955, Minibatch Loss= 0.2045, Training Accuracy= 0.9404, Minibatch error= 6.0%\n",
      "2017-03-30 10:05:55,493 Iter 6960, Minibatch Loss= 0.2651, Training Accuracy= 0.8753, Minibatch error= 12.5%\n",
      "2017-03-30 10:06:11,523 Iter 6965, Minibatch Loss= 0.0947, Training Accuracy= 0.9965, Minibatch error= 0.4%\n",
      "2017-03-30 10:06:27,596 Iter 6970, Minibatch Loss= 0.1487, Training Accuracy= 0.9896, Minibatch error= 1.0%\n",
      "2017-03-30 10:06:43,578 Iter 6975, Minibatch Loss= 0.1256, Training Accuracy= 0.9728, Minibatch error= 2.7%\n",
      "2017-03-30 10:06:59,248 Iter 6980, Minibatch Loss= 0.2504, Training Accuracy= 0.8972, Minibatch error= 10.3%\n",
      "2017-03-30 10:07:14,903 Iter 6985, Minibatch Loss= 0.1795, Training Accuracy= 0.9095, Minibatch error= 9.0%\n",
      "2017-03-30 10:07:30,449 Iter 6990, Minibatch Loss= 0.0529, Training Accuracy= 0.9901, Minibatch error= 1.0%\n",
      "2017-03-30 10:07:46,117 Iter 6995, Minibatch Loss= 0.2285, Training Accuracy= 0.8975, Minibatch error= 10.2%\n",
      "2017-03-30 10:07:58,151 Epoch 69, Average loss: 0.1856, learning rate: 0.0010\n",
      "2017-03-30 10:08:02,262 Verification error= 4.2%, loss= 0.1065\n",
      "2017-03-30 10:08:10,302 Iter 7000, Minibatch Loss= 0.1625, Training Accuracy= 0.9473, Minibatch error= 5.3%\n",
      "2017-03-30 10:08:26,029 Iter 7005, Minibatch Loss= 0.0445, Training Accuracy= 0.9910, Minibatch error= 0.9%\n",
      "2017-03-30 10:08:41,943 Iter 7010, Minibatch Loss= 0.6553, Training Accuracy= 0.7284, Minibatch error= 27.2%\n",
      "2017-03-30 10:08:57,759 Iter 7015, Minibatch Loss= 0.1879, Training Accuracy= 0.9269, Minibatch error= 7.3%\n",
      "2017-03-30 10:09:13,610 Iter 7020, Minibatch Loss= 0.1178, Training Accuracy= 0.9727, Minibatch error= 2.7%\n",
      "2017-03-30 10:09:29,454 Iter 7025, Minibatch Loss= 0.0810, Training Accuracy= 0.9841, Minibatch error= 1.6%\n",
      "2017-03-30 10:09:45,244 Iter 7030, Minibatch Loss= 0.0604, Training Accuracy= 0.9920, Minibatch error= 0.8%\n",
      "2017-03-30 10:10:01,081 Iter 7035, Minibatch Loss= 0.1204, Training Accuracy= 0.9660, Minibatch error= 3.4%\n",
      "2017-03-30 10:10:16,931 Iter 7040, Minibatch Loss= 0.0823, Training Accuracy= 0.9788, Minibatch error= 2.1%\n",
      "2017-03-30 10:10:32,865 Iter 7045, Minibatch Loss= 0.3141, Training Accuracy= 0.8687, Minibatch error= 13.1%\n",
      "2017-03-30 10:10:48,771 Iter 7050, Minibatch Loss= 0.0681, Training Accuracy= 0.9954, Minibatch error= 0.5%\n",
      "2017-03-30 10:11:04,511 Iter 7055, Minibatch Loss= 0.0550, Training Accuracy= 0.9944, Minibatch error= 0.6%\n",
      "2017-03-30 10:11:20,280 Iter 7060, Minibatch Loss= 0.2326, Training Accuracy= 0.9091, Minibatch error= 9.1%\n",
      "2017-03-30 10:11:36,051 Iter 7065, Minibatch Loss= 0.2434, Training Accuracy= 0.8889, Minibatch error= 11.1%\n",
      "2017-03-30 10:11:51,785 Iter 7070, Minibatch Loss= 0.4506, Training Accuracy= 0.8234, Minibatch error= 17.7%\n",
      "2017-03-30 10:12:07,384 Iter 7075, Minibatch Loss= 0.0614, Training Accuracy= 0.9904, Minibatch error= 1.0%\n",
      "2017-03-30 10:12:23,090 Iter 7080, Minibatch Loss= 0.1294, Training Accuracy= 0.9662, Minibatch error= 3.4%\n",
      "2017-03-30 10:12:38,716 Iter 7085, Minibatch Loss= 0.2711, Training Accuracy= 0.8777, Minibatch error= 12.2%\n",
      "2017-03-30 10:12:54,442 Iter 7090, Minibatch Loss= 0.1116, Training Accuracy= 0.9926, Minibatch error= 0.7%\n",
      "2017-03-30 10:13:10,027 Iter 7095, Minibatch Loss= 0.0178, Training Accuracy= 0.9981, Minibatch error= 0.2%\n",
      "2017-03-30 10:13:22,092 Epoch 70, Average loss: 0.1413, learning rate: 0.0010\n",
      "2017-03-30 10:13:26,106 Verification error= 4.6%, loss= 0.0988\n",
      "2017-03-30 10:13:34,316 Iter 7100, Minibatch Loss= 0.0534, Training Accuracy= 0.9902, Minibatch error= 1.0%\n",
      "2017-03-30 10:13:49,902 Iter 7105, Minibatch Loss= 0.6010, Training Accuracy= 0.6981, Minibatch error= 30.2%\n",
      "2017-03-30 10:14:05,507 Iter 7110, Minibatch Loss= 0.1233, Training Accuracy= 0.9567, Minibatch error= 4.3%\n",
      "2017-03-30 10:14:21,135 Iter 7115, Minibatch Loss= 0.1154, Training Accuracy= 0.9662, Minibatch error= 3.4%\n",
      "2017-03-30 10:14:36,815 Iter 7120, Minibatch Loss= 0.1614, Training Accuracy= 0.9609, Minibatch error= 3.9%\n",
      "2017-03-30 10:14:52,485 Iter 7125, Minibatch Loss= 0.1619, Training Accuracy= 0.9848, Minibatch error= 1.5%\n",
      "2017-03-30 10:15:08,219 Iter 7130, Minibatch Loss= 0.1787, Training Accuracy= 0.9885, Minibatch error= 1.2%\n",
      "2017-03-30 10:15:23,904 Iter 7135, Minibatch Loss= 0.2229, Training Accuracy= 0.9257, Minibatch error= 7.4%\n",
      "2017-03-30 10:15:39,603 Iter 7140, Minibatch Loss= 0.1395, Training Accuracy= 0.9395, Minibatch error= 6.1%\n",
      "2017-03-30 10:15:55,515 Iter 7145, Minibatch Loss= 0.1162, Training Accuracy= 0.9544, Minibatch error= 4.6%\n",
      "2017-03-30 10:16:11,187 Iter 7150, Minibatch Loss= 0.1246, Training Accuracy= 0.9659, Minibatch error= 3.4%\n",
      "2017-03-30 10:16:27,068 Iter 7155, Minibatch Loss= 0.1593, Training Accuracy= 0.9891, Minibatch error= 1.1%\n",
      "2017-03-30 10:16:42,787 Iter 7160, Minibatch Loss= 0.1090, Training Accuracy= 0.9695, Minibatch error= 3.1%\n",
      "2017-03-30 10:16:58,576 Iter 7165, Minibatch Loss= 0.0363, Training Accuracy= 0.9969, Minibatch error= 0.3%\n",
      "2017-03-30 10:17:14,391 Iter 7170, Minibatch Loss= 0.0914, Training Accuracy= 0.9787, Minibatch error= 2.1%\n",
      "2017-03-30 10:17:30,111 Iter 7175, Minibatch Loss= 0.0807, Training Accuracy= 0.9821, Minibatch error= 1.8%\n",
      "2017-03-30 10:17:45,825 Iter 7180, Minibatch Loss= 0.1846, Training Accuracy= 0.9386, Minibatch error= 6.1%\n",
      "2017-03-30 10:18:01,563 Iter 7185, Minibatch Loss= 0.0840, Training Accuracy= 0.9794, Minibatch error= 2.1%\n",
      "2017-03-30 10:18:17,426 Iter 7190, Minibatch Loss= 0.0537, Training Accuracy= 0.9927, Minibatch error= 0.7%\n",
      "2017-03-30 10:18:33,372 Iter 7195, Minibatch Loss= 0.1401, Training Accuracy= 0.9321, Minibatch error= 6.8%\n",
      "2017-03-30 10:18:45,666 Epoch 71, Average loss: 0.1652, learning rate: 0.0010\n",
      "2017-03-30 10:18:49,746 Verification error= 4.7%, loss= 0.1069\n",
      "2017-03-30 10:18:57,496 Iter 7200, Minibatch Loss= 0.0654, Training Accuracy= 0.9944, Minibatch error= 0.6%\n",
      "2017-03-30 10:19:13,502 Iter 7205, Minibatch Loss= 0.1250, Training Accuracy= 0.9661, Minibatch error= 3.4%\n",
      "2017-03-30 10:19:29,410 Iter 7210, Minibatch Loss= 0.3099, Training Accuracy= 0.8077, Minibatch error= 19.2%\n",
      "2017-03-30 10:19:45,435 Iter 7215, Minibatch Loss= 0.1067, Training Accuracy= 0.9767, Minibatch error= 2.3%\n",
      "2017-03-30 10:20:01,324 Iter 7220, Minibatch Loss= 0.1531, Training Accuracy= 0.9421, Minibatch error= 5.8%\n",
      "2017-03-30 10:20:17,147 Iter 7225, Minibatch Loss= 0.0856, Training Accuracy= 0.9784, Minibatch error= 2.2%\n",
      "2017-03-30 10:20:33,024 Iter 7230, Minibatch Loss= 0.4201, Training Accuracy= 0.7621, Minibatch error= 23.8%\n",
      "2017-03-30 10:20:48,909 Iter 7235, Minibatch Loss= 0.0627, Training Accuracy= 0.9881, Minibatch error= 1.2%\n",
      "2017-03-30 10:21:04,786 Iter 7240, Minibatch Loss= 0.1427, Training Accuracy= 0.9578, Minibatch error= 4.2%\n",
      "2017-03-30 10:21:20,734 Iter 7245, Minibatch Loss= 0.0479, Training Accuracy= 0.9942, Minibatch error= 0.6%\n",
      "2017-03-30 10:21:36,697 Iter 7250, Minibatch Loss= 0.1095, Training Accuracy= 0.9823, Minibatch error= 1.8%\n",
      "2017-03-30 10:21:52,733 Iter 7255, Minibatch Loss= 0.0781, Training Accuracy= 0.9909, Minibatch error= 0.9%\n",
      "2017-03-30 10:22:08,781 Iter 7260, Minibatch Loss= 0.4248, Training Accuracy= 0.7385, Minibatch error= 26.1%\n",
      "2017-03-30 10:22:24,732 Iter 7265, Minibatch Loss= 0.1594, Training Accuracy= 0.9559, Minibatch error= 4.4%\n",
      "2017-03-30 10:22:40,716 Iter 7270, Minibatch Loss= 0.1508, Training Accuracy= 0.9767, Minibatch error= 2.3%\n",
      "2017-03-30 10:22:56,623 Iter 7275, Minibatch Loss= 0.1832, Training Accuracy= 0.9599, Minibatch error= 4.0%\n",
      "2017-03-30 10:23:12,639 Iter 7280, Minibatch Loss= 0.1590, Training Accuracy= 0.9514, Minibatch error= 4.9%\n",
      "2017-03-30 10:23:28,785 Iter 7285, Minibatch Loss= 0.0777, Training Accuracy= 0.9648, Minibatch error= 3.5%\n",
      "2017-03-30 10:23:44,913 Iter 7290, Minibatch Loss= 0.2509, Training Accuracy= 0.9254, Minibatch error= 7.5%\n",
      "2017-03-30 10:24:01,018 Iter 7295, Minibatch Loss= 0.2221, Training Accuracy= 0.9140, Minibatch error= 8.6%\n",
      "2017-03-30 10:24:13,429 Epoch 72, Average loss: 0.1816, learning rate: 0.0010\n",
      "2017-03-30 10:24:17,607 Verification error= 4.0%, loss= 0.1061\n",
      "2017-03-30 10:24:26,044 Iter 7300, Minibatch Loss= 0.0469, Training Accuracy= 0.9960, Minibatch error= 0.4%\n",
      "2017-03-30 10:24:42,129 Iter 7305, Minibatch Loss= 0.1294, Training Accuracy= 0.9506, Minibatch error= 4.9%\n",
      "2017-03-30 10:24:58,320 Iter 7310, Minibatch Loss= 0.0863, Training Accuracy= 0.9760, Minibatch error= 2.4%\n",
      "2017-03-30 10:25:14,591 Iter 7315, Minibatch Loss= 0.2854, Training Accuracy= 0.8884, Minibatch error= 11.2%\n",
      "2017-03-30 10:25:30,795 Iter 7320, Minibatch Loss= 0.1128, Training Accuracy= 0.9620, Minibatch error= 3.8%\n",
      "2017-03-30 10:25:46,950 Iter 7325, Minibatch Loss= 0.0825, Training Accuracy= 0.9852, Minibatch error= 1.5%\n",
      "2017-03-30 10:26:03,212 Iter 7330, Minibatch Loss= 0.0962, Training Accuracy= 0.9752, Minibatch error= 2.5%\n",
      "2017-03-30 10:26:19,531 Iter 7335, Minibatch Loss= 0.0785, Training Accuracy= 0.9817, Minibatch error= 1.8%\n",
      "2017-03-30 10:26:36,053 Iter 7340, Minibatch Loss= 0.0878, Training Accuracy= 0.9628, Minibatch error= 3.7%\n",
      "2017-03-30 10:26:52,566 Iter 7345, Minibatch Loss= 0.0383, Training Accuracy= 0.9944, Minibatch error= 0.6%\n",
      "2017-03-30 10:27:09,152 Iter 7350, Minibatch Loss= 0.3504, Training Accuracy= 0.8157, Minibatch error= 18.4%\n",
      "2017-03-30 10:27:25,684 Iter 7355, Minibatch Loss= 0.1666, Training Accuracy= 0.9628, Minibatch error= 3.7%\n",
      "2017-03-30 10:27:42,231 Iter 7360, Minibatch Loss= 0.1485, Training Accuracy= 0.9728, Minibatch error= 2.7%\n",
      "2017-03-30 10:27:58,829 Iter 7365, Minibatch Loss= 0.1516, Training Accuracy= 0.9692, Minibatch error= 3.1%\n",
      "2017-03-30 10:28:15,467 Iter 7370, Minibatch Loss= 0.2491, Training Accuracy= 0.8686, Minibatch error= 13.1%\n",
      "2017-03-30 10:28:31,954 Iter 7375, Minibatch Loss= 0.1221, Training Accuracy= 0.9702, Minibatch error= 3.0%\n",
      "2017-03-30 10:28:48,580 Iter 7380, Minibatch Loss= 0.1695, Training Accuracy= 0.9419, Minibatch error= 5.8%\n",
      "2017-03-30 10:29:04,965 Iter 7385, Minibatch Loss= 0.0479, Training Accuracy= 0.9973, Minibatch error= 0.3%\n",
      "2017-03-30 10:29:21,535 Iter 7390, Minibatch Loss= 0.0601, Training Accuracy= 0.9749, Minibatch error= 2.5%\n",
      "2017-03-30 10:29:38,109 Iter 7395, Minibatch Loss= 0.5102, Training Accuracy= 0.7617, Minibatch error= 23.8%\n",
      "2017-03-30 10:29:50,835 Epoch 73, Average loss: 0.1657, learning rate: 0.0010\n",
      "2017-03-30 10:29:55,072 Verification error= 4.3%, loss= 0.1098\n",
      "2017-03-30 10:30:03,100 Iter 7400, Minibatch Loss= 0.0544, Training Accuracy= 0.9931, Minibatch error= 0.7%\n",
      "2017-03-30 10:30:19,639 Iter 7405, Minibatch Loss= 0.1087, Training Accuracy= 0.9777, Minibatch error= 2.2%\n",
      "2017-03-30 10:30:36,356 Iter 7410, Minibatch Loss= 0.2579, Training Accuracy= 0.9234, Minibatch error= 7.7%\n",
      "2017-03-30 10:30:53,272 Iter 7415, Minibatch Loss= 0.2063, Training Accuracy= 0.9296, Minibatch error= 7.0%\n",
      "2017-03-30 10:31:10,114 Iter 7420, Minibatch Loss= 0.1616, Training Accuracy= 0.9574, Minibatch error= 4.3%\n",
      "2017-03-30 10:31:26,838 Iter 7425, Minibatch Loss= 0.2840, Training Accuracy= 0.8630, Minibatch error= 13.7%\n",
      "2017-03-30 10:31:43,558 Iter 7430, Minibatch Loss= 0.2072, Training Accuracy= 0.9204, Minibatch error= 8.0%\n",
      "2017-03-30 10:32:00,366 Iter 7435, Minibatch Loss= 0.1340, Training Accuracy= 0.9657, Minibatch error= 3.4%\n",
      "2017-03-30 10:32:17,153 Iter 7440, Minibatch Loss= 0.0641, Training Accuracy= 0.9861, Minibatch error= 1.4%\n",
      "2017-03-30 10:32:33,873 Iter 7445, Minibatch Loss= 0.1177, Training Accuracy= 0.9520, Minibatch error= 4.8%\n",
      "2017-03-30 10:32:50,664 Iter 7450, Minibatch Loss= 0.0437, Training Accuracy= 0.9881, Minibatch error= 1.2%\n",
      "2017-03-30 10:33:07,472 Iter 7455, Minibatch Loss= 0.5378, Training Accuracy= 0.7001, Minibatch error= 30.0%\n",
      "2017-03-30 10:33:24,271 Iter 7460, Minibatch Loss= 0.4843, Training Accuracy= 0.8204, Minibatch error= 18.0%\n",
      "2017-03-30 10:33:41,093 Iter 7465, Minibatch Loss= 0.1073, Training Accuracy= 0.9630, Minibatch error= 3.7%\n",
      "2017-03-30 10:33:57,836 Iter 7470, Minibatch Loss= 0.0451, Training Accuracy= 0.9853, Minibatch error= 1.5%\n",
      "2017-03-30 10:34:14,600 Iter 7475, Minibatch Loss= 0.0339, Training Accuracy= 0.9961, Minibatch error= 0.4%\n",
      "2017-03-30 10:34:31,404 Iter 7480, Minibatch Loss= 0.0851, Training Accuracy= 0.9758, Minibatch error= 2.4%\n",
      "2017-03-30 10:34:48,173 Iter 7485, Minibatch Loss= 0.1092, Training Accuracy= 0.9664, Minibatch error= 3.4%\n",
      "2017-03-30 10:35:04,965 Iter 7490, Minibatch Loss= 0.0617, Training Accuracy= 0.9930, Minibatch error= 0.7%\n",
      "2017-03-30 10:35:21,802 Iter 7495, Minibatch Loss= 0.0404, Training Accuracy= 0.9922, Minibatch error= 0.8%\n",
      "2017-03-30 10:35:34,767 Epoch 74, Average loss: 0.1577, learning rate: 0.0010\n",
      "2017-03-30 10:35:39,109 Verification error= 4.0%, loss= 0.1311\n",
      "2017-03-30 10:35:47,811 Iter 7500, Minibatch Loss= 0.1070, Training Accuracy= 0.9716, Minibatch error= 2.8%\n",
      "2017-03-30 10:36:04,545 Iter 7505, Minibatch Loss= 0.1470, Training Accuracy= 0.9511, Minibatch error= 4.9%\n",
      "2017-03-30 10:36:21,425 Iter 7510, Minibatch Loss= 0.0797, Training Accuracy= 0.9904, Minibatch error= 1.0%\n",
      "2017-03-30 10:36:38,293 Iter 7515, Minibatch Loss= 0.1720, Training Accuracy= 0.9411, Minibatch error= 5.9%\n",
      "2017-03-30 10:36:55,126 Iter 7520, Minibatch Loss= 0.0943, Training Accuracy= 0.9910, Minibatch error= 0.9%\n",
      "2017-03-30 10:37:11,972 Iter 7525, Minibatch Loss= 1.0697, Training Accuracy= 0.6611, Minibatch error= 33.9%\n",
      "2017-03-30 10:37:28,819 Iter 7530, Minibatch Loss= 0.1313, Training Accuracy= 0.9665, Minibatch error= 3.3%\n",
      "2017-03-30 10:37:45,690 Iter 7535, Minibatch Loss= 0.0807, Training Accuracy= 0.9962, Minibatch error= 0.4%\n",
      "2017-03-30 10:38:02,610 Iter 7540, Minibatch Loss= 0.1571, Training Accuracy= 0.9305, Minibatch error= 6.9%\n",
      "2017-03-30 10:38:19,581 Iter 7545, Minibatch Loss= 0.0951, Training Accuracy= 0.9789, Minibatch error= 2.1%\n",
      "2017-03-30 10:38:36,547 Iter 7550, Minibatch Loss= 0.0871, Training Accuracy= 0.9748, Minibatch error= 2.5%\n",
      "2017-03-30 10:38:53,483 Iter 7555, Minibatch Loss= 0.0747, Training Accuracy= 0.9942, Minibatch error= 0.6%\n",
      "2017-03-30 10:39:10,412 Iter 7560, Minibatch Loss= 0.2082, Training Accuracy= 0.9144, Minibatch error= 8.6%\n",
      "2017-03-30 10:39:27,295 Iter 7565, Minibatch Loss= 0.1852, Training Accuracy= 0.9415, Minibatch error= 5.9%\n",
      "2017-03-30 10:39:44,230 Iter 7570, Minibatch Loss= 0.0855, Training Accuracy= 0.9950, Minibatch error= 0.5%\n",
      "2017-03-30 10:40:01,177 Iter 7575, Minibatch Loss= 0.1566, Training Accuracy= 0.9429, Minibatch error= 5.7%\n",
      "2017-03-30 10:40:18,030 Iter 7580, Minibatch Loss= 0.0965, Training Accuracy= 0.9888, Minibatch error= 1.1%\n",
      "2017-03-30 10:40:34,309 Iter 7585, Minibatch Loss= 0.1601, Training Accuracy= 0.9536, Minibatch error= 4.6%\n",
      "2017-03-30 10:40:51,223 Iter 7590, Minibatch Loss= 0.1154, Training Accuracy= 0.9697, Minibatch error= 3.0%\n",
      "2017-03-30 10:41:07,579 Iter 7595, Minibatch Loss= 0.4953, Training Accuracy= 0.8128, Minibatch error= 18.7%\n",
      "2017-03-30 10:41:20,146 Epoch 75, Average loss: 0.1745, learning rate: 0.0010\n",
      "2017-03-30 10:41:23,955 Verification error= 4.3%, loss= 0.1048\n",
      "2017-03-30 10:41:32,874 Iter 7600, Minibatch Loss= 0.0697, Training Accuracy= 0.9899, Minibatch error= 1.0%\n",
      "2017-03-30 10:41:48,775 Iter 7605, Minibatch Loss= 0.1056, Training Accuracy= 0.9616, Minibatch error= 3.8%\n",
      "2017-03-30 10:42:04,542 Iter 7610, Minibatch Loss= 0.3136, Training Accuracy= 0.8417, Minibatch error= 15.8%\n",
      "2017-03-30 10:42:20,140 Iter 7615, Minibatch Loss= 0.0802, Training Accuracy= 0.9889, Minibatch error= 1.1%\n",
      "2017-03-30 10:42:35,678 Iter 7620, Minibatch Loss= 0.1576, Training Accuracy= 0.9633, Minibatch error= 3.7%\n",
      "2017-03-30 10:42:51,295 Iter 7625, Minibatch Loss= 0.0398, Training Accuracy= 0.9995, Minibatch error= 0.0%\n",
      "2017-03-30 10:43:06,869 Iter 7630, Minibatch Loss= 0.0891, Training Accuracy= 0.9942, Minibatch error= 0.6%\n",
      "2017-03-30 10:43:22,493 Iter 7635, Minibatch Loss= 0.1033, Training Accuracy= 0.9721, Minibatch error= 2.8%\n",
      "2017-03-30 10:43:38,106 Iter 7640, Minibatch Loss= 0.1409, Training Accuracy= 0.9524, Minibatch error= 4.8%\n",
      "2017-03-30 10:43:53,731 Iter 7645, Minibatch Loss= 0.1205, Training Accuracy= 0.9690, Minibatch error= 3.1%\n",
      "2017-03-30 10:44:09,378 Iter 7650, Minibatch Loss= 0.1171, Training Accuracy= 0.9750, Minibatch error= 2.5%\n",
      "2017-03-30 10:44:25,013 Iter 7655, Minibatch Loss= 0.1213, Training Accuracy= 0.9520, Minibatch error= 4.8%\n",
      "2017-03-30 10:44:40,693 Iter 7660, Minibatch Loss= 0.2914, Training Accuracy= 0.8611, Minibatch error= 13.9%\n",
      "2017-03-30 10:44:56,352 Iter 7665, Minibatch Loss= 0.0181, Training Accuracy= 0.9978, Minibatch error= 0.2%\n",
      "2017-03-30 10:45:12,000 Iter 7670, Minibatch Loss= 0.0820, Training Accuracy= 0.9797, Minibatch error= 2.0%\n",
      "2017-03-30 10:45:27,659 Iter 7675, Minibatch Loss= 0.0758, Training Accuracy= 0.9761, Minibatch error= 2.4%\n",
      "2017-03-30 10:45:43,279 Iter 7680, Minibatch Loss= 0.0880, Training Accuracy= 0.9866, Minibatch error= 1.3%\n",
      "2017-03-30 10:45:58,818 Iter 7685, Minibatch Loss= 0.2129, Training Accuracy= 0.9212, Minibatch error= 7.9%\n",
      "2017-03-30 10:46:14,435 Iter 7690, Minibatch Loss= 0.1330, Training Accuracy= 0.9801, Minibatch error= 2.0%\n",
      "2017-03-30 10:46:30,035 Iter 7695, Minibatch Loss= 0.0453, Training Accuracy= 0.9939, Minibatch error= 0.6%\n",
      "2017-03-30 10:46:42,115 Epoch 76, Average loss: 0.1706, learning rate: 0.0010\n",
      "2017-03-30 10:46:45,922 Verification error= 4.7%, loss= 0.1534\n",
      "2017-03-30 10:46:53,930 Iter 7700, Minibatch Loss= 0.0957, Training Accuracy= 0.9763, Minibatch error= 2.4%\n",
      "2017-03-30 10:47:09,639 Iter 7705, Minibatch Loss= 0.0873, Training Accuracy= 0.9778, Minibatch error= 2.2%\n",
      "2017-03-30 10:47:25,304 Iter 7710, Minibatch Loss= 0.1042, Training Accuracy= 0.9745, Minibatch error= 2.5%\n",
      "2017-03-30 10:47:40,944 Iter 7715, Minibatch Loss= 0.0627, Training Accuracy= 0.9841, Minibatch error= 1.6%\n",
      "2017-03-30 10:47:56,600 Iter 7720, Minibatch Loss= 0.0914, Training Accuracy= 0.9754, Minibatch error= 2.5%\n",
      "2017-03-30 10:48:12,291 Iter 7725, Minibatch Loss= 0.0516, Training Accuracy= 0.9957, Minibatch error= 0.4%\n",
      "2017-03-30 10:48:28,072 Iter 7730, Minibatch Loss= 0.1640, Training Accuracy= 0.9400, Minibatch error= 6.0%\n",
      "2017-03-30 10:48:43,974 Iter 7735, Minibatch Loss= 0.1021, Training Accuracy= 0.9744, Minibatch error= 2.6%\n",
      "2017-03-30 10:48:59,976 Iter 7740, Minibatch Loss= 0.0745, Training Accuracy= 0.9811, Minibatch error= 1.9%\n",
      "2017-03-30 10:49:16,071 Iter 7745, Minibatch Loss= 0.1963, Training Accuracy= 0.9230, Minibatch error= 7.7%\n",
      "2017-03-30 10:49:32,215 Iter 7750, Minibatch Loss= 0.0651, Training Accuracy= 0.9857, Minibatch error= 1.4%\n",
      "2017-03-30 10:49:48,619 Iter 7755, Minibatch Loss= 0.1240, Training Accuracy= 0.9465, Minibatch error= 5.4%\n",
      "2017-03-30 10:50:05,030 Iter 7760, Minibatch Loss= 0.3070, Training Accuracy= 0.8767, Minibatch error= 12.3%\n",
      "2017-03-30 10:50:21,428 Iter 7765, Minibatch Loss= 0.3939, Training Accuracy= 0.8101, Minibatch error= 19.0%\n",
      "2017-03-30 10:50:37,836 Iter 7770, Minibatch Loss= 0.1248, Training Accuracy= 0.9613, Minibatch error= 3.9%\n",
      "2017-03-30 10:50:54,307 Iter 7775, Minibatch Loss= 0.9111, Training Accuracy= 0.6891, Minibatch error= 31.1%\n",
      "2017-03-30 10:51:10,759 Iter 7780, Minibatch Loss= 0.1658, Training Accuracy= 0.9298, Minibatch error= 7.0%\n",
      "2017-03-30 10:51:27,254 Iter 7785, Minibatch Loss= 0.0878, Training Accuracy= 0.9818, Minibatch error= 1.8%\n",
      "2017-03-30 10:51:43,787 Iter 7790, Minibatch Loss= 0.2673, Training Accuracy= 0.8741, Minibatch error= 12.6%\n",
      "2017-03-30 10:52:00,289 Iter 7795, Minibatch Loss= 0.9396, Training Accuracy= 0.4752, Minibatch error= 52.5%\n",
      "2017-03-30 10:52:13,008 Epoch 77, Average loss: 0.1768, learning rate: 0.0010\n",
      "2017-03-30 10:52:17,216 Verification error= 4.4%, loss= 0.1520\n",
      "2017-03-30 10:52:25,988 Iter 7800, Minibatch Loss= 0.1109, Training Accuracy= 0.9791, Minibatch error= 2.1%\n",
      "2017-03-30 10:52:42,843 Iter 7805, Minibatch Loss= 0.2126, Training Accuracy= 0.9185, Minibatch error= 8.1%\n",
      "2017-03-30 10:52:59,836 Iter 7810, Minibatch Loss= 0.4288, Training Accuracy= 0.8134, Minibatch error= 18.7%\n",
      "2017-03-30 10:53:16,761 Iter 7815, Minibatch Loss= 0.1276, Training Accuracy= 0.9669, Minibatch error= 3.3%\n",
      "2017-03-30 10:53:33,707 Iter 7820, Minibatch Loss= 0.1678, Training Accuracy= 0.9206, Minibatch error= 7.9%\n",
      "2017-03-30 10:53:50,643 Iter 7825, Minibatch Loss= 0.1106, Training Accuracy= 0.9716, Minibatch error= 2.8%\n",
      "2017-03-30 10:54:07,635 Iter 7830, Minibatch Loss= 0.4609, Training Accuracy= 0.7693, Minibatch error= 23.1%\n",
      "2017-03-30 10:54:24,731 Iter 7835, Minibatch Loss= 0.0763, Training Accuracy= 0.9879, Minibatch error= 1.2%\n",
      "2017-03-30 10:54:41,836 Iter 7840, Minibatch Loss= 0.1562, Training Accuracy= 0.9313, Minibatch error= 6.9%\n",
      "2017-03-30 10:54:59,009 Iter 7845, Minibatch Loss= 0.1557, Training Accuracy= 0.9410, Minibatch error= 5.9%\n",
      "2017-03-30 10:55:16,066 Iter 7850, Minibatch Loss= 0.0651, Training Accuracy= 0.9854, Minibatch error= 1.5%\n",
      "2017-03-30 10:55:33,194 Iter 7855, Minibatch Loss= 0.1614, Training Accuracy= 0.9395, Minibatch error= 6.0%\n",
      "2017-03-30 10:55:50,297 Iter 7860, Minibatch Loss= 0.1838, Training Accuracy= 0.9203, Minibatch error= 8.0%\n",
      "2017-03-30 10:56:07,423 Iter 7865, Minibatch Loss= 0.1113, Training Accuracy= 0.9487, Minibatch error= 5.1%\n",
      "2017-03-30 10:56:24,638 Iter 7870, Minibatch Loss= 0.0291, Training Accuracy= 0.9940, Minibatch error= 0.6%\n",
      "2017-03-30 10:56:41,794 Iter 7875, Minibatch Loss= 0.0822, Training Accuracy= 0.9762, Minibatch error= 2.4%\n",
      "2017-03-30 10:56:58,956 Iter 7880, Minibatch Loss= 0.2082, Training Accuracy= 0.9522, Minibatch error= 4.8%\n",
      "2017-03-30 10:57:16,104 Iter 7885, Minibatch Loss= 0.1370, Training Accuracy= 0.9835, Minibatch error= 1.7%\n",
      "2017-03-30 10:57:32,627 Iter 7890, Minibatch Loss= 0.2483, Training Accuracy= 0.8687, Minibatch error= 13.1%\n",
      "2017-03-30 10:57:49,334 Iter 7895, Minibatch Loss= 0.0924, Training Accuracy= 0.9708, Minibatch error= 2.9%\n",
      "2017-03-30 10:58:02,412 Epoch 78, Average loss: 0.1583, learning rate: 0.0010\n",
      "2017-03-30 10:58:06,696 Verification error= 3.9%, loss= 0.1363\n",
      "2017-03-30 10:58:15,156 Iter 7900, Minibatch Loss= 0.0832, Training Accuracy= 0.9878, Minibatch error= 1.2%\n",
      "2017-03-30 10:58:32,243 Iter 7905, Minibatch Loss= 0.5147, Training Accuracy= 0.7186, Minibatch error= 28.1%\n",
      "2017-03-30 10:58:49,461 Iter 7910, Minibatch Loss= 0.1131, Training Accuracy= 0.9679, Minibatch error= 3.2%\n",
      "2017-03-30 10:59:06,574 Iter 7915, Minibatch Loss= 0.1122, Training Accuracy= 0.9732, Minibatch error= 2.7%\n",
      "2017-03-30 10:59:23,734 Iter 7920, Minibatch Loss= 0.0923, Training Accuracy= 0.9978, Minibatch error= 0.2%\n",
      "2017-03-30 10:59:40,966 Iter 7925, Minibatch Loss= 0.1960, Training Accuracy= 0.9357, Minibatch error= 6.4%\n",
      "2017-03-30 10:59:58,214 Iter 7930, Minibatch Loss= 0.1011, Training Accuracy= 0.9756, Minibatch error= 2.4%\n",
      "2017-03-30 11:00:15,364 Iter 7935, Minibatch Loss= 0.0840, Training Accuracy= 0.9828, Minibatch error= 1.7%\n",
      "2017-03-30 11:00:32,597 Iter 7940, Minibatch Loss= 0.2375, Training Accuracy= 0.9170, Minibatch error= 8.3%\n",
      "2017-03-30 11:00:49,926 Iter 7945, Minibatch Loss= 0.0794, Training Accuracy= 0.9731, Minibatch error= 2.7%\n",
      "2017-03-30 11:01:07,091 Iter 7950, Minibatch Loss= 0.0571, Training Accuracy= 0.9854, Minibatch error= 1.5%\n",
      "2017-03-30 11:01:24,293 Iter 7955, Minibatch Loss= 0.0245, Training Accuracy= 0.9954, Minibatch error= 0.5%\n",
      "2017-03-30 11:01:41,081 Iter 7960, Minibatch Loss= 0.0905, Training Accuracy= 0.9682, Minibatch error= 3.2%\n",
      "2017-03-30 11:01:56,829 Iter 7965, Minibatch Loss= 0.0306, Training Accuracy= 0.9898, Minibatch error= 1.0%\n",
      "2017-03-30 11:02:12,583 Iter 7970, Minibatch Loss= 0.1663, Training Accuracy= 0.9269, Minibatch error= 7.3%\n",
      "2017-03-30 11:02:28,355 Iter 7975, Minibatch Loss= 0.1006, Training Accuracy= 0.9900, Minibatch error= 1.0%\n",
      "2017-03-30 11:02:44,162 Iter 7980, Minibatch Loss= 0.1651, Training Accuracy= 0.9418, Minibatch error= 5.8%\n",
      "2017-03-30 11:02:59,938 Iter 7985, Minibatch Loss= 0.1648, Training Accuracy= 0.9902, Minibatch error= 1.0%\n",
      "2017-03-30 11:03:15,660 Iter 7990, Minibatch Loss= 0.2055, Training Accuracy= 0.9488, Minibatch error= 5.1%\n",
      "2017-03-30 11:03:31,426 Iter 7995, Minibatch Loss= 0.1475, Training Accuracy= 0.9716, Minibatch error= 2.8%\n",
      "2017-03-30 11:03:43,612 Epoch 79, Average loss: 0.1761, learning rate: 0.0010\n",
      "2017-03-30 11:03:47,362 Verification error= 4.0%, loss= 0.1461\n",
      "2017-03-30 11:03:56,112 Iter 8000, Minibatch Loss= 0.3711, Training Accuracy= 0.7785, Minibatch error= 22.2%\n",
      "2017-03-30 11:04:11,900 Iter 8005, Minibatch Loss= 0.3154, Training Accuracy= 0.8147, Minibatch error= 18.5%\n",
      "2017-03-30 11:04:27,706 Iter 8010, Minibatch Loss= 0.0939, Training Accuracy= 0.9703, Minibatch error= 3.0%\n",
      "2017-03-30 11:04:43,545 Iter 8015, Minibatch Loss= 0.0639, Training Accuracy= 0.9899, Minibatch error= 1.0%\n",
      "2017-03-30 11:04:59,328 Iter 8020, Minibatch Loss= 0.4622, Training Accuracy= 0.7449, Minibatch error= 25.5%\n",
      "2017-03-30 11:05:15,110 Iter 8025, Minibatch Loss= 0.0810, Training Accuracy= 0.9942, Minibatch error= 0.6%\n",
      "2017-03-30 11:05:30,900 Iter 8030, Minibatch Loss= 0.1129, Training Accuracy= 0.9790, Minibatch error= 2.1%\n",
      "2017-03-30 11:05:46,687 Iter 8035, Minibatch Loss= 0.1778, Training Accuracy= 0.9416, Minibatch error= 5.8%\n",
      "2017-03-30 11:06:02,484 Iter 8040, Minibatch Loss= 0.0922, Training Accuracy= 0.9864, Minibatch error= 1.4%\n",
      "2017-03-30 11:06:18,331 Iter 8045, Minibatch Loss= 0.1128, Training Accuracy= 0.9643, Minibatch error= 3.6%\n",
      "2017-03-30 11:06:34,147 Iter 8050, Minibatch Loss= 0.0807, Training Accuracy= 0.9798, Minibatch error= 2.0%\n",
      "2017-03-30 11:06:49,982 Iter 8055, Minibatch Loss= 0.1229, Training Accuracy= 0.9824, Minibatch error= 1.8%\n",
      "2017-03-30 11:07:05,792 Iter 8060, Minibatch Loss= 0.0831, Training Accuracy= 0.9743, Minibatch error= 2.6%\n",
      "2017-03-30 11:07:21,595 Iter 8065, Minibatch Loss= 0.0366, Training Accuracy= 0.9932, Minibatch error= 0.7%\n",
      "2017-03-30 11:07:37,405 Iter 8070, Minibatch Loss= 0.6712, Training Accuracy= 0.6869, Minibatch error= 31.3%\n",
      "2017-03-30 11:07:53,188 Iter 8075, Minibatch Loss= 0.0345, Training Accuracy= 0.9977, Minibatch error= 0.2%\n",
      "2017-03-30 11:08:08,968 Iter 8080, Minibatch Loss= 0.0973, Training Accuracy= 0.9850, Minibatch error= 1.5%\n",
      "2017-03-30 11:08:24,762 Iter 8085, Minibatch Loss= 0.0691, Training Accuracy= 0.9951, Minibatch error= 0.5%\n",
      "2017-03-30 11:08:40,617 Iter 8090, Minibatch Loss= 0.1913, Training Accuracy= 0.9431, Minibatch error= 5.7%\n",
      "2017-03-30 11:08:56,466 Iter 8095, Minibatch Loss= 0.1189, Training Accuracy= 0.9855, Minibatch error= 1.5%\n",
      "2017-03-30 11:09:08,691 Epoch 80, Average loss: 0.1499, learning rate: 0.0010\n",
      "2017-03-30 11:09:12,517 Verification error= 4.3%, loss= 0.1160\n",
      "2017-03-30 11:09:20,743 Iter 8100, Minibatch Loss= 0.1406, Training Accuracy= 0.9631, Minibatch error= 3.7%\n",
      "2017-03-30 11:09:36,641 Iter 8105, Minibatch Loss= 0.3725, Training Accuracy= 0.8162, Minibatch error= 18.4%\n",
      "2017-03-30 11:09:52,573 Iter 8110, Minibatch Loss= 0.0847, Training Accuracy= 0.9944, Minibatch error= 0.6%\n",
      "2017-03-30 11:10:08,501 Iter 8115, Minibatch Loss= 0.1074, Training Accuracy= 0.9710, Minibatch error= 2.9%\n",
      "2017-03-30 11:10:24,471 Iter 8120, Minibatch Loss= 0.1976, Training Accuracy= 0.9195, Minibatch error= 8.0%\n",
      "2017-03-30 11:10:40,427 Iter 8125, Minibatch Loss= 0.2404, Training Accuracy= 0.9092, Minibatch error= 9.1%\n",
      "2017-03-30 11:10:56,348 Iter 8130, Minibatch Loss= 0.2712, Training Accuracy= 0.8755, Minibatch error= 12.4%\n",
      "2017-03-30 11:11:12,278 Iter 8135, Minibatch Loss= 0.1107, Training Accuracy= 0.9854, Minibatch error= 1.5%\n",
      "2017-03-30 11:11:28,194 Iter 8140, Minibatch Loss= 0.0555, Training Accuracy= 0.9974, Minibatch error= 0.3%\n",
      "2017-03-30 11:11:44,116 Iter 8145, Minibatch Loss= 0.0920, Training Accuracy= 0.9616, Minibatch error= 3.8%\n",
      "2017-03-30 11:12:00,262 Iter 8150, Minibatch Loss= 0.0720, Training Accuracy= 0.9875, Minibatch error= 1.2%\n",
      "2017-03-30 11:12:16,285 Iter 8155, Minibatch Loss= 0.2415, Training Accuracy= 0.8923, Minibatch error= 10.8%\n",
      "2017-03-30 11:12:32,242 Iter 8160, Minibatch Loss= 0.1598, Training Accuracy= 0.9543, Minibatch error= 4.6%\n",
      "2017-03-30 11:12:48,361 Iter 8165, Minibatch Loss= 0.3238, Training Accuracy= 0.8336, Minibatch error= 16.6%\n",
      "2017-03-30 11:13:04,411 Iter 8170, Minibatch Loss= 0.1123, Training Accuracy= 0.9895, Minibatch error= 1.0%\n",
      "2017-03-30 11:13:20,386 Iter 8175, Minibatch Loss= 0.1361, Training Accuracy= 0.9744, Minibatch error= 2.6%\n",
      "2017-03-30 11:13:36,399 Iter 8180, Minibatch Loss= 0.1218, Training Accuracy= 0.9671, Minibatch error= 3.3%\n",
      "2017-03-30 11:13:52,340 Iter 8185, Minibatch Loss= 0.0915, Training Accuracy= 0.9842, Minibatch error= 1.6%\n",
      "2017-03-30 11:14:08,318 Iter 8190, Minibatch Loss= 0.2148, Training Accuracy= 0.8859, Minibatch error= 11.4%\n",
      "2017-03-30 11:14:24,281 Iter 8195, Minibatch Loss= 0.1013, Training Accuracy= 0.9742, Minibatch error= 2.6%\n",
      "2017-03-30 11:14:36,630 Epoch 81, Average loss: 0.1798, learning rate: 0.0010\n",
      "2017-03-30 11:14:40,546 Verification error= 4.5%, loss= 0.1264\n",
      "2017-03-30 11:14:49,401 Iter 8200, Minibatch Loss= 0.0315, Training Accuracy= 0.9975, Minibatch error= 0.3%\n",
      "2017-03-30 11:15:05,481 Iter 8205, Minibatch Loss= 0.1862, Training Accuracy= 0.9233, Minibatch error= 7.7%\n",
      "2017-03-30 11:15:21,625 Iter 8210, Minibatch Loss= 0.0732, Training Accuracy= 0.9920, Minibatch error= 0.8%\n",
      "2017-03-30 11:15:37,728 Iter 8215, Minibatch Loss= 0.0656, Training Accuracy= 0.9890, Minibatch error= 1.1%\n",
      "2017-03-30 11:15:54,049 Iter 8220, Minibatch Loss= 0.0961, Training Accuracy= 0.9836, Minibatch error= 1.6%\n",
      "2017-03-30 11:16:10,294 Iter 8225, Minibatch Loss= 0.1089, Training Accuracy= 0.9645, Minibatch error= 3.5%\n",
      "2017-03-30 11:16:26,553 Iter 8230, Minibatch Loss= 0.0838, Training Accuracy= 0.9827, Minibatch error= 1.7%\n",
      "2017-03-30 11:16:42,849 Iter 8235, Minibatch Loss= 0.0484, Training Accuracy= 0.9894, Minibatch error= 1.1%\n",
      "2017-03-30 11:16:59,188 Iter 8240, Minibatch Loss= 0.0230, Training Accuracy= 0.9980, Minibatch error= 0.2%\n",
      "2017-03-30 11:17:15,477 Iter 8245, Minibatch Loss= 0.1896, Training Accuracy= 0.9074, Minibatch error= 9.3%\n",
      "2017-03-30 11:17:31,794 Iter 8250, Minibatch Loss= 0.0719, Training Accuracy= 0.9908, Minibatch error= 0.9%\n",
      "2017-03-30 11:17:48,122 Iter 8255, Minibatch Loss= 0.0730, Training Accuracy= 0.9945, Minibatch error= 0.6%\n",
      "2017-03-30 11:18:04,415 Iter 8260, Minibatch Loss= 0.1454, Training Accuracy= 0.9609, Minibatch error= 3.9%\n",
      "2017-03-30 11:18:20,656 Iter 8265, Minibatch Loss= 0.2095, Training Accuracy= 0.9256, Minibatch error= 7.4%\n",
      "2017-03-30 11:18:36,973 Iter 8270, Minibatch Loss= 0.2002, Training Accuracy= 0.9195, Minibatch error= 8.1%\n",
      "2017-03-30 11:18:53,363 Iter 8275, Minibatch Loss= 0.1169, Training Accuracy= 0.9844, Minibatch error= 1.6%\n",
      "2017-03-30 11:19:09,889 Iter 8280, Minibatch Loss= 0.2536, Training Accuracy= 0.9085, Minibatch error= 9.2%\n",
      "2017-03-30 11:19:26,306 Iter 8285, Minibatch Loss= 0.1898, Training Accuracy= 0.9695, Minibatch error= 3.1%\n",
      "2017-03-30 11:19:42,806 Iter 8290, Minibatch Loss= 0.1691, Training Accuracy= 0.9714, Minibatch error= 2.9%\n",
      "2017-03-30 11:19:59,366 Iter 8295, Minibatch Loss= 0.0520, Training Accuracy= 0.9986, Minibatch error= 0.1%\n",
      "2017-03-30 11:20:12,216 Epoch 82, Average loss: 0.1570, learning rate: 0.0010\n",
      "2017-03-30 11:20:16,370 Verification error= 4.1%, loss= 0.1114\n",
      "2017-03-30 11:20:25,603 Iter 8300, Minibatch Loss= 0.1031, Training Accuracy= 0.9823, Minibatch error= 1.8%\n",
      "2017-03-30 11:20:43,041 Iter 8305, Minibatch Loss= 0.0649, Training Accuracy= 0.9941, Minibatch error= 0.6%\n",
      "2017-03-30 11:21:00,966 Iter 8310, Minibatch Loss= 0.1157, Training Accuracy= 0.9858, Minibatch error= 1.4%\n",
      "2017-03-30 11:21:17,873 Iter 8315, Minibatch Loss= 0.1721, Training Accuracy= 0.9589, Minibatch error= 4.1%\n",
      "2017-03-30 11:21:34,798 Iter 8320, Minibatch Loss= 0.1527, Training Accuracy= 0.9668, Minibatch error= 3.3%\n",
      "2017-03-30 11:21:51,718 Iter 8325, Minibatch Loss= 0.1174, Training Accuracy= 0.9827, Minibatch error= 1.7%\n",
      "2017-03-30 11:22:08,763 Iter 8330, Minibatch Loss= 0.3858, Training Accuracy= 0.7761, Minibatch error= 22.4%\n",
      "2017-03-30 11:22:25,997 Iter 8335, Minibatch Loss= 0.1550, Training Accuracy= 0.9622, Minibatch error= 3.8%\n",
      "2017-03-30 11:22:43,369 Iter 8340, Minibatch Loss= 0.0620, Training Accuracy= 0.9967, Minibatch error= 0.3%\n",
      "2017-03-30 11:23:00,662 Iter 8345, Minibatch Loss= 0.0655, Training Accuracy= 0.9970, Minibatch error= 0.3%\n",
      "2017-03-30 11:23:18,083 Iter 8350, Minibatch Loss= 0.1338, Training Accuracy= 0.9773, Minibatch error= 2.3%\n",
      "2017-03-30 11:23:35,353 Iter 8355, Minibatch Loss= 0.2336, Training Accuracy= 0.9033, Minibatch error= 9.7%\n",
      "2017-03-30 11:23:52,696 Iter 8360, Minibatch Loss= 0.0950, Training Accuracy= 0.9775, Minibatch error= 2.2%\n",
      "2017-03-30 11:24:10,076 Iter 8365, Minibatch Loss= 0.2108, Training Accuracy= 0.9190, Minibatch error= 8.1%\n",
      "2017-03-30 11:24:27,526 Iter 8370, Minibatch Loss= 0.1873, Training Accuracy= 0.9351, Minibatch error= 6.5%\n",
      "2017-03-30 11:24:44,981 Iter 8375, Minibatch Loss= 0.2247, Training Accuracy= 0.9231, Minibatch error= 7.7%\n",
      "2017-03-30 11:25:02,458 Iter 8380, Minibatch Loss= 0.0369, Training Accuracy= 0.9975, Minibatch error= 0.2%\n",
      "2017-03-30 11:25:19,852 Iter 8385, Minibatch Loss= 0.4509, Training Accuracy= 0.7621, Minibatch error= 23.8%\n",
      "2017-03-30 11:25:36,712 Iter 8390, Minibatch Loss= 0.1233, Training Accuracy= 0.9698, Minibatch error= 3.0%\n",
      "2017-03-30 11:25:53,461 Iter 8395, Minibatch Loss= 0.1067, Training Accuracy= 0.9723, Minibatch error= 2.8%\n",
      "2017-03-30 11:26:06,586 Epoch 83, Average loss: 0.1749, learning rate: 0.0010\n",
      "2017-03-30 11:26:10,884 Verification error= 4.1%, loss= 0.1462\n",
      "2017-03-30 11:26:20,211 Iter 8400, Minibatch Loss= 0.0814, Training Accuracy= 0.9946, Minibatch error= 0.5%\n",
      "2017-03-30 11:26:37,940 Iter 8405, Minibatch Loss= 0.0849, Training Accuracy= 0.9904, Minibatch error= 1.0%\n",
      "2017-03-30 11:26:55,444 Iter 8410, Minibatch Loss= 0.3709, Training Accuracy= 0.8266, Minibatch error= 17.3%\n",
      "2017-03-30 11:27:13,017 Iter 8415, Minibatch Loss= 0.0914, Training Accuracy= 0.9984, Minibatch error= 0.2%\n",
      "2017-03-30 11:27:30,591 Iter 8420, Minibatch Loss= 0.0875, Training Accuracy= 0.9890, Minibatch error= 1.1%\n",
      "2017-03-30 11:27:48,116 Iter 8425, Minibatch Loss= 0.2661, Training Accuracy= 0.8845, Minibatch error= 11.5%\n",
      "2017-03-30 11:28:05,675 Iter 8430, Minibatch Loss= 0.1275, Training Accuracy= 0.9540, Minibatch error= 4.6%\n",
      "2017-03-30 11:28:23,223 Iter 8435, Minibatch Loss= 0.0671, Training Accuracy= 0.9782, Minibatch error= 2.2%\n",
      "2017-03-30 11:28:40,800 Iter 8440, Minibatch Loss= 0.0941, Training Accuracy= 0.9718, Minibatch error= 2.8%\n",
      "2017-03-30 11:28:58,327 Iter 8445, Minibatch Loss= 0.0843, Training Accuracy= 0.9842, Minibatch error= 1.6%\n",
      "2017-03-30 11:29:15,917 Iter 8450, Minibatch Loss= 0.0624, Training Accuracy= 0.9854, Minibatch error= 1.5%\n",
      "2017-03-30 11:29:33,465 Iter 8455, Minibatch Loss= 0.0319, Training Accuracy= 0.9897, Minibatch error= 1.0%\n",
      "2017-03-30 11:29:51,040 Iter 8460, Minibatch Loss= 0.0304, Training Accuracy= 0.9964, Minibatch error= 0.4%\n",
      "2017-03-30 11:30:07,657 Iter 8465, Minibatch Loss= 0.1002, Training Accuracy= 0.9888, Minibatch error= 1.1%\n",
      "2017-03-30 11:30:23,679 Iter 8470, Minibatch Loss= 0.0918, Training Accuracy= 0.9945, Minibatch error= 0.6%\n",
      "2017-03-30 11:30:39,679 Iter 8475, Minibatch Loss= 0.2055, Training Accuracy= 0.9500, Minibatch error= 5.0%\n",
      "2017-03-30 11:30:55,790 Iter 8480, Minibatch Loss= 0.2746, Training Accuracy= 0.8781, Minibatch error= 12.2%\n",
      "2017-03-30 11:31:11,884 Iter 8485, Minibatch Loss= 0.1909, Training Accuracy= 0.9621, Minibatch error= 3.8%\n",
      "2017-03-30 11:31:27,925 Iter 8490, Minibatch Loss= 0.0778, Training Accuracy= 0.9959, Minibatch error= 0.4%\n",
      "2017-03-30 11:31:43,934 Iter 8495, Minibatch Loss= 0.2956, Training Accuracy= 0.8625, Minibatch error= 13.8%\n",
      "2017-03-30 11:31:56,347 Epoch 84, Average loss: 0.1561, learning rate: 0.0010\n",
      "2017-03-30 11:32:00,134 Verification error= 4.2%, loss= 0.1279\n",
      "2017-03-30 11:32:09,142 Iter 8500, Minibatch Loss= 0.0588, Training Accuracy= 0.9969, Minibatch error= 0.3%\n",
      "2017-03-30 11:32:25,274 Iter 8505, Minibatch Loss= 0.0716, Training Accuracy= 0.9957, Minibatch error= 0.4%\n",
      "2017-03-30 11:32:41,398 Iter 8510, Minibatch Loss= 0.1526, Training Accuracy= 0.9729, Minibatch error= 2.7%\n",
      "2017-03-30 11:32:57,536 Iter 8515, Minibatch Loss= 0.6925, Training Accuracy= 0.6450, Minibatch error= 35.5%\n",
      "2017-03-30 11:33:13,634 Iter 8520, Minibatch Loss= 0.0930, Training Accuracy= 0.9842, Minibatch error= 1.6%\n",
      "2017-03-30 11:33:29,765 Iter 8525, Minibatch Loss= 0.1058, Training Accuracy= 0.9702, Minibatch error= 3.0%\n",
      "2017-03-30 11:33:45,911 Iter 8530, Minibatch Loss= 0.1337, Training Accuracy= 0.9471, Minibatch error= 5.3%\n",
      "2017-03-30 11:34:02,098 Iter 8535, Minibatch Loss= 0.0694, Training Accuracy= 0.9900, Minibatch error= 1.0%\n",
      "2017-03-30 11:34:18,228 Iter 8540, Minibatch Loss= 0.0742, Training Accuracy= 0.9853, Minibatch error= 1.5%\n",
      "2017-03-30 11:34:34,407 Iter 8545, Minibatch Loss= 0.0830, Training Accuracy= 0.9968, Minibatch error= 0.3%\n",
      "2017-03-30 11:34:50,630 Iter 8550, Minibatch Loss= 0.1516, Training Accuracy= 0.9396, Minibatch error= 6.0%\n",
      "2017-03-30 11:35:06,822 Iter 8555, Minibatch Loss= 0.1213, Training Accuracy= 0.9649, Minibatch error= 3.5%\n",
      "2017-03-30 11:35:22,985 Iter 8560, Minibatch Loss= 0.1863, Training Accuracy= 0.9283, Minibatch error= 7.2%\n",
      "2017-03-30 11:35:39,187 Iter 8565, Minibatch Loss= 0.1697, Training Accuracy= 0.9446, Minibatch error= 5.5%\n",
      "2017-03-30 11:35:55,337 Iter 8570, Minibatch Loss= 0.0958, Training Accuracy= 0.9685, Minibatch error= 3.2%\n",
      "2017-03-30 11:36:11,606 Iter 8575, Minibatch Loss= 0.0739, Training Accuracy= 0.9934, Minibatch error= 0.7%\n",
      "2017-03-30 11:36:27,803 Iter 8580, Minibatch Loss= 0.1024, Training Accuracy= 0.9737, Minibatch error= 2.6%\n",
      "2017-03-30 11:36:44,030 Iter 8585, Minibatch Loss= 0.1473, Training Accuracy= 0.9680, Minibatch error= 3.2%\n",
      "2017-03-30 11:37:00,291 Iter 8590, Minibatch Loss= 0.1123, Training Accuracy= 0.9836, Minibatch error= 1.6%\n",
      "2017-03-30 11:37:16,511 Iter 8595, Minibatch Loss= 0.6001, Training Accuracy= 0.6392, Minibatch error= 36.1%\n",
      "2017-03-30 11:37:29,078 Epoch 85, Average loss: 0.1542, learning rate: 0.0010\n",
      "2017-03-30 11:37:32,950 Verification error= 4.0%, loss= 0.1425\n",
      "2017-03-30 11:37:41,491 Iter 8600, Minibatch Loss= 0.2201, Training Accuracy= 0.9486, Minibatch error= 5.1%\n",
      "2017-03-30 11:37:57,774 Iter 8605, Minibatch Loss= 0.1921, Training Accuracy= 0.9647, Minibatch error= 3.5%\n",
      "2017-03-30 11:38:14,082 Iter 8610, Minibatch Loss= 0.1392, Training Accuracy= 0.9570, Minibatch error= 4.3%\n",
      "2017-03-30 11:38:30,450 Iter 8615, Minibatch Loss= 0.2972, Training Accuracy= 0.8447, Minibatch error= 15.5%\n",
      "2017-03-30 11:38:46,847 Iter 8620, Minibatch Loss= 0.0624, Training Accuracy= 0.9928, Minibatch error= 0.7%\n",
      "2017-03-30 11:39:03,231 Iter 8625, Minibatch Loss= 0.1594, Training Accuracy= 0.9657, Minibatch error= 3.4%\n",
      "2017-03-30 11:39:19,606 Iter 8630, Minibatch Loss= 0.0560, Training Accuracy= 0.9947, Minibatch error= 0.5%\n",
      "2017-03-30 11:39:36,059 Iter 8635, Minibatch Loss= 0.0336, Training Accuracy= 0.9979, Minibatch error= 0.2%\n",
      "2017-03-30 11:39:52,438 Iter 8640, Minibatch Loss= 0.1384, Training Accuracy= 0.9794, Minibatch error= 2.1%\n",
      "2017-03-30 11:40:08,795 Iter 8645, Minibatch Loss= 0.1923, Training Accuracy= 0.9441, Minibatch error= 5.6%\n",
      "2017-03-30 11:40:25,239 Iter 8650, Minibatch Loss= 0.1784, Training Accuracy= 0.9782, Minibatch error= 2.2%\n",
      "2017-03-30 11:40:41,639 Iter 8655, Minibatch Loss= 0.6938, Training Accuracy= 0.5469, Minibatch error= 45.3%\n",
      "2017-03-30 11:40:58,156 Iter 8660, Minibatch Loss= 0.1690, Training Accuracy= 0.9582, Minibatch error= 4.2%\n",
      "2017-03-30 11:41:14,640 Iter 8665, Minibatch Loss= 0.0998, Training Accuracy= 0.9947, Minibatch error= 0.5%\n",
      "2017-03-30 11:41:31,059 Iter 8670, Minibatch Loss= 0.0684, Training Accuracy= 0.9947, Minibatch error= 0.5%\n",
      "2017-03-30 11:41:47,440 Iter 8675, Minibatch Loss= 0.0785, Training Accuracy= 0.9843, Minibatch error= 1.6%\n",
      "2017-03-30 11:42:03,812 Iter 8680, Minibatch Loss= 0.0853, Training Accuracy= 0.9846, Minibatch error= 1.5%\n",
      "2017-03-30 11:42:20,194 Iter 8685, Minibatch Loss= 0.1544, Training Accuracy= 0.9433, Minibatch error= 5.7%\n",
      "2017-03-30 11:42:36,632 Iter 8690, Minibatch Loss= 0.1444, Training Accuracy= 0.9685, Minibatch error= 3.2%\n",
      "2017-03-30 11:42:53,101 Iter 8695, Minibatch Loss= 0.1354, Training Accuracy= 0.9636, Minibatch error= 3.6%\n",
      "2017-03-30 11:43:05,741 Epoch 86, Average loss: 0.1680, learning rate: 0.0010\n",
      "2017-03-30 11:43:09,639 Verification error= 4.1%, loss= 0.1158\n",
      "2017-03-30 11:43:18,839 Iter 8700, Minibatch Loss= 0.1894, Training Accuracy= 0.9289, Minibatch error= 7.1%\n",
      "2017-03-30 11:43:35,232 Iter 8705, Minibatch Loss= 0.0914, Training Accuracy= 0.9693, Minibatch error= 3.1%\n",
      "2017-03-30 11:43:51,735 Iter 8710, Minibatch Loss= 0.0520, Training Accuracy= 0.9876, Minibatch error= 1.2%\n",
      "2017-03-30 11:44:08,170 Iter 8715, Minibatch Loss= 0.1416, Training Accuracy= 0.9538, Minibatch error= 4.6%\n",
      "2017-03-30 11:44:24,591 Iter 8720, Minibatch Loss= 0.2038, Training Accuracy= 0.9182, Minibatch error= 8.2%\n",
      "2017-03-30 11:44:40,973 Iter 8725, Minibatch Loss= 0.2328, Training Accuracy= 0.8865, Minibatch error= 11.4%\n",
      "2017-03-30 11:44:57,423 Iter 8730, Minibatch Loss= 0.1303, Training Accuracy= 0.9516, Minibatch error= 4.8%\n",
      "2017-03-30 11:45:13,885 Iter 8735, Minibatch Loss= 0.2959, Training Accuracy= 0.8710, Minibatch error= 12.9%\n",
      "2017-03-30 11:45:30,304 Iter 8740, Minibatch Loss= 0.0674, Training Accuracy= 0.9852, Minibatch error= 1.5%\n",
      "2017-03-30 11:45:46,752 Iter 8745, Minibatch Loss= 0.5705, Training Accuracy= 0.7037, Minibatch error= 29.6%\n",
      "2017-03-30 11:46:03,202 Iter 8750, Minibatch Loss= 0.4296, Training Accuracy= 0.7687, Minibatch error= 23.1%\n",
      "2017-03-30 11:46:19,637 Iter 8755, Minibatch Loss= 0.2009, Training Accuracy= 0.9460, Minibatch error= 5.4%\n",
      "2017-03-30 11:46:36,136 Iter 8760, Minibatch Loss= 0.2214, Training Accuracy= 0.9060, Minibatch error= 9.4%\n",
      "2017-03-30 11:46:52,696 Iter 8765, Minibatch Loss= 0.1126, Training Accuracy= 0.9950, Minibatch error= 0.5%\n",
      "2017-03-30 11:47:09,202 Iter 8770, Minibatch Loss= 0.1648, Training Accuracy= 0.9890, Minibatch error= 1.1%\n",
      "2017-03-30 11:47:25,746 Iter 8775, Minibatch Loss= 0.1421, Training Accuracy= 0.9683, Minibatch error= 3.2%\n",
      "2017-03-30 11:47:42,325 Iter 8780, Minibatch Loss= 0.2152, Training Accuracy= 0.9221, Minibatch error= 7.8%\n",
      "2017-03-30 11:47:58,977 Iter 8785, Minibatch Loss= 0.1703, Training Accuracy= 0.9225, Minibatch error= 7.7%\n",
      "2017-03-30 11:48:15,498 Iter 8790, Minibatch Loss= 0.0661, Training Accuracy= 0.9891, Minibatch error= 1.1%\n",
      "2017-03-30 11:48:32,128 Iter 8795, Minibatch Loss= 0.1833, Training Accuracy= 0.9238, Minibatch error= 7.6%\n",
      "2017-03-30 11:48:45,042 Epoch 87, Average loss: 0.1796, learning rate: 0.0010\n",
      "2017-03-30 11:48:49,066 Verification error= 4.2%, loss= 0.1124\n",
      "2017-03-30 11:48:58,416 Iter 8800, Minibatch Loss= 0.1575, Training Accuracy= 0.9437, Minibatch error= 5.6%\n",
      "2017-03-30 11:49:15,227 Iter 8805, Minibatch Loss= 0.0608, Training Accuracy= 0.9825, Minibatch error= 1.8%\n",
      "2017-03-30 11:49:32,028 Iter 8810, Minibatch Loss= 0.5984, Training Accuracy= 0.7425, Minibatch error= 25.8%\n",
      "2017-03-30 11:49:48,718 Iter 8815, Minibatch Loss= 0.1726, Training Accuracy= 0.9388, Minibatch error= 6.1%\n",
      "2017-03-30 11:50:05,491 Iter 8820, Minibatch Loss= 0.1168, Training Accuracy= 0.9698, Minibatch error= 3.0%\n",
      "2017-03-30 11:50:22,171 Iter 8825, Minibatch Loss= 0.0917, Training Accuracy= 0.9795, Minibatch error= 2.0%\n",
      "2017-03-30 11:50:38,920 Iter 8830, Minibatch Loss= 0.0664, Training Accuracy= 0.9925, Minibatch error= 0.7%\n",
      "2017-03-30 11:50:55,763 Iter 8835, Minibatch Loss= 0.1376, Training Accuracy= 0.9575, Minibatch error= 4.2%\n",
      "2017-03-30 11:51:12,512 Iter 8840, Minibatch Loss= 0.0858, Training Accuracy= 0.9791, Minibatch error= 2.1%\n",
      "2017-03-30 11:51:29,327 Iter 8845, Minibatch Loss= 0.2959, Training Accuracy= 0.8717, Minibatch error= 12.8%\n",
      "2017-03-30 11:51:46,034 Iter 8850, Minibatch Loss= 0.0647, Training Accuracy= 0.9974, Minibatch error= 0.3%\n",
      "2017-03-30 11:52:02,877 Iter 8855, Minibatch Loss= 0.0546, Training Accuracy= 0.9976, Minibatch error= 0.2%\n",
      "2017-03-30 11:52:19,642 Iter 8860, Minibatch Loss= 0.2063, Training Accuracy= 0.9156, Minibatch error= 8.4%\n",
      "2017-03-30 11:52:36,548 Iter 8865, Minibatch Loss= 0.1667, Training Accuracy= 0.9372, Minibatch error= 6.3%\n",
      "2017-03-30 11:52:53,520 Iter 8870, Minibatch Loss= 0.4235, Training Accuracy= 0.8221, Minibatch error= 17.8%\n",
      "2017-03-30 11:53:10,323 Iter 8875, Minibatch Loss= 0.0719, Training Accuracy= 0.9897, Minibatch error= 1.0%\n",
      "2017-03-30 11:53:27,126 Iter 8880, Minibatch Loss= 0.1294, Training Accuracy= 0.9691, Minibatch error= 3.1%\n",
      "2017-03-30 11:53:43,963 Iter 8885, Minibatch Loss= 0.2236, Training Accuracy= 0.9037, Minibatch error= 9.6%\n",
      "2017-03-30 11:54:00,784 Iter 8890, Minibatch Loss= 0.1150, Training Accuracy= 0.9926, Minibatch error= 0.7%\n",
      "2017-03-30 11:54:17,623 Iter 8895, Minibatch Loss= 0.0283, Training Accuracy= 0.9979, Minibatch error= 0.2%\n",
      "2017-03-30 11:54:30,687 Epoch 88, Average loss: 0.1330, learning rate: 0.0010\n",
      "2017-03-30 11:54:34,731 Verification error= 4.5%, loss= 0.1231\n",
      "2017-03-30 11:54:43,606 Iter 8900, Minibatch Loss= 0.0526, Training Accuracy= 0.9921, Minibatch error= 0.8%\n",
      "2017-03-30 11:55:00,395 Iter 8905, Minibatch Loss= 0.5665, Training Accuracy= 0.7660, Minibatch error= 23.4%\n",
      "2017-03-30 11:55:17,401 Iter 8910, Minibatch Loss= 0.1073, Training Accuracy= 0.9591, Minibatch error= 4.1%\n",
      "2017-03-30 11:55:34,538 Iter 8915, Minibatch Loss= 0.1348, Training Accuracy= 0.9568, Minibatch error= 4.3%\n",
      "2017-03-30 11:55:52,530 Iter 8920, Minibatch Loss= 0.1692, Training Accuracy= 0.9501, Minibatch error= 5.0%\n",
      "2017-03-30 11:56:09,490 Iter 8925, Minibatch Loss= 0.1587, Training Accuracy= 0.9795, Minibatch error= 2.0%\n",
      "2017-03-30 11:56:26,712 Iter 8930, Minibatch Loss= 0.2171, Training Accuracy= 0.9346, Minibatch error= 6.5%\n",
      "2017-03-30 11:56:43,771 Iter 8935, Minibatch Loss= 0.2122, Training Accuracy= 0.9345, Minibatch error= 6.5%\n",
      "2017-03-30 11:57:00,689 Iter 8940, Minibatch Loss= 0.1216, Training Accuracy= 0.9493, Minibatch error= 5.1%\n",
      "2017-03-30 11:57:17,710 Iter 8945, Minibatch Loss= 0.1125, Training Accuracy= 0.9634, Minibatch error= 3.7%\n",
      "2017-03-30 11:57:34,630 Iter 8950, Minibatch Loss= 0.1025, Training Accuracy= 0.9904, Minibatch error= 1.0%\n",
      "2017-03-30 11:57:51,672 Iter 8955, Minibatch Loss= 0.1695, Training Accuracy= 0.9890, Minibatch error= 1.1%\n",
      "2017-03-30 11:58:08,669 Iter 8960, Minibatch Loss= 0.1324, Training Accuracy= 0.9679, Minibatch error= 3.2%\n",
      "2017-03-30 11:58:25,734 Iter 8965, Minibatch Loss= 0.0566, Training Accuracy= 0.9917, Minibatch error= 0.8%\n",
      "2017-03-30 11:58:42,816 Iter 8970, Minibatch Loss= 0.1095, Training Accuracy= 0.9799, Minibatch error= 2.0%\n",
      "2017-03-30 11:58:59,732 Iter 8975, Minibatch Loss= 0.0865, Training Accuracy= 0.9812, Minibatch error= 1.9%\n",
      "2017-03-30 11:59:16,870 Iter 8980, Minibatch Loss= 0.1687, Training Accuracy= 0.9349, Minibatch error= 6.5%\n",
      "2017-03-30 11:59:33,724 Iter 8985, Minibatch Loss= 0.0808, Training Accuracy= 0.9808, Minibatch error= 1.9%\n",
      "2017-03-30 11:59:50,633 Iter 8990, Minibatch Loss= 0.0617, Training Accuracy= 0.9933, Minibatch error= 0.7%\n",
      "2017-03-30 12:00:07,601 Iter 8995, Minibatch Loss= 0.1018, Training Accuracy= 0.9695, Minibatch error= 3.1%\n",
      "2017-03-30 12:00:20,572 Epoch 89, Average loss: 0.1552, learning rate: 0.0010\n",
      "2017-03-30 12:00:24,654 Verification error= 4.0%, loss= 0.1153\n",
      "2017-03-30 12:00:34,202 Iter 9000, Minibatch Loss= 0.0733, Training Accuracy= 0.9936, Minibatch error= 0.6%\n",
      "2017-03-30 12:00:51,421 Iter 9005, Minibatch Loss= 0.1157, Training Accuracy= 0.9711, Minibatch error= 2.9%\n",
      "2017-03-30 12:01:08,510 Iter 9010, Minibatch Loss= 0.2060, Training Accuracy= 0.9377, Minibatch error= 6.2%\n",
      "2017-03-30 12:01:25,567 Iter 9015, Minibatch Loss= 0.1141, Training Accuracy= 0.9709, Minibatch error= 2.9%\n",
      "2017-03-30 12:01:42,636 Iter 9020, Minibatch Loss= 0.1498, Training Accuracy= 0.9405, Minibatch error= 5.9%\n",
      "2017-03-30 12:01:59,666 Iter 9025, Minibatch Loss= 0.1035, Training Accuracy= 0.9721, Minibatch error= 2.8%\n",
      "2017-03-30 12:02:16,786 Iter 9030, Minibatch Loss= 0.3383, Training Accuracy= 0.8350, Minibatch error= 16.5%\n",
      "2017-03-30 12:02:33,899 Iter 9035, Minibatch Loss= 0.0870, Training Accuracy= 0.9738, Minibatch error= 2.6%\n",
      "2017-03-30 12:02:50,968 Iter 9040, Minibatch Loss= 0.1428, Training Accuracy= 0.9547, Minibatch error= 4.5%\n",
      "2017-03-30 12:03:07,970 Iter 9045, Minibatch Loss= 0.0685, Training Accuracy= 0.9920, Minibatch error= 0.8%\n",
      "2017-03-30 12:03:25,536 Iter 9050, Minibatch Loss= 0.1300, Training Accuracy= 0.9651, Minibatch error= 3.5%\n",
      "2017-03-30 12:03:43,304 Iter 9055, Minibatch Loss= 0.0904, Training Accuracy= 0.9895, Minibatch error= 1.1%\n",
      "2017-03-30 12:04:02,047 Iter 9060, Minibatch Loss= 0.3585, Training Accuracy= 0.8171, Minibatch error= 18.3%\n",
      "2017-03-30 12:04:19,617 Iter 9065, Minibatch Loss= 0.1873, Training Accuracy= 0.9465, Minibatch error= 5.4%\n",
      "2017-03-30 12:04:37,100 Iter 9070, Minibatch Loss= 0.1568, Training Accuracy= 0.9756, Minibatch error= 2.4%\n",
      "2017-03-30 12:04:54,192 Iter 9075, Minibatch Loss= 0.2379, Training Accuracy= 0.8939, Minibatch error= 10.6%\n",
      "2017-03-30 12:05:11,260 Iter 9080, Minibatch Loss= 0.1740, Training Accuracy= 0.9378, Minibatch error= 6.2%\n",
      "2017-03-30 12:05:28,433 Iter 9085, Minibatch Loss= 0.0774, Training Accuracy= 0.9864, Minibatch error= 1.4%\n",
      "2017-03-30 12:05:45,652 Iter 9090, Minibatch Loss= 0.2518, Training Accuracy= 0.9217, Minibatch error= 7.8%\n",
      "2017-03-30 12:06:02,983 Iter 9095, Minibatch Loss= 0.2182, Training Accuracy= 0.9105, Minibatch error= 9.0%\n",
      "2017-03-30 12:06:16,373 Epoch 90, Average loss: 0.1737, learning rate: 0.0010\n",
      "2017-03-30 12:06:20,431 Verification error= 4.4%, loss= 0.1220\n",
      "2017-03-30 12:06:29,463 Iter 9100, Minibatch Loss= 0.0527, Training Accuracy= 0.9951, Minibatch error= 0.5%\n",
      "2017-03-30 12:06:46,760 Iter 9105, Minibatch Loss= 0.1044, Training Accuracy= 0.9668, Minibatch error= 3.3%\n",
      "2017-03-30 12:07:04,019 Iter 9110, Minibatch Loss= 0.0705, Training Accuracy= 0.9848, Minibatch error= 1.5%\n",
      "2017-03-30 12:07:21,516 Iter 9115, Minibatch Loss= 0.2653, Training Accuracy= 0.8910, Minibatch error= 10.9%\n",
      "2017-03-30 12:07:39,011 Iter 9120, Minibatch Loss= 0.1354, Training Accuracy= 0.9488, Minibatch error= 5.1%\n",
      "2017-03-30 12:07:56,405 Iter 9125, Minibatch Loss= 0.0675, Training Accuracy= 0.9889, Minibatch error= 1.1%\n",
      "2017-03-30 12:08:13,833 Iter 9130, Minibatch Loss= 0.1019, Training Accuracy= 0.9587, Minibatch error= 4.1%\n",
      "2017-03-30 12:08:31,208 Iter 9135, Minibatch Loss= 0.1073, Training Accuracy= 0.9603, Minibatch error= 4.0%\n",
      "2017-03-30 12:08:48,768 Iter 9140, Minibatch Loss= 0.1567, Training Accuracy= 0.9480, Minibatch error= 5.2%\n",
      "2017-03-30 12:09:06,461 Iter 9145, Minibatch Loss= 0.0410, Training Accuracy= 0.9945, Minibatch error= 0.6%\n",
      "2017-03-30 12:09:24,085 Iter 9150, Minibatch Loss= 0.2519, Training Accuracy= 0.9058, Minibatch error= 9.4%\n",
      "2017-03-30 12:09:41,775 Iter 9155, Minibatch Loss= 0.2042, Training Accuracy= 0.9506, Minibatch error= 4.9%\n",
      "2017-03-30 12:09:59,389 Iter 9160, Minibatch Loss= 0.1470, Training Accuracy= 0.9758, Minibatch error= 2.4%\n",
      "2017-03-30 12:10:16,933 Iter 9165, Minibatch Loss= 0.1545, Training Accuracy= 0.9607, Minibatch error= 3.9%\n",
      "2017-03-30 12:10:34,517 Iter 9170, Minibatch Loss= 0.1477, Training Accuracy= 0.9776, Minibatch error= 2.2%\n",
      "2017-03-30 12:10:52,369 Iter 9175, Minibatch Loss= 0.1400, Training Accuracy= 0.9654, Minibatch error= 3.5%\n",
      "2017-03-30 12:11:09,978 Iter 9180, Minibatch Loss= 0.1708, Training Accuracy= 0.9377, Minibatch error= 6.2%\n",
      "2017-03-30 12:11:27,699 Iter 9185, Minibatch Loss= 0.0542, Training Accuracy= 0.9980, Minibatch error= 0.2%\n",
      "2017-03-30 12:11:45,374 Iter 9190, Minibatch Loss= 0.0740, Training Accuracy= 0.9727, Minibatch error= 2.7%\n",
      "2017-03-30 12:12:03,122 Iter 9195, Minibatch Loss= 0.4024, Training Accuracy= 0.8074, Minibatch error= 19.3%\n",
      "2017-03-30 12:12:16,850 Epoch 91, Average loss: 0.1577, learning rate: 0.0010\n",
      "2017-03-30 12:12:21,089 Verification error= 4.2%, loss= 0.1191\n",
      "2017-03-30 12:12:30,865 Iter 9200, Minibatch Loss= 0.0562, Training Accuracy= 0.9930, Minibatch error= 0.7%\n",
      "2017-03-30 12:12:48,593 Iter 9205, Minibatch Loss= 0.1158, Training Accuracy= 0.9782, Minibatch error= 2.2%\n",
      "2017-03-30 12:13:06,270 Iter 9210, Minibatch Loss= 0.2397, Training Accuracy= 0.9239, Minibatch error= 7.6%\n",
      "2017-03-30 12:13:24,005 Iter 9215, Minibatch Loss= 0.2231, Training Accuracy= 0.9241, Minibatch error= 7.6%\n",
      "2017-03-30 12:13:41,715 Iter 9220, Minibatch Loss= 0.1590, Training Accuracy= 0.9706, Minibatch error= 2.9%\n",
      "2017-03-30 12:13:59,455 Iter 9225, Minibatch Loss= 0.2220, Training Accuracy= 0.8911, Minibatch error= 10.9%\n",
      "2017-03-30 12:14:17,329 Iter 9230, Minibatch Loss= 0.1890, Training Accuracy= 0.9241, Minibatch error= 7.6%\n",
      "2017-03-30 12:14:35,143 Iter 9235, Minibatch Loss= 0.1517, Training Accuracy= 0.9654, Minibatch error= 3.5%\n",
      "2017-03-30 12:14:53,127 Iter 9240, Minibatch Loss= 0.0840, Training Accuracy= 0.9873, Minibatch error= 1.3%\n",
      "2017-03-30 12:15:11,135 Iter 9245, Minibatch Loss= 0.1370, Training Accuracy= 0.9510, Minibatch error= 4.9%\n",
      "2017-03-30 12:15:29,126 Iter 9250, Minibatch Loss= 0.0672, Training Accuracy= 0.9825, Minibatch error= 1.8%\n",
      "2017-03-30 12:15:47,006 Iter 9255, Minibatch Loss= 0.3976, Training Accuracy= 0.7785, Minibatch error= 22.2%\n",
      "2017-03-30 12:16:05,066 Iter 9260, Minibatch Loss= 0.4583, Training Accuracy= 0.8125, Minibatch error= 18.7%\n",
      "2017-03-30 12:16:23,124 Iter 9265, Minibatch Loss= 0.1100, Training Accuracy= 0.9597, Minibatch error= 4.0%\n",
      "2017-03-30 12:16:41,223 Iter 9270, Minibatch Loss= 0.0500, Training Accuracy= 0.9837, Minibatch error= 1.6%\n",
      "2017-03-30 12:16:59,293 Iter 9275, Minibatch Loss= 0.0296, Training Accuracy= 0.9967, Minibatch error= 0.3%\n",
      "2017-03-30 12:17:17,067 Iter 9280, Minibatch Loss= 0.0821, Training Accuracy= 0.9768, Minibatch error= 2.3%\n",
      "2017-03-30 12:17:34,607 Iter 9285, Minibatch Loss= 0.0996, Training Accuracy= 0.9711, Minibatch error= 2.9%\n",
      "2017-03-30 12:17:52,377 Iter 9290, Minibatch Loss= 0.0720, Training Accuracy= 0.9912, Minibatch error= 0.9%\n",
      "2017-03-30 12:18:10,112 Iter 9295, Minibatch Loss= 0.0404, Training Accuracy= 0.9921, Minibatch error= 0.8%\n",
      "2017-03-30 12:18:23,830 Epoch 92, Average loss: 0.1509, learning rate: 0.0010\n",
      "2017-03-30 12:18:28,102 Verification error= 4.3%, loss= 0.1414\n",
      "2017-03-30 12:18:37,439 Iter 9300, Minibatch Loss= 0.1125, Training Accuracy= 0.9761, Minibatch error= 2.4%\n",
      "2017-03-30 12:18:55,292 Iter 9305, Minibatch Loss= 0.1439, Training Accuracy= 0.9525, Minibatch error= 4.7%\n",
      "2017-03-30 12:19:13,120 Iter 9310, Minibatch Loss= 0.0898, Training Accuracy= 0.9871, Minibatch error= 1.3%\n",
      "2017-03-30 12:19:30,976 Iter 9315, Minibatch Loss= 0.1879, Training Accuracy= 0.9429, Minibatch error= 5.7%\n",
      "2017-03-30 12:19:48,815 Iter 9320, Minibatch Loss= 0.1014, Training Accuracy= 0.9909, Minibatch error= 0.9%\n",
      "2017-03-30 12:20:06,706 Iter 9325, Minibatch Loss= 0.8908, Training Accuracy= 0.6463, Minibatch error= 35.4%\n",
      "2017-03-30 12:20:24,606 Iter 9330, Minibatch Loss= 0.1399, Training Accuracy= 0.9728, Minibatch error= 2.7%\n",
      "2017-03-30 12:20:42,519 Iter 9335, Minibatch Loss= 0.0931, Training Accuracy= 0.9953, Minibatch error= 0.5%\n",
      "2017-03-30 12:21:00,347 Iter 9340, Minibatch Loss= 0.1592, Training Accuracy= 0.9330, Minibatch error= 6.7%\n",
      "2017-03-30 12:21:18,259 Iter 9345, Minibatch Loss= 0.1232, Training Accuracy= 0.9705, Minibatch error= 3.0%\n",
      "2017-03-30 12:21:36,180 Iter 9350, Minibatch Loss= 0.0991, Training Accuracy= 0.9736, Minibatch error= 2.6%\n",
      "2017-03-30 12:21:53,941 Iter 9355, Minibatch Loss= 0.0857, Training Accuracy= 0.9938, Minibatch error= 0.6%\n",
      "2017-03-30 12:22:11,864 Iter 9360, Minibatch Loss= 0.1704, Training Accuracy= 0.9497, Minibatch error= 5.0%\n",
      "2017-03-30 12:22:29,794 Iter 9365, Minibatch Loss= 0.1656, Training Accuracy= 0.9495, Minibatch error= 5.0%\n",
      "2017-03-30 12:22:47,818 Iter 9370, Minibatch Loss= 0.0886, Training Accuracy= 0.9925, Minibatch error= 0.7%\n",
      "2017-03-30 12:23:05,801 Iter 9375, Minibatch Loss= 0.1800, Training Accuracy= 0.9230, Minibatch error= 7.7%\n",
      "2017-03-30 12:23:23,685 Iter 9380, Minibatch Loss= 0.1145, Training Accuracy= 0.9887, Minibatch error= 1.1%\n",
      "2017-03-30 12:23:41,708 Iter 9385, Minibatch Loss= 0.1641, Training Accuracy= 0.9538, Minibatch error= 4.6%\n",
      "2017-03-30 12:23:59,737 Iter 9390, Minibatch Loss= 0.1186, Training Accuracy= 0.9681, Minibatch error= 3.2%\n",
      "2017-03-30 12:24:17,729 Iter 9395, Minibatch Loss= 0.3966, Training Accuracy= 0.8306, Minibatch error= 16.9%\n",
      "2017-03-30 12:24:31,631 Epoch 93, Average loss: 0.1631, learning rate: 0.0010\n",
      "2017-03-30 12:24:35,895 Verification error= 3.9%, loss= 0.1070\n",
      "2017-03-30 12:24:45,996 Iter 9400, Minibatch Loss= 0.0761, Training Accuracy= 0.9890, Minibatch error= 1.1%\n",
      "2017-03-30 12:25:03,601 Iter 9405, Minibatch Loss= 0.1107, Training Accuracy= 0.9651, Minibatch error= 3.5%\n",
      "2017-03-30 12:25:20,543 Iter 9410, Minibatch Loss= 0.3636, Training Accuracy= 0.8199, Minibatch error= 18.0%\n",
      "2017-03-30 12:25:37,382 Iter 9415, Minibatch Loss= 0.0836, Training Accuracy= 0.9893, Minibatch error= 1.1%\n",
      "2017-03-30 12:25:54,227 Iter 9420, Minibatch Loss= 0.1590, Training Accuracy= 0.9607, Minibatch error= 3.9%\n",
      "2017-03-30 12:26:11,125 Iter 9425, Minibatch Loss= 0.0611, Training Accuracy= 0.9974, Minibatch error= 0.3%\n",
      "2017-03-30 12:26:28,037 Iter 9430, Minibatch Loss= 0.1050, Training Accuracy= 0.9867, Minibatch error= 1.3%\n",
      "2017-03-30 12:26:45,028 Iter 9435, Minibatch Loss= 0.0694, Training Accuracy= 0.9896, Minibatch error= 1.0%\n",
      "2017-03-30 12:27:02,026 Iter 9440, Minibatch Loss= 0.1468, Training Accuracy= 0.9453, Minibatch error= 5.5%\n",
      "2017-03-30 12:27:19,039 Iter 9445, Minibatch Loss= 0.1321, Training Accuracy= 0.9673, Minibatch error= 3.3%\n",
      "2017-03-30 12:27:36,009 Iter 9450, Minibatch Loss= 0.1181, Training Accuracy= 0.9791, Minibatch error= 2.1%\n",
      "2017-03-30 12:27:53,071 Iter 9455, Minibatch Loss= 0.1157, Training Accuracy= 0.9585, Minibatch error= 4.1%\n",
      "2017-03-30 12:28:10,305 Iter 9460, Minibatch Loss= 0.2940, Training Accuracy= 0.8738, Minibatch error= 12.6%\n",
      "2017-03-30 12:28:27,716 Iter 9465, Minibatch Loss= 0.0235, Training Accuracy= 0.9950, Minibatch error= 0.5%\n",
      "2017-03-30 12:28:45,298 Iter 9470, Minibatch Loss= 0.0983, Training Accuracy= 0.9753, Minibatch error= 2.5%\n",
      "2017-03-30 12:29:02,782 Iter 9475, Minibatch Loss= 0.1034, Training Accuracy= 0.9683, Minibatch error= 3.2%\n",
      "2017-03-30 12:29:20,252 Iter 9480, Minibatch Loss= 0.1071, Training Accuracy= 0.9696, Minibatch error= 3.0%\n",
      "2017-03-30 12:29:37,780 Iter 9485, Minibatch Loss= 0.2386, Training Accuracy= 0.9164, Minibatch error= 8.4%\n",
      "2017-03-30 12:29:55,464 Iter 9490, Minibatch Loss= 0.1470, Training Accuracy= 0.9796, Minibatch error= 2.0%\n",
      "2017-03-30 12:30:13,155 Iter 9495, Minibatch Loss= 0.0688, Training Accuracy= 0.9929, Minibatch error= 0.7%\n",
      "2017-03-30 12:30:26,808 Epoch 94, Average loss: 0.1640, learning rate: 0.0010\n",
      "2017-03-30 12:30:31,035 Verification error= 4.4%, loss= 0.1714\n",
      "2017-03-30 12:30:41,164 Iter 9500, Minibatch Loss= 0.1300, Training Accuracy= 0.9720, Minibatch error= 2.8%\n",
      "2017-03-30 12:30:59,252 Iter 9505, Minibatch Loss= 0.1249, Training Accuracy= 0.9655, Minibatch error= 3.4%\n",
      "2017-03-30 12:31:17,366 Iter 9510, Minibatch Loss= 0.1104, Training Accuracy= 0.9681, Minibatch error= 3.2%\n",
      "2017-03-30 12:31:35,444 Iter 9515, Minibatch Loss= 0.1177, Training Accuracy= 0.9609, Minibatch error= 3.9%\n",
      "2017-03-30 12:31:53,432 Iter 9520, Minibatch Loss= 0.1115, Training Accuracy= 0.9696, Minibatch error= 3.0%\n",
      "2017-03-30 12:32:11,581 Iter 9525, Minibatch Loss= 0.0858, Training Accuracy= 0.9848, Minibatch error= 1.5%\n",
      "2017-03-30 12:32:29,847 Iter 9530, Minibatch Loss= 0.1458, Training Accuracy= 0.9524, Minibatch error= 4.8%\n",
      "2017-03-30 12:32:48,163 Iter 9535, Minibatch Loss= 0.1182, Training Accuracy= 0.9719, Minibatch error= 2.8%\n",
      "2017-03-30 12:33:06,402 Iter 9540, Minibatch Loss= 0.0878, Training Accuracy= 0.9792, Minibatch error= 2.1%\n",
      "2017-03-30 12:33:24,700 Iter 9545, Minibatch Loss= 0.1978, Training Accuracy= 0.9153, Minibatch error= 8.5%\n",
      "2017-03-30 12:33:42,327 Iter 9550, Minibatch Loss= 0.0745, Training Accuracy= 0.9859, Minibatch error= 1.4%\n",
      "2017-03-30 12:33:59,862 Iter 9555, Minibatch Loss= 0.1286, Training Accuracy= 0.9489, Minibatch error= 5.1%\n",
      "2017-03-30 12:34:17,397 Iter 9560, Minibatch Loss= 0.2627, Training Accuracy= 0.8914, Minibatch error= 10.9%\n",
      "2017-03-30 12:34:35,090 Iter 9565, Minibatch Loss= 0.1949, Training Accuracy= 0.9138, Minibatch error= 8.6%\n",
      "2017-03-30 12:34:52,780 Iter 9570, Minibatch Loss= 0.1155, Training Accuracy= 0.9689, Minibatch error= 3.1%\n",
      "2017-03-30 12:35:10,527 Iter 9575, Minibatch Loss= 0.6358, Training Accuracy= 0.6868, Minibatch error= 31.3%\n",
      "2017-03-30 12:35:28,380 Iter 9580, Minibatch Loss= 0.1629, Training Accuracy= 0.9356, Minibatch error= 6.4%\n",
      "2017-03-30 12:35:46,145 Iter 9585, Minibatch Loss= 0.0854, Training Accuracy= 0.9856, Minibatch error= 1.4%\n",
      "2017-03-30 12:36:04,104 Iter 9590, Minibatch Loss= 0.2146, Training Accuracy= 0.9474, Minibatch error= 5.3%\n",
      "2017-03-30 12:36:22,108 Iter 9595, Minibatch Loss= 0.9980, Training Accuracy= 0.4577, Minibatch error= 54.2%\n",
      "2017-03-30 12:36:35,998 Epoch 95, Average loss: 0.1680, learning rate: 0.0010\n",
      "2017-03-30 12:36:40,248 Verification error= 4.3%, loss= 0.1398\n",
      "2017-03-30 12:36:49,736 Iter 9600, Minibatch Loss= 0.0973, Training Accuracy= 0.9805, Minibatch error= 1.9%\n",
      "2017-03-30 12:37:07,956 Iter 9605, Minibatch Loss= 0.2144, Training Accuracy= 0.9177, Minibatch error= 8.2%\n",
      "2017-03-30 12:37:26,211 Iter 9610, Minibatch Loss= 0.4320, Training Accuracy= 0.8109, Minibatch error= 18.9%\n",
      "2017-03-30 12:37:44,360 Iter 9615, Minibatch Loss= 0.1212, Training Accuracy= 0.9676, Minibatch error= 3.2%\n",
      "2017-03-30 12:38:02,670 Iter 9620, Minibatch Loss= 0.1795, Training Accuracy= 0.9059, Minibatch error= 9.4%\n",
      "2017-03-30 12:38:20,845 Iter 9625, Minibatch Loss= 0.1102, Training Accuracy= 0.9688, Minibatch error= 3.1%\n",
      "2017-03-30 12:38:39,177 Iter 9630, Minibatch Loss= 0.4977, Training Accuracy= 0.7634, Minibatch error= 23.7%\n",
      "2017-03-30 12:38:57,588 Iter 9635, Minibatch Loss= 0.0802, Training Accuracy= 0.9886, Minibatch error= 1.1%\n",
      "2017-03-30 12:39:15,944 Iter 9640, Minibatch Loss= 0.1807, Training Accuracy= 0.9147, Minibatch error= 8.5%\n",
      "2017-03-30 12:39:34,371 Iter 9645, Minibatch Loss= 0.1404, Training Accuracy= 0.9548, Minibatch error= 4.5%\n",
      "2017-03-30 12:39:52,776 Iter 9650, Minibatch Loss= 0.0634, Training Accuracy= 0.9860, Minibatch error= 1.4%\n",
      "2017-03-30 12:40:11,183 Iter 9655, Minibatch Loss= 0.2021, Training Accuracy= 0.8963, Minibatch error= 10.4%\n",
      "2017-03-30 12:40:29,509 Iter 9660, Minibatch Loss= 0.1768, Training Accuracy= 0.9285, Minibatch error= 7.2%\n",
      "2017-03-30 12:40:47,932 Iter 9665, Minibatch Loss= 0.1283, Training Accuracy= 0.9503, Minibatch error= 5.0%\n",
      "2017-03-30 12:41:06,320 Iter 9670, Minibatch Loss= 0.0452, Training Accuracy= 0.9956, Minibatch error= 0.4%\n",
      "2017-03-30 12:41:24,678 Iter 9675, Minibatch Loss= 0.0903, Training Accuracy= 0.9772, Minibatch error= 2.3%\n",
      "2017-03-30 12:41:43,120 Iter 9680, Minibatch Loss= 0.1716, Training Accuracy= 0.9764, Minibatch error= 2.4%\n",
      "2017-03-30 12:42:01,457 Iter 9685, Minibatch Loss= 0.1362, Training Accuracy= 0.9720, Minibatch error= 2.8%\n",
      "2017-03-30 12:42:19,616 Iter 9690, Minibatch Loss= 0.2729, Training Accuracy= 0.8637, Minibatch error= 13.6%\n",
      "2017-03-30 12:42:37,720 Iter 9695, Minibatch Loss= 0.0876, Training Accuracy= 0.9729, Minibatch error= 2.7%\n",
      "2017-03-30 12:42:51,731 Epoch 96, Average loss: 0.1523, learning rate: 0.0010\n",
      "2017-03-30 12:42:56,025 Verification error= 4.2%, loss= 0.1318\n",
      "2017-03-30 12:43:06,309 Iter 9700, Minibatch Loss= 0.0755, Training Accuracy= 0.9885, Minibatch error= 1.1%\n",
      "2017-03-30 12:43:24,618 Iter 9705, Minibatch Loss= 0.5465, Training Accuracy= 0.7096, Minibatch error= 29.0%\n",
      "2017-03-30 12:43:43,137 Iter 9710, Minibatch Loss= 0.1186, Training Accuracy= 0.9635, Minibatch error= 3.6%\n",
      "2017-03-30 12:44:01,575 Iter 9715, Minibatch Loss= 0.1146, Training Accuracy= 0.9711, Minibatch error= 2.9%\n",
      "2017-03-30 12:44:19,965 Iter 9720, Minibatch Loss= 0.1024, Training Accuracy= 0.9947, Minibatch error= 0.5%\n",
      "2017-03-30 12:44:37,628 Iter 9725, Minibatch Loss= 0.1987, Training Accuracy= 0.9390, Minibatch error= 6.1%\n",
      "2017-03-30 12:44:54,716 Iter 9730, Minibatch Loss= 0.1083, Training Accuracy= 0.9728, Minibatch error= 2.7%\n",
      "2017-03-30 12:45:11,792 Iter 9735, Minibatch Loss= 0.1085, Training Accuracy= 0.9764, Minibatch error= 2.4%\n",
      "2017-03-30 12:45:28,900 Iter 9740, Minibatch Loss= 0.2357, Training Accuracy= 0.9155, Minibatch error= 8.5%\n",
      "2017-03-30 12:45:45,987 Iter 9745, Minibatch Loss= 0.0911, Training Accuracy= 0.9681, Minibatch error= 3.2%\n",
      "2017-03-30 12:46:03,105 Iter 9750, Minibatch Loss= 0.0571, Training Accuracy= 0.9813, Minibatch error= 1.9%\n",
      "2017-03-30 12:46:20,279 Iter 9755, Minibatch Loss= 0.0444, Training Accuracy= 0.9835, Minibatch error= 1.6%\n",
      "2017-03-30 12:46:37,474 Iter 9760, Minibatch Loss= 0.1225, Training Accuracy= 0.9595, Minibatch error= 4.1%\n",
      "2017-03-30 12:46:54,691 Iter 9765, Minibatch Loss= 0.0287, Training Accuracy= 0.9941, Minibatch error= 0.6%\n",
      "2017-03-30 12:47:11,907 Iter 9770, Minibatch Loss= 0.1619, Training Accuracy= 0.9309, Minibatch error= 6.9%\n",
      "2017-03-30 12:47:29,210 Iter 9775, Minibatch Loss= 0.1397, Training Accuracy= 0.9591, Minibatch error= 4.1%\n",
      "2017-03-30 12:47:46,467 Iter 9780, Minibatch Loss= 0.1748, Training Accuracy= 0.9351, Minibatch error= 6.5%\n",
      "2017-03-30 12:48:03,747 Iter 9785, Minibatch Loss= 0.1564, Training Accuracy= 0.9814, Minibatch error= 1.9%\n",
      "2017-03-30 12:48:21,074 Iter 9790, Minibatch Loss= 0.1844, Training Accuracy= 0.9537, Minibatch error= 4.6%\n",
      "2017-03-30 12:48:38,447 Iter 9795, Minibatch Loss= 0.1476, Training Accuracy= 0.9647, Minibatch error= 3.5%\n",
      "2017-03-30 12:48:51,937 Epoch 97, Average loss: 0.1602, learning rate: 0.0010\n",
      "2017-03-30 12:48:55,878 Verification error= 4.2%, loss= 0.1458\n",
      "2017-03-30 12:49:05,367 Iter 9800, Minibatch Loss= 0.3079, Training Accuracy= 0.8284, Minibatch error= 17.2%\n",
      "2017-03-30 12:49:22,835 Iter 9805, Minibatch Loss= 0.2779, Training Accuracy= 0.8592, Minibatch error= 14.1%\n",
      "2017-03-30 12:49:40,391 Iter 9810, Minibatch Loss= 0.0825, Training Accuracy= 0.9783, Minibatch error= 2.2%\n",
      "2017-03-30 12:49:57,994 Iter 9815, Minibatch Loss= 0.0716, Training Accuracy= 0.9903, Minibatch error= 1.0%\n",
      "2017-03-30 12:50:15,535 Iter 9820, Minibatch Loss= 0.4557, Training Accuracy= 0.7437, Minibatch error= 25.6%\n",
      "2017-03-30 12:50:33,081 Iter 9825, Minibatch Loss= 0.0941, Training Accuracy= 0.9943, Minibatch error= 0.6%\n",
      "2017-03-30 12:50:50,724 Iter 9830, Minibatch Loss= 0.1207, Training Accuracy= 0.9784, Minibatch error= 2.2%\n",
      "2017-03-30 12:51:08,266 Iter 9835, Minibatch Loss= 0.1920, Training Accuracy= 0.9399, Minibatch error= 6.0%\n",
      "2017-03-30 12:51:25,814 Iter 9840, Minibatch Loss= 0.1045, Training Accuracy= 0.9870, Minibatch error= 1.3%\n",
      "2017-03-30 12:51:43,315 Iter 9845, Minibatch Loss= 0.1213, Training Accuracy= 0.9674, Minibatch error= 3.3%\n",
      "2017-03-30 12:52:00,902 Iter 9850, Minibatch Loss= 0.0799, Training Accuracy= 0.9857, Minibatch error= 1.4%\n",
      "2017-03-30 12:52:18,525 Iter 9855, Minibatch Loss= 0.1236, Training Accuracy= 0.9810, Minibatch error= 1.9%\n",
      "2017-03-30 12:52:36,178 Iter 9860, Minibatch Loss= 0.0932, Training Accuracy= 0.9747, Minibatch error= 2.5%\n",
      "2017-03-30 12:52:53,737 Iter 9865, Minibatch Loss= 0.0497, Training Accuracy= 0.9954, Minibatch error= 0.5%\n",
      "2017-03-30 12:53:11,298 Iter 9870, Minibatch Loss= 0.6886, Training Accuracy= 0.6788, Minibatch error= 32.1%\n",
      "2017-03-30 12:53:28,806 Iter 9875, Minibatch Loss= 0.0515, Training Accuracy= 0.9977, Minibatch error= 0.2%\n",
      "2017-03-30 12:53:46,511 Iter 9880, Minibatch Loss= 0.1063, Training Accuracy= 0.9894, Minibatch error= 1.1%\n",
      "2017-03-30 12:54:04,038 Iter 9885, Minibatch Loss= 0.0802, Training Accuracy= 0.9953, Minibatch error= 0.5%\n",
      "2017-03-30 12:54:21,647 Iter 9890, Minibatch Loss= 0.2000, Training Accuracy= 0.9484, Minibatch error= 5.2%\n",
      "2017-03-30 12:54:39,243 Iter 9895, Minibatch Loss= 0.1200, Training Accuracy= 0.9858, Minibatch error= 1.4%\n",
      "2017-03-30 12:54:52,940 Epoch 98, Average loss: 0.1451, learning rate: 0.0010\n",
      "2017-03-30 12:54:56,965 Verification error= 4.3%, loss= 0.1242\n",
      "2017-03-30 12:55:07,126 Iter 9900, Minibatch Loss= 0.1521, Training Accuracy= 0.9593, Minibatch error= 4.1%\n",
      "2017-03-30 12:55:24,769 Iter 9905, Minibatch Loss= 0.3056, Training Accuracy= 0.8390, Minibatch error= 16.1%\n",
      "2017-03-30 12:55:42,467 Iter 9910, Minibatch Loss= 0.0861, Training Accuracy= 0.9936, Minibatch error= 0.6%\n",
      "2017-03-30 12:56:00,099 Iter 9915, Minibatch Loss= 0.1080, Training Accuracy= 0.9687, Minibatch error= 3.1%\n",
      "2017-03-30 12:56:17,821 Iter 9920, Minibatch Loss= 0.2007, Training Accuracy= 0.9164, Minibatch error= 8.4%\n",
      "2017-03-30 12:56:35,580 Iter 9925, Minibatch Loss= 0.1965, Training Accuracy= 0.9392, Minibatch error= 6.1%\n",
      "2017-03-30 12:56:53,339 Iter 9930, Minibatch Loss= 0.2513, Training Accuracy= 0.8846, Minibatch error= 11.5%\n",
      "2017-03-30 12:57:11,079 Iter 9935, Minibatch Loss= 0.1029, Training Accuracy= 0.9882, Minibatch error= 1.2%\n",
      "2017-03-30 12:57:28,753 Iter 9940, Minibatch Loss= 0.0590, Training Accuracy= 0.9975, Minibatch error= 0.2%\n",
      "2017-03-30 12:57:46,475 Iter 9945, Minibatch Loss= 0.1161, Training Accuracy= 0.9604, Minibatch error= 4.0%\n",
      "2017-03-30 12:58:04,208 Iter 9950, Minibatch Loss= 0.0874, Training Accuracy= 0.9856, Minibatch error= 1.4%\n",
      "2017-03-30 12:58:21,954 Iter 9955, Minibatch Loss= 0.2227, Training Accuracy= 0.8963, Minibatch error= 10.4%\n",
      "2017-03-30 12:58:39,754 Iter 9960, Minibatch Loss= 0.1702, Training Accuracy= 0.9493, Minibatch error= 5.1%\n",
      "2017-03-30 12:58:57,622 Iter 9965, Minibatch Loss= 0.3278, Training Accuracy= 0.8395, Minibatch error= 16.0%\n",
      "2017-03-30 12:59:15,492 Iter 9970, Minibatch Loss= 0.1129, Training Accuracy= 0.9903, Minibatch error= 1.0%\n",
      "2017-03-30 12:59:33,356 Iter 9975, Minibatch Loss= 0.1371, Training Accuracy= 0.9759, Minibatch error= 2.4%\n",
      "2017-03-30 12:59:51,177 Iter 9980, Minibatch Loss= 0.1291, Training Accuracy= 0.9630, Minibatch error= 3.7%\n",
      "2017-03-30 13:00:08,956 Iter 9985, Minibatch Loss= 0.0999, Training Accuracy= 0.9848, Minibatch error= 1.5%\n",
      "2017-03-30 13:00:26,694 Iter 9990, Minibatch Loss= 0.1837, Training Accuracy= 0.9169, Minibatch error= 8.3%\n",
      "2017-03-30 13:00:44,412 Iter 9995, Minibatch Loss= 0.1053, Training Accuracy= 0.9781, Minibatch error= 2.2%\n",
      "2017-03-30 13:00:58,161 Epoch 99, Average loss: 0.1728, learning rate: 0.0010\n",
      "2017-03-30 13:01:02,223 Verification error= 4.2%, loss= 0.1153\n",
      "2017-03-30 13:01:08,532 Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "path = trainer.train(generator, \"./unet_trained\", training_iters=100, epochs=100, display_step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-30 13:01:15,503 Model restored from file: ./unet_trained/model.cpkt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 260, 260, 2) 0.934798 3.27342e-07\n"
     ]
    }
   ],
   "source": [
    "prediction = net.predict(\"./unet_trained/model.cpkt\", x_test)\n",
    "print(prediction.shape, np.max(prediction[0,...,1]), np.min(prediction[0,...,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
